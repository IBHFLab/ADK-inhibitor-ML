{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964b86ac-fc5d-4c29-b396-2085650307d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle \n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc,roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score,train_test_split,cross_validate, StratifiedKFold\n",
    "from sklearn.utils  import shuffle\n",
    "import joblib\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "# 忽略特定类型的警告\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5061bb92-d244-4ead-b1c5-24f08bb3115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager, pyplot as plt\n",
    "\n",
    "# 查找系统中所有可用的Times New Roman字体的路径\n",
    "times_new_roman = font_manager.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "# 从列表中找到一个指定的字体名称，并确保字体能支持加粗\n",
    "t_nr_path = [f for f in times_new_roman if 'Times New Roman' in f and 'Bold' in f]\n",
    "\n",
    "if t_nr_path:\n",
    "    # 如果找到了Times New Roman Bold字体，设置为默认字体\n",
    "    prop = font_manager.FontProperties(fname=t_nr_path[0])\n",
    "    plt.rcParams['font.family'] = prop.get_name()\n",
    "    plt.rcParams['font.weight'] = 'bold'  # 设置字体为加粗\n",
    "else:\n",
    "    # 如果没有找到加粗的Times New Roman，尝试设置为普通的Times New Roman并加粗\n",
    "    t_nr_path = [f for f in times_new_roman if 'Times New Roman' in f]\n",
    "    if t_nr_path:\n",
    "        prop = font_manager.FontProperties(fname=t_nr_path[0])\n",
    "        plt.rcParams['font.family'] = prop.get_name()\n",
    "        plt.rcParams['font.weight'] = 'bold'\n",
    "    else:\n",
    "        # 如果没有找到Times New Roman，使用默认的衬线字体并设置为加粗\n",
    "        plt.rcParams['font.family'] = 'serif'\n",
    "        plt.rcParams['font.weight'] = 'bold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ab0309-4cd3-4e51-a867-f0ddae9652eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查当前工作目录\n",
    "current_directory = os.getcwd()\n",
    "print(\"当前工作目录:\", current_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5fa6a5-fece-4ca9-a16e-dfbca26ac1e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c755eba7-e3d4-46ec-87e1-10f9e050687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分数据集\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "data = pd.read_csv('全部筛选过后数据-14.csv')\n",
    "x = data.iloc[:,2:] ###描述符\n",
    "y = data[\"bioactivity_class\"]   #标签\n",
    "chembl_id = data[\"molecule_chembl_id\"]  # Chembl ID\n",
    "#x_mor_train和x_mor_test分别为训练集和测试集中的特征数据，y_mor_train和y_mor_test分别为训练集和测试集中的目标变量数据。\n",
    "x_train, x_test, y_train, y_test, x_chembl_id, y_chembl_id = train_test_split(x, y, chembl_id, test_size=0.2,  \n",
    "                                                  #test_size=0.2: 测试集大小占总数据的20%。\n",
    "                                                  #stratify=y: 划分时保持y中的类别比例，确保训练集和测试集中各类别的比例与原始数据集相同。\n",
    "                                                       stratify=y, \n",
    "                                                  #设置随机数种子以确保结果的可重复性。\n",
    "                                                       random_state=13)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d2892-78b3-4f1f-a038-667c1c91be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看划分后数据集的大小\n",
    "print(\"训练集特征维度:\", x_train.shape)\n",
    "print(\"训练集目标维度:\",y_train.shape)\n",
    "print(\"测试集特征维度:\", x_test.shape)\n",
    "print(\"测试集目标维度:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220552f8-8b2d-4dad-8d8f-8646a91c6a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存训练集特征\n",
    "x_train.to_csv('train_features.csv', index=False)\n",
    "# 保存训练集目标变量\n",
    "y_train.to_csv('train_target.csv', index=False)\n",
    "x_chembl_id.to_csv('train_chembl_id.csv', index=False)\n",
    "\n",
    "# 保存测试集特征\n",
    "x_test.to_csv('test_features.csv', index=False)\n",
    "# 保存测试集目标变量\n",
    "y_test.to_csv('test_target.csv', index=False)\n",
    "y_chembl_id.to_csv('test_chembl_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c67f6c-9ad1-4a07-a8aa-006d2039069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 组合训练集的特征、目标变量和Chembl ID\n",
    "train_data = pd.concat([x_chembl_id, y_train, x_train], axis=1)\n",
    "# 保存训练数据集\n",
    "train_data.to_csv('train_dataset.csv', index=False)\n",
    "\n",
    "# 组合测试集的特征、目标变量和Chembl ID\n",
    "test_data = pd.concat([y_chembl_id,y_test, x_test], axis=1)\n",
    "# 保存测试数据集\n",
    "test_data.to_csv('test_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7460048-7111-4fb8-8dac-a64dbeb29d30",
   "metadata": {},
   "source": [
    "#### 数据读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3e11561-76e6-4f4a-add1-d7ba52a240f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train-dataset-ECFPs.csv')\n",
    "data2 = pd.read_csv('test-dataset-ECFPs.csv')\n",
    "\n",
    "x_mor_train = data.iloc[:,2:]   #第三列以后的数据，Python中索引是从0开始的，读取描述符\n",
    "y_mor_train = data.iloc[:,1:2]  #左开右闭，读取第二列的数据 ，读取标签\n",
    "x_mor_test = data2.iloc[:,2:]\n",
    "y_mor_test = data2.iloc[:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f583c6e-117a-472f-8f61-02d21d106938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = x_mor_train    #x_mor_train 是输入特征，\n",
    "Y = y_mor_train    #y_mor_train 是对应的目标变量（即标签）。\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)    \n",
    "#K折交叉验证（Stratified K-Fold Cross Validation）\n",
    "#shuffle=True 表示在每次分割前都会对数据进行随机洗牌\n",
    "#random_state=0 是设置随机种子，确保结果的可重复性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd1a74b-02a3-493d-88fc-845913714a4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# AdaBoost参数搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feccb2b-d71d-4ee0-951b-9d0c486b7092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "n_estimators_range=[int(x) for x in np.linspace(start=10,stop=510,num=100)]\n",
    "def AdaBoostClassifier_model(X,Y):\n",
    "\n",
    "    # 首先实例化各个回归方法\n",
    "    AdaBoostClassifier_auto = AdaBoostClassifier(random_state=0)\n",
    "    param_dict = { \"n_estimators\":n_estimators_range,\n",
    "                  \"learning_rate\":[0,0.5,1,1.5,2],\n",
    "                 \"algorithm\":['SAMME', 'SAMME.R']}\n",
    "    estimator = GridSearchCV(estimator = AdaBoostClassifier_auto, param_grid=param_dict, cv=cv,n_jobs=-1,scoring = \"roc_auc\")\n",
    "    estimator.fit(X,Y)\n",
    "    return estimator.best_params_,estimator.best_score_,estimator.best_estimator_\n",
    "\n",
    "tmp_1,tmp_2,AdaBoostClassifier_auto = AdaBoostClassifier_model(X,Y)\n",
    "print(tmp_1,tmp_2,AdaBoostClassifier_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4570136-c8ef-4c61-b47b-1000c6303d74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tmp_1,tmp_2,AdaBoostClassifier_auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d20e46-7216-4fea-b092-dcab4174bc6c",
   "metadata": {},
   "source": [
    "### 混淆矩阵  AUC-ROC   PR-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f753f887-7831-4426-aa86-00646f50d7b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "train_X = x_mor_train\n",
    "train_Y = y_mor_train\n",
    "test_X = x_mor_test\n",
    "test_Y = y_mor_test\n",
    "\n",
    "Ada = AdaBoostClassifier(random_state = 0,\n",
    "                         algorithm = 'SAMME',\n",
    "                         learning_rate = 1,\n",
    "                         n_estimators = 510)\n",
    "\n",
    "\n",
    "estimator = Ada\n",
    "estimator.fit(train_X, train_Y)\n",
    "clf_train = estimator.predict(train_X)\n",
    "clf_test = estimator.predict(test_X)\n",
    "print(f\"训练集准确度是{accuracy_score(train_Y,clf_train)}\")\n",
    "print(f\"测试集准确度是{accuracy_score(test_Y,clf_test)}\")\n",
    "\n",
    "train_matrix = confusion_matrix(train_Y, clf_train)\n",
    "test_matrix = confusion_matrix(test_Y, clf_test)\n",
    "\n",
    "plt.rc('axes', linewidth=1.5)\n",
    "\n",
    "# 绘制热图\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)  #创建了一个包含两个子图的图形，排列方式为一行两列\n",
    "sns.heatmap(train_matrix, annot=True, cmap=\"Blues\", cbar=None,\n",
    "            fmt=\"d\")  #cbar=None 就会不显示色条,fmt=\"d\"确保中间现实数字\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title(\"Confusion Matrix of Train\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(test_matrix, annot=True, cmap=\"Blues\", cbar=None,\n",
    "            fmt=\"d\")  #cbar=None 就会不显示色条,fmt=\"d\"确保中间现实数字\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title(\"Confusion Matrix of Test\")\n",
    "plt.savefig(\"./AdaBoost/混淆矩阵_Ada.svg\", dpi = 600)\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 绘制训练集 ROC 图\n",
    "plt.subplot(1, 2, 1)\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]  # 获取训练集的预测概率\n",
    "fpr_train, tpr_train, _ = roc_curve(train_Y, y_pro_train)  # 计算 ROC 曲线的参数\n",
    "roc_auc_train = auc(fpr_train, tpr_train)  # 计算 AUC\n",
    "plt.plot(fpr_train, tpr_train, label='AdaBoost-Train (AUC = %0.3f)' % roc_auc_train)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 绘制测试集 ROC 图\n",
    "plt.subplot(1, 2, 2)\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]  # 获取测试集的预测概率\n",
    "fpr_test, tpr_test, _ = roc_curve(test_Y, y_pro_test)  # 计算 ROC 曲线的参数\n",
    "roc_auc_test = auc(fpr_test, tpr_test)  # 计算 AUC\n",
    "plt.plot(fpr_test, tpr_test, label='AdaBoost-Test (AUC = %0.3f)' % roc_auc_test)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.savefig(\"./AdaBoost/ROC_Ada.svg\", dpi=600)  # 保存图形为 SVG 格式文件\n",
    "plt.show()  # 显示图形\n",
    "\n",
    "##绘制组合图\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制 ROC 曲线\n",
    "plt.plot(fpr_train, tpr_train, color='#5D9C59',label='AdaBoost-Train (AUC = %0.3f)' % roc_auc_train)\n",
    "plt.plot(fpr_test, tpr_test,  color='#5463FF',label='AdaBoost-Test (AUC = %0.3f)' % roc_auc_test)\n",
    "# 绘制对角线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 设置标题和标签\n",
    "plt.title('AdaBoost-ECFPs', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('False Positive Rate', fontweight='bold', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontweight='bold', fontsize=15)\n",
    "plt.legend(loc='lower right')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./AdaBoost/ROC_Ada_组合.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 训练集PR_AUC图\n",
    "plt.figure(figsize=(12, 5))\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]\n",
    "precision_train, recall_train, _ = precision_recall_curve(train_Y, y_pro_train, pos_label=1)\n",
    "pr_auc_train = auc(recall_train, precision_train)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(recall_train, precision_train, label='AdaBoost-Train (PR_AUC = {:.3f})'.format(pr_auc_train))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "# 测试集PR_AUC图\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]\n",
    "precision_test, recall_test, _ = precision_recall_curve(test_Y, y_pro_test, pos_label=1)\n",
    "pr_auc_test = auc(recall_test, precision_test)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall_test, precision_test, label='AdaBoost-Test (PR_AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./AdaBoost/PR_Ada.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "## 绘制组合图\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制训练集PR_AUC图\n",
    "plt.plot(recall_train, precision_train, color='#5D9C59',label='AdaBoost-Train (PR-AUC = {:.3f})'.format(pr_auc_train))\n",
    "# 绘制测试集PR_AUC图\n",
    "plt.plot(recall_test, precision_test, color='#5463FF', label='AdaBoost-Test (PR-AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('AdaBoost-ECFPs', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Recall', fontweight='bold', fontsize=15)\n",
    "plt.ylabel('Precision', fontweight='bold', fontsize=15)\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./AdaBoost/PR_Ada_组合.svg\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e4e95f-52d4-40cb-929e-47c40cc6b460",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### ROC曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a71aa-01f9-4c80-9f37-583c566a267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 绘制训练集 ROC 图\n",
    "plt.subplot(1, 2, 1)\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]  # 获取训练集的预测概率\n",
    "fpr_train, tpr_train, _ = roc_curve(train_Y, y_pro_train)  # 计算 ROC 曲线的参数\n",
    "roc_auc_train = auc(fpr_train, tpr_train)  # 计算 AUC\n",
    "plt.plot(fpr_train, tpr_train, label='AdaBoost-Train (AUC = %0.3f)' % roc_auc_train)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "\n",
    "# 绘制测试集 ROC 图\n",
    "plt.subplot(1, 2, 2)\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]  # 获取测试集的预测概率\n",
    "fpr_test, tpr_test, _ = roc_curve(test_Y, y_pro_test)  # 计算 ROC 曲线的参数\n",
    "roc_auc_test = auc(fpr_test, tpr_test)  # 计算 AUC\n",
    "plt.plot(fpr_test, tpr_test, label='AdaBoost-Test (AUC = %0.3f)' % roc_auc_test)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.savefig(\"ROC_Ada.svg\", dpi=600)  # 保存图形为 SVG 格式文件\n",
    "plt.show()  # 显示图形\n",
    "\n",
    "##绘制组合图\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制 ROC 曲线\n",
    "plt.plot(fpr_train, tpr_train, label='AdaBoost-Train (AUC = %0.3f)' % roc_auc_train)\n",
    "plt.plot(fpr_test, tpr_test, label='AdaBoost-Test (AUC = %0.3f)' % roc_auc_test)\n",
    "# 绘制对角线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 设置标题和标签\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"ROC_Ada_组合.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 训练集PR_AUC图\n",
    "plt.figure(figsize=(12, 5))\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]\n",
    "precision_train, recall_train, _ = precision_recall_curve(train_Y, y_pro_train, pos_label=1)\n",
    "pr_auc_train = auc(recall_train, precision_train)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(recall_train, precision_train, label='AdaBoost-Train (PR_AUC = {:.3f})'.format(pr_auc_train))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "\n",
    "# 测试集PR_AUC图\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]\n",
    "precision_test, recall_test, _ = precision_recall_curve(test_Y, y_pro_test, pos_label=1)\n",
    "pr_auc_test = auc(recall_test, precision_test)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall_test, precision_test, label='AdaBoost-Test (PR_AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"PR_Ada.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制训练集PR_AUC图\n",
    "plt.plot(recall_train, precision_train, label='AdaBoost-Train (PR_AUC = {:.3f})'.format(pr_auc_train))\n",
    "# 绘制测试集PR_AUC图\n",
    "plt.plot(recall_test, precision_test, label='AdaBoost-Test (PR_AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"PR_Ada_组合.svg\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b59d728-3190-46b7-91b0-98f0e23f5abd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 绘制PR_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e958ed4a-1abe-4d67-83cc-23d89c336745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 训练集PR_AUC图\n",
    "plt.figure(figsize=(12, 5))\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]\n",
    "precision_train, recall_train, _ = precision_recall_curve(train_Y, y_pro_train, pos_label=1)\n",
    "pr_auc_train = auc(recall_train, precision_train)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(recall_train, precision_train, label='AdaBoost-Train (PR_AUC = {:.3f})'.format(pr_auc_train))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "\n",
    "# 测试集PR_AUC图\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]\n",
    "precision_test, recall_test, _ = precision_recall_curve(test_Y, y_pro_test, pos_label=1)\n",
    "pr_auc_test = auc(recall_test, precision_test)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall_test, precision_test, label='AdaBoost-Test (PR_AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"PR_Ada.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制训练集PR_AUC图\n",
    "plt.plot(recall_train, precision_train, label='AdaBoost-Train (PR_AUC = {:.3f})'.format(pr_auc_train))\n",
    "# 绘制测试集PR_AUC图\n",
    "plt.plot(recall_test, precision_test, label='AdaBoost-Test (PR_AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"PR_Ada_组合.svg\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b62183-52f8-4095-8d31-46bb51189e21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31cbcd-6338-4873-a3fb-02b1fa067d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef, make_scorer\n",
    "\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    return data\n",
    "\n",
    "def process_all_scores(score_dict, algorithm_name, folder):\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/5-CV-{metric.upper()}.csv\"\n",
    "        columns = [str(i) for i in range(len(values))]\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)\n",
    "    return results\n",
    "\n",
    "# 实际的数据和模型定义\n",
    "train_X = x_mor_train  \n",
    "train_Y = y_mor_train  \n",
    "model = Ada    #修改模型，使用在计算混淆矩阵时用的定义模型\n",
    "\n",
    "# 定义5折交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# 评分函数\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'roc_auc': 'roc_auc_ovr',\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# 执行交叉验证\n",
    "scores = cross_validate(model, train_X, train_Y, scoring=scoring, cv=cv_strategy, return_estimator=False)\n",
    "\n",
    "# 格式化分数字典以使用在处理函数中\n",
    "formatted_scores = {key[5:]: scores[key] for key in scores.keys() if key.startswith('test_')}\n",
    "\n",
    "# 处理并保存分数\n",
    "results = process_all_scores(formatted_scores, \"Ada\", \"./AdaBoost/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c344c0b-862f-46c3-b83a-6dea065e3f1e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 10折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bf5d14-7c9c-4bd4-a79b-8f5887f96b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef, make_scorer\n",
    "\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    return data\n",
    "\n",
    "def process_all_scores(score_dict, algorithm_name, folder):\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/10-CV-{metric.upper()}.csv\"\n",
    "        columns = [str(i) for i in range(len(values))]\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)\n",
    "    return results\n",
    "\n",
    "# 实际的数据和模型定义\n",
    "train_X = x_mor_train  \n",
    "train_Y = y_mor_train  \n",
    "model = Ada   ####修改模型\n",
    "\n",
    "# 定义10折交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# 评分函数\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'roc_auc': 'roc_auc_ovr',\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# 执行交叉验证\n",
    "scores = cross_validate(model, train_X, train_Y, scoring=scoring, cv=cv_strategy, return_estimator=False)\n",
    "\n",
    "# 格式化分数字典以使用在处理函数中\n",
    "formatted_scores = {key[5:]: scores[key] for key in scores.keys() if key.startswith('test_')}\n",
    "\n",
    "# 处理并保存分数\n",
    "results = process_all_scores(formatted_scores, \"Ada\", \"./AdaBoost/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c9e91f-c48e-4738-9b02-610af37518f0",
   "metadata": {},
   "source": [
    "### 在外部测试集上的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3887bf30-cc35-4795-8db2-7a93ee65c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入机器学习库scikit-learn中的Ada分类器和其他必要的工具包\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    roc_auc_score, f1_score, matthews_corrcoef, \n",
    "    make_scorer, confusion_matrix\n",
    ")\n",
    "import pandas as pd  # 导入数据处理库pandas\n",
    "import numpy as np  # 导入数值计算库numpy\n",
    "\n",
    "# 定义特异性评分函数\n",
    "def specificity_score(y_true, y_pred):\n",
    "    \"\"\"计算特异性（Specificity）.\"\"\"\n",
    "    tn, fp, _, _ = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "\n",
    "# 定义一个函数用于保存训练集交叉验证的分数到CSV文件，并且打印/保存平均值。\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    \"\"\"将交叉验证的成绩保存到CSV文件中。\"\"\"\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)  # 计算平均分并添加为新列\n",
    "    data.to_csv(file_path, index=False)  # 将DataFrame保存为CSV文件\n",
    "    print(f\"Data saved to {file_path}\")  # 打印保存信息\n",
    "    return data\n",
    "\n",
    "# 定义一个函数来处理所有成绩指标并使用`save_cv_scores`函数保存它们。\n",
    "# 修改process_all_scores函数，添加n_splits参数以反映正确的折数。\n",
    "def process_all_scores(score_dict, algorithm_name, folder, n_splits):\n",
    "    \"\"\"处理所有成绩指标并将其保存到CSV文件中。\"\"\"\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/{n_splits}-CV-{metric.upper()}.csv\"  # 使用传入的n_splits来构造文件名\n",
    "        columns = [str(i+1) for i in range(len(values))]  # 创建列名列表\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)  # 保存成绩并添加到结果字典\n",
    "    return results\n",
    "\n",
    "Ada = AdaBoostClassifier(random_state = 0,\n",
    "                         algorithm = 'SAMME',\n",
    "                         learning_rate = 1,\n",
    "                         n_estimators = 510)\n",
    "\n",
    "# 使用Ada分类器进行训练和预测。\n",
    "def train_and_evaluate(model, train_features, train_labels, test_features, test_labels):\n",
    "    \"\"\"训练模型并评估其在训练集和测试集上的性能。\"\"\"\n",
    "    model.fit(train_features, train_labels)  # 训练模型\n",
    "    clf_train_preds = model.predict(train_features)  # 在训练集上进行预测\n",
    "    clf_test_preds = model.predict(test_features)  # 在测试集上进行预测\n",
    "    # 打印训练集和测试集的准确率\n",
    "    print(f\"Training Set Accuracy: {accuracy_score(train_labels, clf_train_preds)}\")\n",
    "    print(f\"Test Set Accuracy: {accuracy_score(test_labels, clf_test_preds)}\")\n",
    "\n",
    "# 初始化用于训练和测试的特征和标签变量。\n",
    "train_X, train_Y = x_mor_train, y_mor_train  # 训练集特征和标签\n",
    "test_X, test_Y = x_mor_test, y_mor_test  # 测试集特征和标签\n",
    "\n",
    "# 执行训练和评估。\n",
    "train_and_evaluate(Ada, train_X, train_Y, test_X, test_Y)\n",
    "\n",
    "# 定义一个函数进行交叉验证和成绩的保存。\n",
    "# 修改perform_cross_validation函数的调用，传入n_splits参数。\n",
    "def perform_cross_validation(model, train_features, train_labels, n_splits, folder):\n",
    "    \"\"\"执行交叉验证和成绩处理。\"\"\"\n",
    "    cv_strategy = StratifiedKFold(n_splits=n_splits)  # 使用分层k折交叉验证\n",
    "    # 定义评分方法\n",
    "    scoring_methods = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': make_scorer(precision_score, average='macro'),\n",
    "        'recall': make_scorer(recall_score, average='macro'),\n",
    "        'roc_auc': 'roc_auc_ovr',\n",
    "        'f1': make_scorer(f1_score, average='macro'),\n",
    "        'matthews_corrcoef': make_scorer(matthews_corrcoef),\n",
    "        'specificity': make_scorer(specificity_score)  # 添加特异性评分\n",
    "    }\n",
    "    # 执行交叉验证\n",
    "    scores = cross_validate(model, train_features, train_labels, scoring=scoring_methods, cv=cv_strategy)\n",
    "    # 格式化分数并返回结果\n",
    "    formatted_scores = {key.split('_')[-1]: scores[key] for key in scores if key.startswith('test_')}\n",
    "    # 注意这里传入n_splits\n",
    "    return process_all_scores(formatted_scores, model.__class__.__name__, folder, n_splits)\n",
    "\n",
    "# 执行5折交叉验证然后是10折交叉验证。\n",
    "# 注意这里传入n_splits参数到process_all_scores函数。\n",
    "results_5_fold = perform_cross_validation(Ada, train_X, train_Y, 5, \"./AdaBoost\")  # 5折交叉验证结果\n",
    "results_10_fold = perform_cross_validation(Ada, train_X, train_Y, 10, \"./AdaBoost\")  # 10折交叉验证结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf42d40-e3fb-47e4-9918-705da755cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def train_and_evaluate(model, train_features, train_labels, test_features, test_labels, output_file):\n",
    "    \"\"\"训练模型并评估其在训练集和测试集上的性能，包括多种评估指标，并将结果保存到CSV文件。\"\"\"\n",
    "    model.fit(train_features, train_labels)  # 训练模型\n",
    "    clf_train_preds = model.predict(train_features)  # 在训练集上进行预测\n",
    "    clf_test_preds = model.predict(test_features)  # 在测试集上进行预测\n",
    "    \n",
    "    # 计算训练集上的性能指标\n",
    "    metrics = {\n",
    "        'Train_Accuracy': accuracy_score(train_labels, clf_train_preds),\n",
    "        'Train_Precision': precision_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_Recall': recall_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_F1': f1_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_MCC': matthews_corrcoef(train_labels, clf_train_preds),\n",
    "        'Train_Specificity': specificity_score(train_labels, clf_train_preds),\n",
    "        'Train_ROC_AUC': roc_auc_score(train_labels, model.predict_proba(train_features)[:, 1], multi_class='ovr'),\n",
    "        \n",
    "        'Test_Accuracy': accuracy_score(test_labels, clf_test_preds),\n",
    "        'Test_Precision': precision_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_Recall': recall_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_F1': f1_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_MCC': matthews_corrcoef(test_labels, clf_test_preds),\n",
    "        'Test_Specificity': specificity_score(test_labels, clf_test_preds),\n",
    "        'Test_ROC_AUC': roc_auc_score(test_labels, model.predict_proba(test_features)[:, 1], multi_class='ovr')\n",
    "    }\n",
    "    \n",
    "    # 将字典转换为DataFrame并保存到CSV文件\n",
    "    df = pd.DataFrame([metrics])\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Metrics saved to {output_file}\")\n",
    "\n",
    "# 执行训练和评估，输出结果\n",
    "train_and_evaluate(Ada, train_X, train_Y, test_X, test_Y,\"./AdaBoost/训练和评估.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca133cb-2ecb-40c6-b69b-c2362bd8dd4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "estimator = Ada\n",
    "estimator.fit(train_X, train_Y)\n",
    "clf_test = estimator.predict(test_X)\n",
    "acc_test = accuracy_score(test_Y,clf_test) \n",
    "roc_test = roc_auc_score(test_Y,clf_test)\n",
    "pre_test = precision_score(test_Y,clf_test)\n",
    "rec_test = recall_score(test_Y,clf_test)\n",
    "f1_test = f1_score(test_Y,clf_test)\n",
    "mcc_test = matthews_corrcoef(test_Y,clf_test)\n",
    "matrix_test = confusion_matrix(test_Y,clf_test)\n",
    "ap_test = average_precision_score(test_Y,clf_test)\n",
    "\n",
    "algorithm_model = [Ada]\n",
    "algorithm_name = [\"AdaBoost\"]\n",
    "tmp_1 = np.zeros((1,2))\n",
    "Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(2))\n",
    "tmp_2 = np.zeros((1,2))\n",
    "Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(2))\n",
    "tmp_3 = np.zeros((1,2))\n",
    "Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(2))  \n",
    "tmp_4 = np.zeros((1,2))\n",
    "Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(2)) \n",
    "tmp_5 = np.zeros((1,2))\n",
    "F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(2))\n",
    "tmp_6 = np.zeros((1,2))\n",
    "MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(2))\n",
    "tmp_7 = np.zeros((1,2))\n",
    "Ap_data = pd.DataFrame(tmp_7,index=algorithm_name,columns=range(2))\n",
    "\n",
    "Auc_data.loc[algorithm_name]  = roc_test\n",
    "Acc_data.loc[algorithm_name]  = acc_test\n",
    "Recall_data.loc[algorithm_name] = rec_test\n",
    "Precision_data.loc[algorithm_name] = pre_test\n",
    "F1_data.loc[algorithm_name]  = f1_test\n",
    "MCC_data.loc[algorithm_name]  = mcc_test\n",
    "Ap_data.loc[algorithm_name]  = ap_test\n",
    "\n",
    "Auc_data.to_csv(\"./AdaBoost/test_ROC.csv\")\n",
    "Acc_data.to_csv(\"./AdaBoost/test_ACC.csv\")\n",
    "Recall_data.to_csv(\"./AdaBoost/test_REC.csv\")\n",
    "Precision_data.to_csv(\"./AdaBoost/test_PRE.csv\")\n",
    "F1_data.to_csv(\"./AdaBoost/test_F1.csv\")\n",
    "MCC_data.to_csv(\"./AdaBoost/test_MCC.csv\")\n",
    "Ap_data.to_csv(\"./AdaBoost/test_AP.csv\")\n",
    "\n",
    "clf_train = estimator.predict(train_X)\n",
    "acc_train = accuracy_score(train_Y,clf_train)\n",
    "roc_train = roc_auc_score(train_Y,clf_train)\n",
    "pre_train = precision_score(train_Y,clf_train)\n",
    "rec_train = recall_score(train_Y,clf_train)\n",
    "f1_train = f1_score(train_Y,clf_train)\n",
    "mcc_train = matthews_corrcoef(train_Y,clf_train)\n",
    "matrix_train = confusion_matrix(train_Y,clf_train)\n",
    "ap_train = average_precision_score(train_Y,clf_train)\n",
    "\n",
    "tmp_1 = np.zeros((1,2))\n",
    "Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(2))\n",
    "tmp_2 = np.zeros((1,2))\n",
    "Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(2))\n",
    "tmp_3 = np.zeros((1,2))\n",
    "Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(2))  \n",
    "tmp_4 = np.zeros((1,2))\n",
    "Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(2)) \n",
    "tmp_5 = np.zeros((1,2))\n",
    "F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(2))\n",
    "tmp_6 = np.zeros((1,2))\n",
    "MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(2))\n",
    "tmp_7 = np.zeros((1,2))\n",
    "Ap_data = pd.DataFrame(tmp_7,index=algorithm_name,columns=range(2))\n",
    "\n",
    "Auc_data.loc[algorithm_name]  = roc_train\n",
    "Acc_data.loc[algorithm_name]  = acc_train\n",
    "Recall_data.loc[algorithm_name] = rec_train\n",
    "Precision_data.loc[algorithm_name] = pre_train\n",
    "F1_data.loc[algorithm_name]  = f1_train\n",
    "MCC_data.loc[algorithm_name]  = mcc_train\n",
    "Ap_data.loc[algorithm_name]  = ap_train\n",
    "\n",
    "Auc_data.to_csv(\"./AdaBoost/train_ROC.csv\")\n",
    "Acc_data.to_csv(\"./AdaBoost/train_ACC.csv\")\n",
    "Recall_data.to_csv(\"./AdaBoost/train_REC.csv\")\n",
    "Precision_data.to_csv(\"./AdaBoost/train_PRE.csv\")\n",
    "F1_data.to_csv(\"./AdaBoost/train_F1.csv\")\n",
    "MCC_data.to_csv(\"./AdaBoost/train_MCC.csv\")\n",
    "Ap_data.to_csv(\"./AdaBoost/train_AP.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591fd73b-37fc-42bc-a1c8-bcbb05ee9e94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# DT参数搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc4522c-7ea6-4bd8-884f-d734e264f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "max_depth_range=[int(x) for x in np.linspace(5,20,num=5)]\n",
    "min_samples_split_range=[int(x) for x in np.linspace(5,25,num=5)]\n",
    "min_samples_leaf_range=[3,4,5,6,7]\n",
    "def DecisionTreeClassifier_model(X,Y): \n",
    "\n",
    "    # 首先实例化各个回归方法\n",
    "    DecisionTreeClassifier_auto = DecisionTreeClassifier(random_state=0)\n",
    "    param_dict = {\n",
    "                'max_depth':max_depth_range,\n",
    "                'min_samples_split':min_samples_split_range,\n",
    "                'min_samples_leaf':min_samples_leaf_range,\n",
    "                 }\n",
    "    estimator = GridSearchCV(estimator = DecisionTreeClassifier_auto, param_grid=param_dict, cv=cv,n_jobs=-1,scoring = \"roc_auc\")\n",
    "    estimator.fit(X,Y)\n",
    "    return estimator.best_params_,estimator.best_score_,estimator.best_estimator_\n",
    "\n",
    "tmp_1,tmp_2,DecisionTreeClassifier_auto = DecisionTreeClassifier_model(X,Y)\n",
    "print(tmp_1,tmp_2,DecisionTreeClassifier_auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9564a1e2-9f41-4e04-b7b6-8cbf6979688e",
   "metadata": {},
   "source": [
    "### 混淆矩阵  AUC-ROC   PR-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6909dbb-933c-4deb-8850-5f43bd20baf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X = x_mor_train\n",
    "train_Y = y_mor_train\n",
    "test_X = x_mor_test\n",
    "test_Y = y_mor_test\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DT = DecisionTreeClassifier(random_state = 0,\n",
    "                            class_weight = 'balanced',\n",
    "                            criterion = 'gini',\n",
    "                            max_features = 'sqrt',\n",
    "                            splitter = 'best',\n",
    "                            max_depth = 8,\n",
    "                           min_samples_leaf = 6,\n",
    "                           min_samples_split = 15)\n",
    "estimator = DT\n",
    "estimator.fit(train_X, train_Y)\n",
    "clf_train = estimator.predict(train_X)\n",
    "clf_test = estimator.predict(test_X)\n",
    "print(f\"训练集准确度是{accuracy_score(train_Y,clf_train)}\")\n",
    "print(f\"测试集准确度是{accuracy_score(test_Y,clf_test)}\")\n",
    "\n",
    "train_matrix = confusion_matrix(train_Y, clf_train)\n",
    "test_matrix = confusion_matrix(test_Y, clf_test)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(train_matrix, annot=True, cmap=\"Blues\", cbar=None,\n",
    "            fmt=\"d\")  #cbar=None 就会不显示色条,fmt=\"d\"确保中间现实数字\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title(\"Confusion Matrix of Train\")\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(test_matrix, annot=True, cmap=\"Blues\", cbar=None,\n",
    "            fmt=\"d\")  #cbar=None 就会不显示色条,fmt=\"d\"确保中间现实数字\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title(\"Confusion Matrix of Test\")\n",
    "plt.savefig(\"./DT/混淆矩阵_DT.svg\", dpi = 600)\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 绘制训练集 ROC 图\n",
    "plt.subplot(1, 2, 1)\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]  # 获取训练集的预测概率\n",
    "fpr_train, tpr_train, _ = roc_curve(train_Y, y_pro_train)  # 计算 ROC 曲线的参数\n",
    "roc_auc_train = auc(fpr_train, tpr_train)  # 计算 AUC\n",
    "plt.plot(fpr_train, tpr_train, label='DT-Train (AUC = %0.3f)' % roc_auc_train)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 绘制测试集 ROC 图\n",
    "plt.subplot(1, 2, 2)\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]  # 获取测试集的预测概率\n",
    "fpr_test, tpr_test, _ = roc_curve(test_Y, y_pro_test)  # 计算 ROC 曲线的参数\n",
    "roc_auc_test = auc(fpr_test, tpr_test)  # 计算 AUC\n",
    "plt.plot(fpr_test, tpr_test, label='DT-Test (AUC = %0.3f)' % roc_auc_test)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.savefig(\"./DT/ROC_DT.svg\", dpi=600)  # 保存图形为 SVG 格式文件\n",
    "plt.show()  # 显示图形\n",
    "\n",
    "##绘制组合图\n",
    "plt.figure(figsize=(5, 5))   \n",
    "# 绘制 ROC 曲线\n",
    "plt.plot(fpr_train, tpr_train, color='#5D9C59', label='DT-Train (AUC = %0.3f)' % roc_auc_train)\n",
    "plt.plot(fpr_test, tpr_test,color='#5463FF', label='DT-Test (AUC = %0.3f)' % roc_auc_test)\n",
    "# 绘制对角线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 设置标题和标签\n",
    "plt.title('DT-PubchemFPs')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./DT/ROC_DT_组合.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 训练集PR_AUC图\n",
    "plt.figure(figsize=(12, 5))\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]\n",
    "precision_train, recall_train, _ = precision_recall_curve(train_Y, y_pro_train, pos_label=1)\n",
    "pr_auc_train = auc(recall_train, precision_train)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(recall_train, precision_train, label='DT-Train (PR_AUC = {:.3f})'.format(pr_auc_train))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "# 测试集PR_AUC图\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]\n",
    "precision_test, recall_test, _ = precision_recall_curve(test_Y, y_pro_test, pos_label=1)\n",
    "pr_auc_test = auc(recall_test, precision_test)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall_test, precision_test, label='DT-Test (PR_AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./DT/PR_DT.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制训练集PR_AUC图\n",
    "plt.plot(recall_train, precision_train,color='#5D9C59', label='DT-Train (PR_AUC = {:.3f})'.format(pr_auc_train))\n",
    "# 绘制测试集PR_AUC图\n",
    "plt.plot(recall_test, precision_test,color='#5463FF', label='DT-Test (PR_AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./DT/PR_DT_组合.svg\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797f28d8-7784-4a9f-81b9-59d32f795712",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42db443-34f2-4749-aadd-6bbd31a7513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 绘制训练集 ROC 图\n",
    "plt.subplot(1, 2, 1)\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]  # 获取训练集的预测概率\n",
    "fpr_train, tpr_train, _ = roc_curve(train_Y, y_pro_train)  # 计算 ROC 曲线的参数\n",
    "roc_auc_train = auc(fpr_train, tpr_train)  # 计算 AUC\n",
    "plt.plot(fpr_train, tpr_train, label='DT-Train (AUC = %0.3f)' % roc_auc_train)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "\n",
    "# 绘制测试集 ROC 图\n",
    "plt.subplot(1, 2, 2)\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]  # 获取测试集的预测概率\n",
    "fpr_test, tpr_test, _ = roc_curve(test_Y, y_pro_test)  # 计算 ROC 曲线的参数\n",
    "roc_auc_test = auc(fpr_test, tpr_test)  # 计算 AUC\n",
    "plt.plot(fpr_test, tpr_test, label='DT-Test (AUC = %0.3f)' % roc_auc_test)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.savefig(\"ROC_DT.svg\", dpi=600)  # 保存图形为 SVG 格式文件\n",
    "plt.show()  # 显示图形\n",
    "\n",
    "##绘制组合图\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制 ROC 曲线\n",
    "plt.plot(fpr_train, tpr_train, label='DT-Train (AUC = %0.3f)' % roc_auc_train)\n",
    "plt.plot(fpr_test, tpr_test, label='DT-Test (AUC = %0.3f)' % roc_auc_test)\n",
    "# 绘制对角线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 设置标题和标签\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"ROC_DT_组合.svg\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613479d0-896d-42b4-bcb6-fa2a6cae3dd6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### PR_AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6299b443-bc5c-4f23-b8cf-b20acb511e0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 训练集PR_AUC图\n",
    "plt.figure(figsize=(12, 5))\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]\n",
    "precision_train, recall_train, _ = precision_recall_curve(train_Y, y_pro_train, pos_label=1)\n",
    "pr_auc_train = auc(recall_train, precision_train)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(recall_train, precision_train, label='DT-Train (PR_AUC = {:.3f})'.format(pr_auc_train))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "\n",
    "# 测试集PR_AUC图\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]\n",
    "precision_test, recall_test, _ = precision_recall_curve(test_Y, y_pro_test, pos_label=1)\n",
    "pr_auc_test = auc(recall_test, precision_test)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall_test, precision_test, label='DT-Test (PR_AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"PR_DT.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制训练集PR_AUC图\n",
    "plt.plot(recall_train, precision_train, label='DT-Train (PR_AUC = {:.3f})'.format(pr_auc_train))\n",
    "# 绘制测试集PR_AUC图\n",
    "plt.plot(recall_test, precision_test, label='DT-Test (PR_AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"PR_DT_组合.svg\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2034bca7-c844-4fac-9055-a5352daef5d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c27cbb-cc59-4d01-9488-f023c63a5cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef, make_scorer\n",
    "\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    return data\n",
    "\n",
    "def process_all_scores(score_dict, algorithm_name, folder):\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/5-CV-{metric.upper()}.csv\"\n",
    "        columns = [str(i) for i in range(len(values))]\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)\n",
    "    return results\n",
    "\n",
    "# 实际的数据和模型定义\n",
    "train_X = x_mor_train  \n",
    "train_Y = y_mor_train  \n",
    "model = DT   \n",
    "\n",
    "# 定义5折交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# 评分函数\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'roc_auc': 'roc_auc_ovr',\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# 执行交叉验证\n",
    "scores = cross_validate(model, train_X, train_Y, scoring=scoring, cv=cv_strategy, return_estimator=False)\n",
    "\n",
    "# 格式化分数字典以使用在处理函数中\n",
    "formatted_scores = {key[5:]: scores[key] for key in scores.keys() if key.startswith('test_')}\n",
    "\n",
    "# 处理并保存分数\n",
    "results = process_all_scores(formatted_scores, \"DT\", \"./DT/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5fe142-2d67-4285-bccb-7727a599827c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 10折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8469d25b-21cf-4441-b17f-c384ef25711f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef, make_scorer\n",
    "\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    return data\n",
    "\n",
    "def process_all_scores(score_dict, algorithm_name, folder):\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/10-CV-{metric.upper()}.csv\"\n",
    "        columns = [str(i) for i in range(len(values))]\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)\n",
    "    return results\n",
    "\n",
    "# 实际的数据和模型定义\n",
    "train_X = x_mor_train  \n",
    "train_Y = y_mor_train  \n",
    "model = DT   ####修改模型\n",
    "\n",
    "# 定义10折交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# 评分函数\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'roc_auc': 'roc_auc_ovr',\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# 执行交叉验证\n",
    "scores = cross_validate(model, train_X, train_Y, scoring=scoring, cv=cv_strategy, return_estimator=False)\n",
    "\n",
    "# 格式化分数字典以使用在处理函数中\n",
    "formatted_scores = {key[5:]: scores[key] for key in scores.keys() if key.startswith('test_')}\n",
    "\n",
    "# 处理并保存分数\n",
    "results = process_all_scores(formatted_scores, \"DT\", \"./DT/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d174d554-f1d8-41a0-a886-f6da00b7a0e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 在外部测试集的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd51ecd-b79e-4650-a595-fb79f5e8c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "estimator = DT\n",
    "estimator.fit(train_X, train_Y)\n",
    "clf_test = estimator.predict(test_X)\n",
    "acc_test = accuracy_score(test_Y,clf_test)\n",
    "roc_test = roc_auc_score(test_Y,clf_test)\n",
    "pre_test = precision_score(test_Y,clf_test)\n",
    "rec_test = recall_score(test_Y,clf_test)\n",
    "f1_test = f1_score(test_Y,clf_test)\n",
    "mcc_test = matthews_corrcoef(test_Y,clf_test)\n",
    "matrix_test = confusion_matrix(test_Y,clf_test)\n",
    "ap_test = average_precision_score(test_Y,clf_test)\n",
    "\n",
    "algorithm_model = [DT]\n",
    "algorithm_name = [\"DecisionTree\"]\n",
    "tmp_1 = np.zeros((1,2))\n",
    "Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(2))\n",
    "tmp_2 = np.zeros((1,2))\n",
    "Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(2))\n",
    "tmp_3 = np.zeros((1,2))\n",
    "Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(2))  \n",
    "tmp_4 = np.zeros((1,2))\n",
    "Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(2)) \n",
    "tmp_5 = np.zeros((1,2))\n",
    "F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(2))\n",
    "tmp_6 = np.zeros((1,2))\n",
    "MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(2))\n",
    "tmp_7 = np.zeros((1,2))\n",
    "Ap_data = pd.DataFrame(tmp_7,index=algorithm_name,columns=range(2))\n",
    "\n",
    "Auc_data.loc[algorithm_name]  = roc_test\n",
    "Acc_data.loc[algorithm_name]  = acc_test\n",
    "Recall_data.loc[algorithm_name] = rec_test\n",
    "Precision_data.loc[algorithm_name] = pre_test\n",
    "F1_data.loc[algorithm_name]  = f1_test\n",
    "MCC_data.loc[algorithm_name]  = mcc_test\n",
    "Ap_data.loc[algorithm_name]  = ap_test\n",
    "\n",
    "Auc_data.to_csv(\"./DT/test_ROC.csv\")\n",
    "Acc_data.to_csv(\"./DT/test_ACC.csv\")\n",
    "Recall_data.to_csv(\"./DT/test_REC.csv\")\n",
    "Precision_data.to_csv(\"./DT/test_PRE.csv\")\n",
    "F1_data.to_csv(\"./DT/test_F1.csv\")\n",
    "MCC_data.to_csv(\"./DT/test_MCC.csv\")\n",
    "Ap_data.to_csv(\"./DT/test_AP.csv\")\n",
    "\n",
    "clf_train = estimator.predict(train_X)\n",
    "acc_train = accuracy_score(train_Y,clf_train)\n",
    "roc_train = roc_auc_score(train_Y,clf_train)\n",
    "pre_train = precision_score(train_Y,clf_train)\n",
    "rec_train = recall_score(train_Y,clf_train)\n",
    "f1_train = f1_score(train_Y,clf_train)\n",
    "mcc_train = matthews_corrcoef(train_Y,clf_train)\n",
    "matrix_train = confusion_matrix(train_Y,clf_train)\n",
    "ap_train = average_precision_score(train_Y,clf_train)\n",
    "\n",
    "tmp_1 = np.zeros((1,2))\n",
    "Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(2))\n",
    "tmp_2 = np.zeros((1,2))\n",
    "Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(2))\n",
    "tmp_3 = np.zeros((1,2))\n",
    "Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(2))  \n",
    "tmp_4 = np.zeros((1,2))\n",
    "Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(2)) \n",
    "tmp_5 = np.zeros((1,2))\n",
    "F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(2))\n",
    "tmp_6 = np.zeros((1,2))\n",
    "MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(2))\n",
    "tmp_7 = np.zeros((1,2))\n",
    "Ap_data = pd.DataFrame(tmp_7,index=algorithm_name,columns=range(2))\n",
    "\n",
    "Auc_data.loc[algorithm_name]  = roc_train\n",
    "Acc_data.loc[algorithm_name]  = acc_train\n",
    "Recall_data.loc[algorithm_name] = rec_train\n",
    "Precision_data.loc[algorithm_name] = pre_train\n",
    "F1_data.loc[algorithm_name]  = f1_train\n",
    "MCC_data.loc[algorithm_name]  = mcc_train\n",
    "Ap_data.loc[algorithm_name]  = ap_train\n",
    "\n",
    "Auc_data.to_csv(\"./DT/train_ROC.csv\")\n",
    "Acc_data.to_csv(\"./DT/train_ACC.csv\")\n",
    "Recall_data.to_csv(\"./DT/train_REC.csv\")\n",
    "Precision_data.to_csv(\"./DT/train_PRE.csv\")\n",
    "F1_data.to_csv(\"./DT/train_F1.csv\")\n",
    "MCC_data.to_csv(\"./DT/train_MCC.csv\")\n",
    "Ap_data.to_csv(\"./DT/train_AP.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f394d5da-de38-4a32-8275-0765dfefdb33",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# GBT参数搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d257d9da-2043-40b7-a762-e1346079d7d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# n_estimators_range=[int(x) for x in np.linspace(start=10,stop=210,num=100)]\n",
    "# max_depth_range=[int(x) for x in np.linspace(5,20,num=5)]\n",
    "# min_samples_split_range=[int(x) for x in np.linspace(5,25,num=5)]\n",
    "# min_samples_leaf_range=[3,4,5,6,7]\n",
    "# def GradientBoostingClassifier_model(X,Y):\n",
    "    \n",
    "#     # 首先实例化各个回归方法\n",
    "#     GradientBoostingClassifier_auto = GradientBoostingClassifier(random_state=0)\n",
    "#     param_dict = {\n",
    "#                   'n_estimators':n_estimators_range,\n",
    "#                     'max_depth':max_depth_range,\n",
    "#                     'min_samples_split':min_samples_split_range,\n",
    "#                     'min_samples_leaf':min_samples_leaf_range,\n",
    "#                     \"criterion\":['friedman_mse', 'mse',\"mae\"],\n",
    "#                     \"max_features\":[\"auto\",\"sqrt\",\"log2\"],\n",
    "#                  \"learning_rate\":[0,0.5,1],\n",
    "#                  }\n",
    "#     estimator = GridSearchCV(estimator = GradientBoostingClassifier_auto, param_grid=param_dict, cv=cv,n_jobs=-1,scoring = \"accuracy\")\n",
    "#     estimator.fit(X,Y)\n",
    "#     return estimator.best_params_,estimator.best_score_,estimator.best_estimator_\n",
    "\n",
    "# tmp_1,tmp_2,GradientBoostingClassifier_auto = GradientBoostingClassifier_model(X,Y)\n",
    "# print(tmp_1,tmp_2,GradientBoostingClassifier_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162fa4e4-8100-420c-9387-4f96f762c9b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from time import time\n",
    "begin_time = time()\n",
    "# Search optimal hyperparameter\n",
    "n_estimators_range=[int(x) for x in np.linspace(start=10,stop=210,num=10)]\n",
    "max_depth_range=[int(x) for x in np.linspace(5,20,num=5)]\n",
    "min_samples_split_range=[int(x) for x in np.linspace(5,20,num=5)]\n",
    "min_samples_leaf_range=[3,4,5,6,7]\n",
    "# max_features=['sqrt','log2']\n",
    "# min_samples_leaf=\n",
    "GtBossT = GradientBoostingClassifier(random_state=0)\n",
    "random_forest_hp_range={'n_estimators':n_estimators_range,\n",
    "                        'max_depth':max_depth_range,\n",
    "                        'min_samples_split':min_samples_split_range,\n",
    "                        'min_samples_leaf':min_samples_leaf_range,\n",
    "                        \"criterion\":['friedman_mse', 'squared_error'],\n",
    "                        \"max_features\":[\"auto\",\"sqrt\",\"log2\"]\n",
    "                       }\n",
    "print(random_forest_hp_range)\n",
    "\n",
    "estimator_all_roc = GridSearchCV(estimator=GtBossT,\n",
    "                                 param_grid=random_forest_hp_range,\n",
    "                                 cv=cv,\n",
    "                                 n_jobs=-1,\n",
    "                                 scoring=\"roc_auc\",verbose=1)\n",
    "# %%time\n",
    "estimator_all_roc.fit(X, Y)\n",
    "end_time = time()\n",
    "print({end_time - begin_time})\n",
    "print(estimator_all_roc.best_params_)\n",
    "print(estimator_all_roc.best_score_)\n",
    "tmp = pd.DataFrame(estimator_all_roc.cv_results_)\n",
    "df_fig = tmp[[\"mean_test_score\",\"params\"]]\n",
    "df_fig.to_csv(\"./GBDT/tmp2.csv\",index=False)\n",
    "df_fig[\"n_estimators\"] = 1\n",
    "df_fig['max_depth'] = 1\n",
    "df_fig[\"min_samples_split\"] = 1\n",
    "df_fig['min_samples_leaf']=1\n",
    "for i in range(0,df_fig.shape[0]):\n",
    "    dict_tmp = df_fig[\"params\"].iloc[i]\n",
    "    df_fig[\"n_estimators\"].iloc[i] = dict_tmp[\"n_estimators\"]\n",
    "    df_fig[\"max_depth\"].iloc[i] = dict_tmp[\"max_depth\"]\n",
    "    df_fig[\"min_samples_split\"].iloc[i] = dict_tmp[\"min_samples_split\"]\n",
    "    df_fig['min_samples_leaf'].iloc[i]=dict_tmp['min_samples_leaf']\n",
    "    \n",
    "df_fig.head(50)\n",
    "df_fig.to_csv(\"./GBDT/网格搜索结果GBDT.csv\",index=False)\n",
    "df_fig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f430091-8017-4554-95da-2cb316db624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimator_all_roc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d032837-30bb-4fbf-bffc-12cc0242d2dd",
   "metadata": {},
   "source": [
    "### ROC和PR_AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8efb39-b266-47dc-9250-080dd5c36d4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X = x_mor_train\n",
    "train_Y = y_mor_train\n",
    "test_X = x_mor_test\n",
    "test_Y = y_mor_test\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GBT = GradientBoostingClassifier(random_state = 0,\n",
    "                            criterion = 'friedman_mse',\n",
    "                            max_depth = 12,\n",
    "                            max_features = 'sqrt',\n",
    "                            min_samples_leaf = 3,\n",
    "                            min_samples_split = 5,\n",
    "                            n_estimators = 76)\n",
    "\n",
    "estimator = GBT\n",
    "estimator.fit(train_X, train_Y)\n",
    "clf_train = estimator.predict(train_X)\n",
    "clf_test = estimator.predict(test_X)\n",
    "print(f\"训练集准确度是{accuracy_score(train_Y,clf_train)}\")\n",
    "print(f\"测试集准确度是{accuracy_score(test_Y,clf_test)}\")\n",
    "train_matrix = confusion_matrix(train_Y, clf_train)\n",
    "test_matrix = confusion_matrix(test_Y, clf_test)\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "plt.rc('axes', linewidth=1.5)  # 设置边框宽度\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(train_matrix, annot=True, cmap=\"Blues\", cbar=None,fmt=\"d\")  \n",
    "#cbar=None 就会不显示色条,fmt=\"d\"确保中间现实数字\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title(\"Confusion Matrix of Train\")\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(test_matrix, annot=True, cmap=\"Blues\", cbar=None,fmt=\"d\")  \n",
    "#cbar=None 就会不显示色条,fmt=\"d\"确保中间现实数字\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title(\"Confusion Matrix of Test\")\n",
    "plt.savefig(\"./GBDT/混淆矩阵_GBT.svg\", dpi = 600)\n",
    "plt.show()\n",
    "\n",
    "#########  ROC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "# 绘制训练集 ROC 图\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.rc('axes', linewidth=1.5) \n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]  # 获取训练集的预测概率\n",
    "fpr_train, tpr_train, _ = roc_curve(train_Y, y_pro_train)  # 计算 ROC 曲线的参数\n",
    "roc_auc_train = auc(fpr_train, tpr_train)  # 计算 AUC\n",
    "plt.plot(fpr_train, tpr_train, label='GBDT-Train (AUC = %0.3f)' % roc_auc_train)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 绘制测试集 ROC 图\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.rc('axes', linewidth=1.5) \n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]  # 获取测试集的预测概率\n",
    "fpr_test, tpr_test, _ = roc_curve(test_Y, y_pro_test)  # 计算 ROC 曲线的参数\n",
    "roc_auc_test = auc(fpr_test, tpr_test)  # 计算 AUC\n",
    "plt.plot(fpr_test, tpr_test, label='GBDT-Test (AUC = %0.3f)' % roc_auc_test)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.savefig(\"./GBDT/ROC_GBT.svg\", dpi=600)  # 保存图形为 SVG 格式文件\n",
    "plt.show()  # 显示图形\n",
    "\n",
    "##绘制组合图\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.rc('axes', linewidth=1.5) \n",
    "# 绘制 ROC 曲线\n",
    "plt.plot(fpr_train, tpr_train,color='#5D9C59', label='GBDT-Train (AUC = %0.3f)' % roc_auc_train)\n",
    "plt.plot(fpr_test, tpr_test,color='#5463FF', label='GBDT-Test (AUC = %0.3f)' % roc_auc_test)\n",
    "# 绘制对角线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 设置标题和标签\n",
    "plt.title('GBDT-ECFPs', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('False Positive Rate', fontweight='bold', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontweight='bold', fontsize=15)\n",
    "plt.legend(loc='lower right')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./GBDT/ROC_GBT_组合.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "# 训练集PR_AUC图\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.rc('axes', linewidth=1.5) \n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]\n",
    "precision_train, recall_train, _ = precision_recall_curve(train_Y, y_pro_train, pos_label=1)\n",
    "pr_auc_train = auc(recall_train, precision_train)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(recall_train, precision_train, label='GBT-Train (PR_AUC = {:.3f})'.format(pr_auc_train))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "# 测试集PR_AUC图\n",
    "plt.rc('axes', linewidth=1.5) \n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]\n",
    "precision_test, recall_test, _ = precision_recall_curve(test_Y, y_pro_test, pos_label=1)\n",
    "pr_auc_test = auc(recall_test, precision_test)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall_test, precision_test, label='GBT-Test (PR_AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./GBDT/PR_GBT.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.rc('axes', linewidth=1.5) \n",
    "# 绘制训练集PR_AUC图\n",
    "plt.plot(recall_train, precision_train,color='#5D9C59', label='GBDT-Train (PR-AUC = {:.3f})'.format(pr_auc_train))\n",
    "# 绘制测试集PR_AUC图\n",
    "plt.plot(recall_test, precision_test,color='#5463FF', label='GBDT-Test (PR-AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('GBDT-ECFPs', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Recall', fontweight='bold', fontsize=15)\n",
    "plt.ylabel('Precision', fontweight='bold', fontsize=15)\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./GBDT/PR_GBT_组合.svg\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "420cf48a-a627-48a2-acd5-886376577dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GBDT 模型训练完成，并已保存为 GBDT-ECFPs.pkl！\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# 训练 GBDT 模型\n",
    "GBT = GradientBoostingClassifier(random_state=0,\n",
    "                                 criterion='friedman_mse',\n",
    "                                 max_depth=12,\n",
    "                                 max_features='sqrt',\n",
    "                                 min_samples_leaf=3,\n",
    "                                 min_samples_split=5,\n",
    "                                 n_estimators=76)\n",
    "\n",
    "# 训练 GBDT 模型\n",
    "GBT.fit(x_mor_train, y_mor_train.values.ravel())  # 确保 y_train 是 1D 数组\n",
    "\n",
    "joblib.dump(GBT, \"GBDT-ECFPs.pkl\")  # 保存模型\n",
    "\n",
    "print(\"✅ GBDT 模型训练完成，并已保存为 GBDT-ECFPs.pkl！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e58ae64d-ccd3-425a-9cad-2e561c83fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "model = joblib.load(\"GBDT-ECFPs.pkl\")  # 使用 joblib 加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f8841e0-71a0-4842-8c95-4297e81d8a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model))  # 应该输出 <class 'sklearn.ensemble._gb.GradientBoostingClassifier'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2fcef6-ca97-4484-bcd9-621dd73bc620",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f0705-f279-4809-9f78-04f587e894df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef, make_scorer\n",
    "\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    return data\n",
    "\n",
    "def process_all_scores(score_dict, algorithm_name, folder):\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/5-CV-{metric.upper()}.csv\"\n",
    "        columns = [str(i) for i in range(len(values))]\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)\n",
    "    return results\n",
    "\n",
    "# 实际的数据和模型定义\n",
    "train_X = x_mor_train  \n",
    "train_Y = y_mor_train  \n",
    "model = GBT   \n",
    "\n",
    "# 定义5折交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# 评分函数\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'roc_auc': 'roc_auc_ovr',\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# 执行交叉验证\n",
    "scores = cross_validate(model, train_X, train_Y, scoring=scoring, cv=cv_strategy, return_estimator=False)\n",
    "\n",
    "# 格式化分数字典以使用在处理函数中\n",
    "formatted_scores = {key[5:]: scores[key] for key in scores.keys() if key.startswith('test_')}\n",
    "\n",
    "# 处理并保存分数\n",
    "results = process_all_scores(formatted_scores, \"GBT\", \"./GBT/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac34a57d-55d7-450b-b4a3-9e0629386282",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 10折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e89ff1-359e-4ac6-814e-4510bbc39d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef, make_scorer\n",
    "\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    return data\n",
    "\n",
    "def process_all_scores(score_dict, algorithm_name, folder):\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/10-CV-{metric.upper()}.csv\"\n",
    "        columns = [str(i) for i in range(len(values))]\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)\n",
    "    return results\n",
    "\n",
    "# 实际的数据和模型定义\n",
    "train_X = x_mor_train  \n",
    "train_Y = y_mor_train  \n",
    "model = GBT   ####修改模型\n",
    "\n",
    "# 定义10折交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# 评分函数\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'roc_auc': 'roc_auc_ovr',\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# 执行交叉验证\n",
    "scores = cross_validate(model, train_X, train_Y, scoring=scoring, cv=cv_strategy, return_estimator=False)\n",
    "\n",
    "# 格式化分数字典以使用在处理函数中\n",
    "formatted_scores = {key[5:]: scores[key] for key in scores.keys() if key.startswith('test_')}\n",
    "\n",
    "# 处理并保存分数\n",
    "results = process_all_scores(formatted_scores, \"GBT\", \"./GBT/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f93fbe8-11bd-46fb-8786-1ea31864a5f9",
   "metadata": {},
   "source": [
    "### 在外部测试集的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ced5535-1c21-4b9a-ae69-b348ce5d95a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入机器学习库scikit-learn中的GBT分类器和其他必要的工具包\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    roc_auc_score, f1_score, matthews_corrcoef, \n",
    "    make_scorer, confusion_matrix\n",
    ")\n",
    "import pandas as pd  # 导入数据处理库pandas\n",
    "import numpy as np  # 导入数值计算库numpy\n",
    "\n",
    "# 定义特异性评分函数\n",
    "def specificity_score(y_true, y_pred):\n",
    "    \"\"\"计算特异性（Specificity）.\"\"\"\n",
    "    tn, fp, _, _ = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "\n",
    "# 定义一个函数用于保存训练集交叉验证的分数到CSV文件，并且打印/保存平均值。\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    \"\"\"将交叉验证的成绩保存到CSV文件中。\"\"\"\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)  # 计算平均分并添加为新列\n",
    "    data.to_csv(file_path, index=False)  # 将DataFrame保存为CSV文件\n",
    "    print(f\"Data saved to {file_path}\")  # 打印保存信息\n",
    "    return data\n",
    "\n",
    "# 定义一个函数来处理所有成绩指标并使用`save_cv_scores`函数保存它们。\n",
    "# 修改process_all_scores函数，添加n_splits参数以反映正确的折数。\n",
    "def process_all_scores(score_dict, algorithm_name, folder, n_splits):\n",
    "    \"\"\"处理所有成绩指标并将其保存到CSV文件中。\"\"\"\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/{n_splits}-CV-{metric.upper()}.csv\"  # 使用传入的n_splits来构造文件名\n",
    "        columns = [str(i+1) for i in range(len(values))]  # 创建列名列表\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)  # 保存成绩并添加到结果字典\n",
    "    return results\n",
    "\n",
    "# 定义梯度提升树模型，设置好超参数\n",
    "GBDT = GradientBoostingClassifier(random_state = 0,\n",
    "                            criterion = 'friedman_mse',\n",
    "                            max_depth = 12,\n",
    "                            max_features = 'sqrt',\n",
    "                            min_samples_leaf = 3,\n",
    "                            min_samples_split = 5,\n",
    "                            n_estimators = 76)\n",
    "\n",
    "# 使用GBT分类器进行训练和预测。\n",
    "def train_and_evaluate(model, train_features, train_labels, test_features, test_labels):\n",
    "    \"\"\"训练模型并评估其在训练集和测试集上的性能。\"\"\"\n",
    "    model.fit(train_features, train_labels)  # 训练模型\n",
    "    clf_train_preds = model.predict(train_features)  # 在训练集上进行预测\n",
    "    clf_test_preds = model.predict(test_features)  # 在测试集上进行预测\n",
    "    # 打印训练集和测试集的准确率\n",
    "    print(f\"Training Set Accuracy: {accuracy_score(train_labels, clf_train_preds)}\")\n",
    "    print(f\"Test Set Accuracy: {accuracy_score(test_labels, clf_test_preds)}\")\n",
    "\n",
    "# 初始化用于训练和测试的特征和标签变量。\n",
    "train_X, train_Y = x_mor_train, y_mor_train  # 训练集特征和标签\n",
    "test_X, test_Y = x_mor_test, y_mor_test  # 测试集特征和标签\n",
    "\n",
    "# 执行训练和评估。\n",
    "train_and_evaluate(GBDT, train_X, train_Y, test_X, test_Y)\n",
    "\n",
    "# 定义一个函数进行交叉验证和成绩的保存。\n",
    "# 修改perform_cross_validation函数的调用，传入n_splits参数。\n",
    "def perform_cross_validation(model, train_features, train_labels, n_splits, folder):\n",
    "    \"\"\"执行交叉验证和成绩处理。\"\"\"\n",
    "    cv_strategy = StratifiedKFold(n_splits=n_splits)  # 使用分层k折交叉验证\n",
    "    # 定义评分方法\n",
    "    scoring_methods = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': make_scorer(precision_score, average='macro'),\n",
    "        'recall': make_scorer(recall_score, average='macro'),\n",
    "        'roc_auc': 'roc_auc_ovr',\n",
    "        'f1': make_scorer(f1_score, average='macro'),\n",
    "        'matthews_corrcoef': make_scorer(matthews_corrcoef),\n",
    "        'specificity': make_scorer(specificity_score)  # 添加特异性评分\n",
    "    }\n",
    "    # 执行交叉验证\n",
    "    scores = cross_validate(model, train_features, train_labels, scoring=scoring_methods, cv=cv_strategy)\n",
    "    # 格式化分数并返回结果\n",
    "    formatted_scores = {key.split('_')[-1]: scores[key] for key in scores if key.startswith('test_')}\n",
    "    # 注意这里传入n_splits\n",
    "    return process_all_scores(formatted_scores, model.__class__.__name__, folder, n_splits)\n",
    "\n",
    "# 执行5折交叉验证然后是10折交叉验证。\n",
    "# 注意这里传入n_splits参数到process_all_scores函数。\n",
    "results_5_fold = perform_cross_validation(GBDT, train_X, train_Y, 5, \"./GBDT\")  # 5折交叉验证结果\n",
    "results_10_fold = perform_cross_validation(GBDT, train_X, train_Y, 10, \"./GBDT\")  # 10折交叉验证结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948c097f-f15e-433a-9e74-9e2d4fd6f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def train_and_evaluate(model, train_features, train_labels, test_features, test_labels, output_file):\n",
    "    \"\"\"训练模型并评估其在训练集和测试集上的性能，包括多种评估指标，并将结果保存到CSV文件。\"\"\"\n",
    "    model.fit(train_features, train_labels)  # 训练模型\n",
    "    clf_train_preds = model.predict(train_features)  # 在训练集上进行预测\n",
    "    clf_test_preds = model.predict(test_features)  # 在测试集上进行预测\n",
    "    \n",
    "    # 计算训练集上的性能指标\n",
    "    metrics = {\n",
    "        'Train_Accuracy': accuracy_score(train_labels, clf_train_preds),\n",
    "        'Train_Precision': precision_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_Recall': recall_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_F1': f1_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_MCC': matthews_corrcoef(train_labels, clf_train_preds),\n",
    "        'Train_Specificity': specificity_score(train_labels, clf_train_preds),\n",
    "        'Train_ROC_AUC': roc_auc_score(train_labels, model.predict_proba(train_features)[:, 1], multi_class='ovr'),\n",
    "        \n",
    "        'Test_Accuracy': accuracy_score(test_labels, clf_test_preds),\n",
    "        'Test_Precision': precision_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_Recall': recall_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_F1': f1_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_MCC': matthews_corrcoef(test_labels, clf_test_preds),\n",
    "        'Test_Specificity': specificity_score(test_labels, clf_test_preds),\n",
    "        'Test_ROC_AUC': roc_auc_score(test_labels, model.predict_proba(test_features)[:, 1], multi_class='ovr')\n",
    "    }\n",
    "    \n",
    "    # 将字典转换为DataFrame并保存到CSV文件\n",
    "    df = pd.DataFrame([metrics])\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Metrics saved to {output_file}\")\n",
    "\n",
    "# 执行训练和评估，输出结果\n",
    "train_and_evaluate(GBDT, train_X, train_Y, test_X, test_Y,\"./GBDT/训练和评估.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616e04df-19c3-42cf-a285-49e034881d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "estimator = GBT\n",
    "estimator.fit(train_X, train_Y)\n",
    "clf_test = estimator.predict(test_X)\n",
    "acc_test = accuracy_score(test_Y,clf_test)\n",
    "roc_test = roc_auc_score(test_Y,clf_test)\n",
    "pre_test = precision_score(test_Y,clf_test)\n",
    "rec_test = recall_score(test_Y,clf_test)\n",
    "f1_test = f1_score(test_Y,clf_test)\n",
    "mcc_test = matthews_corrcoef(test_Y,clf_test)\n",
    "matrix_test = confusion_matrix(test_Y,clf_test)\n",
    "ap_test = average_precision_score(test_Y,clf_test)\n",
    "\n",
    "algorithm_model = [GBT]\n",
    "algorithm_name = [\"GBT\"]\n",
    "tmp_1 = np.zeros((1,2))\n",
    "Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(2))\n",
    "tmp_2 = np.zeros((1,2))\n",
    "Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(2))\n",
    "tmp_3 = np.zeros((1,2))\n",
    "Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(2))  \n",
    "tmp_4 = np.zeros((1,2))\n",
    "Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(2)) \n",
    "tmp_5 = np.zeros((1,2))\n",
    "F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(2))\n",
    "tmp_6 = np.zeros((1,2))\n",
    "MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(2))\n",
    "tmp_7 = np.zeros((1,2))\n",
    "Ap_data = pd.DataFrame(tmp_7,index=algorithm_name,columns=range(2))\n",
    "\n",
    "Auc_data.loc[algorithm_name]  = roc_test\n",
    "Acc_data.loc[algorithm_name]  = acc_test\n",
    "Recall_data.loc[algorithm_name] = rec_test\n",
    "Precision_data.loc[algorithm_name] = pre_test\n",
    "F1_data.loc[algorithm_name]  = f1_test\n",
    "MCC_data.loc[algorithm_name]  = mcc_test\n",
    "Ap_data.loc[algorithm_name]  = ap_test\n",
    "\n",
    "Auc_data.to_csv(\"./GBT/test_ROC.csv\")\n",
    "Acc_data.to_csv(\"./GBT/test_ACC.csv\")\n",
    "Recall_data.to_csv(\"./GBT/test_REC.csv\")\n",
    "Precision_data.to_csv(\"./GBT/test_PRE.csv\")\n",
    "F1_data.to_csv(\"./GBT/test_F1.csv\")\n",
    "MCC_data.to_csv(\"./GBT/test_MCC.csv\")\n",
    "Ap_data.to_csv(\"./GBT/test_AP.csv\")\n",
    "\n",
    "clf_train = estimator.predict(train_X)\n",
    "acc_train = accuracy_score(train_Y,clf_train)\n",
    "roc_train = roc_auc_score(train_Y,clf_train)\n",
    "pre_train = precision_score(train_Y,clf_train)\n",
    "rec_train = recall_score(train_Y,clf_train)\n",
    "f1_train = f1_score(train_Y,clf_train)\n",
    "mcc_train = matthews_corrcoef(train_Y,clf_train)\n",
    "matrix_train = confusion_matrix(train_Y,clf_train)\n",
    "ap_train = average_precision_score(train_Y,clf_train)\n",
    "\n",
    "tmp_1 = np.zeros((1,2))\n",
    "Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(2))\n",
    "tmp_2 = np.zeros((1,2))\n",
    "Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(2))\n",
    "tmp_3 = np.zeros((1,2))\n",
    "Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(2))  \n",
    "tmp_4 = np.zeros((1,2))\n",
    "Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(2)) \n",
    "tmp_5 = np.zeros((1,2))\n",
    "F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(2))\n",
    "tmp_6 = np.zeros((1,2))\n",
    "MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(2))\n",
    "tmp_7 = np.zeros((1,2))\n",
    "Ap_data = pd.DataFrame(tmp_7,index=algorithm_name,columns=range(2))\n",
    "\n",
    "Auc_data.loc[algorithm_name]  = roc_train\n",
    "Acc_data.loc[algorithm_name]  = acc_train\n",
    "Recall_data.loc[algorithm_name] = rec_train\n",
    "Precision_data.loc[algorithm_name] = pre_train\n",
    "F1_data.loc[algorithm_name]  = f1_train\n",
    "MCC_data.loc[algorithm_name]  = mcc_train\n",
    "Ap_data.loc[algorithm_name]  = ap_train\n",
    "\n",
    "Auc_data.to_csv(\"./GBT/train_ROC.csv\")\n",
    "Acc_data.to_csv(\"./GBT/train_ACC.csv\")\n",
    "Recall_data.to_csv(\"./GBT/train_REC.csv\")\n",
    "Precision_data.to_csv(\"./GBT/train_PRE.csv\")\n",
    "F1_data.to_csv(\"./GBT/train_F1.csv\")\n",
    "MCC_data.to_csv(\"./GBT/train_MCC.csv\")\n",
    "Ap_data.to_csv(\"./GBT/train_AP.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdece2f-4ad4-4ef2-8da8-45dbca7f6269",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LogisticRegression参数搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445649d4-a2b6-45b9-b9fd-9f1873cd0ef3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "def LogisticRegressionCV_mdoel (X,Y):\n",
    "    LogisticRegressionCV_auto = LogisticRegressionCV(random_state=0,n_jobs=-1)\n",
    "    \n",
    "    # 搜索的参数是para\n",
    "    param_dict = {\"solver\":['newton-cg','lbfgs', 'sag', 'saga'],\n",
    "                  \"penalty\":['l1','l2', 'elasticnet',],\n",
    "                  \"class_weight\":['none','balanced'],\n",
    "                  \"fit_intercept\":[True,False],\n",
    "                  \"dual\":[True,False],\n",
    "                 }\n",
    "    estimator = GridSearchCV(estimator = LogisticRegressionCV_auto, param_grid=param_dict, cv=cv,n_jobs=-1,scoring = \"roc_auc\")\n",
    "    estimator.fit(X,Y)\n",
    "    \n",
    "    return estimator.best_params_,estimator.best_score_,estimator.best_estimator_\n",
    "\n",
    "tmp_1,tmp_2,LogisticRegressionCV_auto  = LogisticRegressionCV_mdoel(X,Y)\n",
    "print(tmp_1,tmp_2,LogisticRegressionCV_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f7d42d-bc18-46d0-a56b-cfd3ec745915",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp_1,tmp_2,LogisticRegressionCV_auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e96f20-c849-4c1f-ba08-70dfae14dc58",
   "metadata": {},
   "source": [
    "### 混淆矩阵  AUC-ROC   PR-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a4f57-9642-4f4e-8bb4-0ac11f5b81d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X = x_mor_train\n",
    "train_Y = y_mor_train\n",
    "test_X = x_mor_test\n",
    "test_Y = y_mor_test\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "LR = LogisticRegressionCV(random_state=0,n_jobs=-1,\n",
    "                            solver = 'sag',\n",
    "                            penalty = 'l2',\n",
    "                            class_weight = 'balanced',\n",
    "                            fit_intercept = False,\n",
    "                            dual = False\n",
    "                         )\n",
    "\n",
    "estimator = LR\n",
    "estimator.fit(train_X, train_Y)\n",
    "clf_train = estimator.predict(train_X)\n",
    "clf_test = estimator.predict(test_X)\n",
    "print(f\"训练集准确度是{accuracy_score(train_Y,clf_train)}\")\n",
    "print(f\"测试集准确度是{accuracy_score(test_Y,clf_test)}\")\n",
    "train_matrix = confusion_matrix(train_Y, clf_train)\n",
    "test_matrix = confusion_matrix(test_Y, clf_test)\n",
    "\n",
    "# 绘制热图\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(train_matrix, annot=True, cmap=\"Blues\", cbar=None,\n",
    "            fmt=\"d\")  #cbar=None 就会不显示色条,fmt=\"d\"确保中间现实数字\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title(\"Confusion Matrix of Train\")\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(test_matrix, annot=True, cmap=\"Blues\", cbar=None,\n",
    "            fmt=\"d\")  #cbar=None 就会不显示色条,fmt=\"d\"确保中间现实数字\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title(\"Confusion Matrix of Test\")\n",
    "plt.savefig(\"./LR/混淆矩阵_LR.svg\", dpi = 600)\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 绘制训练集 ROC 图\n",
    "plt.subplot(1, 2, 1)\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]  # 获取训练集的预测概率\n",
    "fpr_train, tpr_train, _ = roc_curve(train_Y, y_pro_train)  # 计算 ROC 曲线的参数\n",
    "roc_auc_train = auc(fpr_train, tpr_train)  # 计算 AUC\n",
    "plt.plot(fpr_train, tpr_train, label='LR-Train (AUC = %0.3f)' % roc_auc_train)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 绘制测试集 ROC 图\n",
    "plt.subplot(1, 2, 2)\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]  # 获取测试集的预测概率\n",
    "fpr_test, tpr_test, _ = roc_curve(test_Y, y_pro_test)  # 计算 ROC 曲线的参数\n",
    "roc_auc_test = auc(fpr_test, tpr_test)  # 计算 AUC\n",
    "plt.plot(fpr_test, tpr_test, label='LR-Test (AUC = %0.3f)' % roc_auc_test)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.savefig(\"./LR/ROC_LR.svg\", dpi=600)  # 保存图形为 SVG 格式文件\n",
    "plt.show()  # 显示图形\n",
    "\n",
    "##绘制组合图\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制 ROC 曲线\n",
    "plt.plot(fpr_train, tpr_train, color='#5D9C59',label='LR-Train (AUC = %0.3f)' % roc_auc_train)\n",
    "plt.plot(fpr_test, tpr_test, color='#5463FF',label='LR-Test (AUC = %0.3f)' % roc_auc_test)\n",
    "# 绘制对角线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 设置标题和标签\n",
    "plt.title('LR-ECFPs', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('False Positive Rate', fontweight='bold', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontweight='bold', fontsize=15)\n",
    "plt.legend(loc='lower right')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./LR/ROC_LR_组合.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 训练集PR_AUC图\n",
    "plt.figure(figsize=(12, 5))\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]\n",
    "precision_train, recall_train, _ = precision_recall_curve(train_Y, y_pro_train, pos_label=1)\n",
    "pr_auc_train = auc(recall_train, precision_train)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(recall_train, precision_train, label='LR-Train (PR_AUC = {:.3f})'.format(pr_auc_train))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "# 测试集PR_AUC图\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]\n",
    "precision_test, recall_test, _ = precision_recall_curve(test_Y, y_pro_test, pos_label=1)\n",
    "pr_auc_test = auc(recall_test, precision_test)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall_test, precision_test, label='LR-Test (PR_AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./LR/PR_LR.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制训练集PR_AUC图\n",
    "plt.plot(recall_train, precision_train,color='#5D9C59', label='LR-Train (PR-AUC = {:.3f})'.format(pr_auc_train))\n",
    "# 绘制测试集PR_AUC图\n",
    "plt.plot(recall_test, precision_test,color='#5463FF', label='LR-Test (PR-AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('LR-ECFPs', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Recall', fontweight='bold', fontsize=15)\n",
    "plt.ylabel('Precision', fontweight='bold', fontsize=15)\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./LR/PR_LR_组合.svg\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc045abf-ca14-4d20-9ade-c1ca17cef91f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6733bf62-b902-464c-9638-90a1e6d5e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 绘制训练集 ROC 图\n",
    "plt.subplot(1, 2, 1)\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]  # 获取训练集的预测概率\n",
    "fpr_train, tpr_train, _ = roc_curve(train_Y, y_pro_train)  # 计算 ROC 曲线的参数\n",
    "roc_auc_train = auc(fpr_train, tpr_train)  # 计算 AUC\n",
    "plt.plot(fpr_train, tpr_train, label='LR-Train (AUC = %0.3f)' % roc_auc_train)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "\n",
    "# 绘制测试集 ROC 图\n",
    "plt.subplot(1, 2, 2)\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]  # 获取测试集的预测概率\n",
    "fpr_test, tpr_test, _ = roc_curve(test_Y, y_pro_test)  # 计算 ROC 曲线的参数\n",
    "roc_auc_test = auc(fpr_test, tpr_test)  # 计算 AUC\n",
    "plt.plot(fpr_test, tpr_test, label='LR-Test (AUC = %0.3f)' % roc_auc_test)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.savefig(\"ROC_LR.svg\", dpi=600)  # 保存图形为 SVG 格式文件\n",
    "plt.show()  # 显示图形\n",
    "\n",
    "##绘制组合图\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制 ROC 曲线\n",
    "plt.plot(fpr_train, tpr_train, label='LR-Train (AUC = %0.3f)' % roc_auc_train)\n",
    "plt.plot(fpr_test, tpr_test, label='LR-Test (AUC = %0.3f)' % roc_auc_test)\n",
    "# 绘制对角线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 设置标题和标签\n",
    "plt.title('LR-ECFPs')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"ROC_LR_组合.svg\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a68393-2692-4a05-8fb6-03f29db3c309",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### PR_AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b904e600-752e-45e5-a1d7-d9132da75f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 训练集PR_AUC图\n",
    "plt.figure(figsize=(12, 5))\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]\n",
    "precision_train, recall_train, _ = precision_recall_curve(train_Y, y_pro_train, pos_label=1)\n",
    "pr_auc_train = auc(recall_train, precision_train)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(recall_train, precision_train, label='LR-Train (PR_AUC = {:.3f})'.format(pr_auc_train))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "\n",
    "# 测试集PR_AUC图\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]\n",
    "precision_test, recall_test, _ = precision_recall_curve(test_Y, y_pro_test, pos_label=1)\n",
    "pr_auc_test = auc(recall_test, precision_test)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall_test, precision_test, label='LR-Test (PR_AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"LR_DT.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制训练集PR_AUC图\n",
    "plt.plot(recall_train, precision_train, label='LR-Train (PR_AUC = {:.3f})'.format(pr_auc_train))\n",
    "# 绘制测试集PR_AUC图\n",
    "plt.plot(recall_test, precision_test, label='LR-Test (PR_AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"LR_DT_组合.svg\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b2ee64-7c78-4133-94c6-2c75a0cd31c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11df209-3105-423f-a7ec-0d1ba54921c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef, make_scorer\n",
    "\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    return data\n",
    "\n",
    "def process_all_scores(score_dict, algorithm_name, folder):\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/5-CV-{metric.upper()}.csv\"\n",
    "        columns = [str(i) for i in range(len(values))]\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)\n",
    "    return results\n",
    "\n",
    "# 实际的数据和模型定义\n",
    "train_X = x_mor_train  \n",
    "train_Y = y_mor_train  \n",
    "model = LR   \n",
    "\n",
    "# 定义5折交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# 评分函数\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'roc_auc': 'roc_auc_ovr',\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# 执行交叉验证\n",
    "scores = cross_validate(model, train_X, train_Y, scoring=scoring, cv=cv_strategy, return_estimator=False)\n",
    "\n",
    "# 格式化分数字典以使用在处理函数中\n",
    "formatted_scores = {key[5:]: scores[key] for key in scores.keys() if key.startswith('test_')}\n",
    "\n",
    "# 处理并保存分数\n",
    "results = process_all_scores(formatted_scores, \"LR\", \"./LR/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e00069f-d713-4f4c-879c-54c5e96a1252",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 10折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce2017-1ea8-4566-b173-4c127c885fff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef, make_scorer\n",
    "\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    return data\n",
    "\n",
    "def process_all_scores(score_dict, algorithm_name, folder):\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/10-CV-{metric.upper()}.csv\"\n",
    "        columns = [str(i) for i in range(len(values))]\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)\n",
    "    return results\n",
    "\n",
    "# 实际的数据和模型定义\n",
    "train_X = x_mor_train  \n",
    "train_Y = y_mor_train  \n",
    "model = LR   ####修改模型\n",
    "\n",
    "# 定义10折交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# 评分函数\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'roc_auc': 'roc_auc_ovr',\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# 执行交叉验证\n",
    "scores = cross_validate(model, train_X, train_Y, scoring=scoring, cv=cv_strategy, return_estimator=False)\n",
    "\n",
    "# 格式化分数字典以使用在处理函数中\n",
    "formatted_scores = {key[5:]: scores[key] for key in scores.keys() if key.startswith('test_')}\n",
    "\n",
    "# 处理并保存分数\n",
    "results = process_all_scores(formatted_scores, \"LR\", \"./LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e5d609-12da-4f63-9de4-a9431ad84ecb",
   "metadata": {},
   "source": [
    "### 在外部数据集上的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2187ee1e-5258-48eb-9cf4-02953f80ed4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 忽略特定类型的警告\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "\n",
    "# 导入机器学习库scikit-learn中的LR分类器和其他必要的工具包\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    roc_auc_score, f1_score, matthews_corrcoef, \n",
    "    make_scorer, confusion_matrix\n",
    ")\n",
    "import pandas as pd  # 导入数据处理库pandas\n",
    "import numpy as np  # 导入数值计算库numpy\n",
    "\n",
    "# 定义特异性评分函数\n",
    "def specificity_score(y_true, y_pred):\n",
    "    \"\"\"计算特异性（Specificity）.\"\"\"\n",
    "    tn, fp, _, _ = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "\n",
    "# 定义一个函数用于保存训练集交叉验证的分数到CSV文件，并且打印/保存平均值。\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    \"\"\"将交叉验证的成绩保存到CSV文件中。\"\"\"\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)  # 计算平均分并添加为新列\n",
    "    data.to_csv(file_path, index=False)  # 将DataFrame保存为CSV文件\n",
    "    print(f\"Data saved to {file_path}\")  # 打印保存信息\n",
    "    return data\n",
    "\n",
    "# 定义一个函数来处理所有成绩指标并使用`save_cv_scores`函数保存它们。\n",
    "# 修改process_all_scores函数，添加n_splits参数以反映正确的折数。\n",
    "def process_all_scores(score_dict, algorithm_name, folder, n_splits):\n",
    "    \"\"\"处理所有成绩指标并将其保存到CSV文件中。\"\"\"\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/{n_splits}-CV-{metric.upper()}.csv\"  # 使用传入的n_splits来构造文件名\n",
    "        columns = [str(i+1) for i in range(len(values))]  # 创建列名列表\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)  # 保存成绩并添加到结果字典\n",
    "    return results\n",
    "\n",
    "# 初始化和训练逻辑回归模型\n",
    "LR = LogisticRegressionCV(random_state=0,n_jobs=-1,\n",
    "                            solver = 'sag',\n",
    "                            penalty = 'l2',\n",
    "                            class_weight = 'balanced',\n",
    "                            fit_intercept = False,\n",
    "                            dual = False\n",
    "                         )\n",
    "\n",
    "# 使用LR分类器进行训练和预测。\n",
    "def train_and_evaluate(model, train_features, train_labels, test_features, test_labels):\n",
    "    \"\"\"训练模型并评估其在训练集和测试集上的性能。\"\"\"\n",
    "    model.fit(train_features, train_labels)  # 训练模型\n",
    "    clf_train_preds = model.predict(train_features)  # 在训练集上进行预测\n",
    "    clf_test_preds = model.predict(test_features)  # 在测试集上进行预测\n",
    "    # 打印训练集和测试集的准确率\n",
    "    print(f\"Training Set Accuracy: {accuracy_score(train_labels, clf_train_preds)}\")\n",
    "    print(f\"Test Set Accuracy: {accuracy_score(test_labels, clf_test_preds)}\")\n",
    "\n",
    "# 初始化用于训练和测试的特征和标签变量。\n",
    "train_X, train_Y = x_mor_train, y_mor_train  # 训练集特征和标签\n",
    "test_X, test_Y = x_mor_test, y_mor_test  # 测试集特征和标签\n",
    "\n",
    "# 执行训练和评估。\n",
    "train_and_evaluate(LR, train_X, train_Y, test_X, test_Y)\n",
    "\n",
    "# 定义一个函数进行交叉验证和成绩的保存。\n",
    "# 修改perform_cross_validation函数的调用，传入n_splits参数。\n",
    "def perform_cross_validation(model, train_features, train_labels, n_splits, folder):\n",
    "    \"\"\"执行交叉验证和成绩处理。\"\"\"\n",
    "    cv_strategy = StratifiedKFold(n_splits=n_splits)  # 使用分层k折交叉验证\n",
    "    # 定义评分方法\n",
    "    scoring_methods = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': make_scorer(precision_score, average='macro'),\n",
    "        'recall': make_scorer(recall_score, average='macro'),\n",
    "        'roc_auc': 'roc_auc_ovr',\n",
    "        'f1': make_scorer(f1_score, average='macro'),\n",
    "        'matthews_corrcoef': make_scorer(matthews_corrcoef),\n",
    "        'specificity': make_scorer(specificity_score)  # 添加特异性评分\n",
    "    }\n",
    "    # 执行交叉验证\n",
    "    scores = cross_validate(model, train_features, train_labels, scoring=scoring_methods, cv=cv_strategy)\n",
    "    # 格式化分数并返回结果\n",
    "    formatted_scores = {key.split('_')[-1]: scores[key] for key in scores if key.startswith('test_')}\n",
    "    # 注意这里传入n_splits\n",
    "    return process_all_scores(formatted_scores, model.__class__.__name__, folder, n_splits)\n",
    "\n",
    "# 执行5折交叉验证然后是10折交叉验证。\n",
    "# 注意这里传入n_splits参数到process_all_scores函数。\n",
    "results_5_fold = perform_cross_validation(LR, train_X, train_Y, 5, \"./LR\")  # 5折交叉验证结果\n",
    "results_10_fold = perform_cross_validation(LR, train_X, train_Y, 10, \"./LR\")  # 10折交叉验证结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f433f4e6-8d68-4c41-85d3-67441cccb0a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def train_and_evaluate(model, train_features, train_labels, test_features, test_labels, output_file):\n",
    "    \"\"\"训练模型并评估其在训练集和测试集上的性能，包括多种评估指标，并将结果保存到CSV文件。\"\"\"\n",
    "    model.fit(train_features, train_labels)  # 训练模型\n",
    "    clf_train_preds = model.predict(train_features)  # 在训练集上进行预测\n",
    "    clf_test_preds = model.predict(test_features)  # 在测试集上进行预测\n",
    "    \n",
    "    # 计算训练集上的性能指标\n",
    "    metrics = {\n",
    "        'Train_Accuracy': accuracy_score(train_labels, clf_train_preds),\n",
    "        'Train_Precision': precision_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_Recall': recall_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_F1': f1_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_MCC': matthews_corrcoef(train_labels, clf_train_preds),\n",
    "        'Train_Specificity': specificity_score(train_labels, clf_train_preds),\n",
    "        'Train_ROC_AUC': roc_auc_score(train_labels, model.predict_proba(train_features)[:, 1], multi_class='ovr'),\n",
    "        \n",
    "        'Test_Accuracy': accuracy_score(test_labels, clf_test_preds),\n",
    "        'Test_Precision': precision_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_Recall': recall_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_F1': f1_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_MCC': matthews_corrcoef(test_labels, clf_test_preds),\n",
    "        'Test_Specificity': specificity_score(test_labels, clf_test_preds),\n",
    "        'Test_ROC_AUC': roc_auc_score(test_labels, model.predict_proba(test_features)[:, 1], multi_class='ovr')\n",
    "    }\n",
    "    \n",
    "    # 将字典转换为DataFrame并保存到CSV文件\n",
    "    df = pd.DataFrame([metrics])\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Metrics saved to {output_file}\")\n",
    "\n",
    "# 执行训练和评估，输出结果\n",
    "train_and_evaluate(LR, train_X, train_Y, test_X, test_Y,\"./LR/训练和评估.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd7336-8fc9-4288-a13c-8837cbb48133",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "estimator = LR\n",
    "estimator.fit(train_X, train_Y)\n",
    "clf_test = estimator.predict(test_X)\n",
    "acc_test = accuracy_score(test_Y,clf_test)\n",
    "roc_test = roc_auc_score(test_Y,clf_test)\n",
    "pre_test = precision_score(test_Y,clf_test)\n",
    "rec_test = recall_score(test_Y,clf_test)\n",
    "f1_test = f1_score(test_Y,clf_test)\n",
    "mcc_test = matthews_corrcoef(test_Y,clf_test)\n",
    "matrix_test = confusion_matrix(test_Y,clf_test)\n",
    "ap_test = average_precision_score(test_Y,clf_test)\n",
    "\n",
    "algorithm_model = [LR]\n",
    "algorithm_name = [\"LR\"]\n",
    "tmp_1 = np.zeros((1,2))\n",
    "Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(2))\n",
    "tmp_2 = np.zeros((1,2))\n",
    "Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(2))\n",
    "tmp_3 = np.zeros((1,2))\n",
    "Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(2))  \n",
    "tmp_4 = np.zeros((1,2))\n",
    "Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(2)) \n",
    "tmp_5 = np.zeros((1,2))\n",
    "F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(2))\n",
    "tmp_6 = np.zeros((1,2))\n",
    "MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(2))\n",
    "tmp_7 = np.zeros((1,2))\n",
    "Ap_data = pd.DataFrame(tmp_7,index=algorithm_name,columns=range(2))\n",
    "\n",
    "Auc_data.loc[algorithm_name]  = roc_test\n",
    "Acc_data.loc[algorithm_name]  = acc_test\n",
    "Recall_data.loc[algorithm_name] = rec_test\n",
    "Precision_data.loc[algorithm_name] = pre_test\n",
    "F1_data.loc[algorithm_name]  = f1_test\n",
    "MCC_data.loc[algorithm_name]  = mcc_test\n",
    "Ap_data.loc[algorithm_name]  = ap_test\n",
    "\n",
    "Auc_data.to_csv(\"./LR/test_ROC.csv\")\n",
    "Acc_data.to_csv(\"./LR/test_ACC.csv\")\n",
    "Recall_data.to_csv(\"./LR/test_REC.csv\")\n",
    "Precision_data.to_csv(\"./LR/test_PRE.csv\")\n",
    "F1_data.to_csv(\"./LR/test_F1.csv\")\n",
    "MCC_data.to_csv(\"./LR/test_MCC.csv\")\n",
    "Ap_data.to_csv(\"./LR/test_AP.csv\")\n",
    "\n",
    "clf_train = estimator.predict(train_X)\n",
    "acc_train = accuracy_score(train_Y,clf_train)\n",
    "roc_train = roc_auc_score(train_Y,clf_train)\n",
    "pre_train = precision_score(train_Y,clf_train)\n",
    "rec_train = recall_score(train_Y,clf_train)\n",
    "f1_train = f1_score(train_Y,clf_train)\n",
    "mcc_train = matthews_corrcoef(train_Y,clf_train)\n",
    "matrix_train = confusion_matrix(train_Y,clf_train)\n",
    "ap_train = average_precision_score(train_Y,clf_train)\n",
    "\n",
    "tmp_1 = np.zeros((1,2))\n",
    "Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(2))\n",
    "tmp_2 = np.zeros((1,2))\n",
    "Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(2))\n",
    "tmp_3 = np.zeros((1,2))\n",
    "Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(2))  \n",
    "tmp_4 = np.zeros((1,2))\n",
    "Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(2)) \n",
    "tmp_5 = np.zeros((1,2))\n",
    "F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(2))\n",
    "tmp_6 = np.zeros((1,2))\n",
    "MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(2))\n",
    "tmp_7 = np.zeros((1,2))\n",
    "Ap_data = pd.DataFrame(tmp_7,index=algorithm_name,columns=range(2))\n",
    "\n",
    "Auc_data.loc[algorithm_name]  = roc_train\n",
    "Acc_data.loc[algorithm_name]  = acc_train\n",
    "Recall_data.loc[algorithm_name] = rec_train\n",
    "Precision_data.loc[algorithm_name] = pre_train\n",
    "F1_data.loc[algorithm_name]  = f1_train\n",
    "MCC_data.loc[algorithm_name]  = mcc_train\n",
    "Ap_data.loc[algorithm_name]  = ap_train\n",
    "\n",
    "Auc_data.to_csv(\"./LR/train_ROC.csv\")\n",
    "Acc_data.to_csv(\"./LR/train_ACC.csv\")\n",
    "Recall_data.to_csv(\"./LR/train_REC.csv\")\n",
    "Precision_data.to_csv(\"./LR/train_PRE.csv\")\n",
    "F1_data.to_csv(\"./LR/train_F1.csv\")\n",
    "MCC_data.to_csv(\"./LR/train_MCC.csv\")\n",
    "Ap_data.to_csv(\"./LR/train_AP.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefab0ab-4621-47a0-afb1-70e0dfb0baa8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# KNeighbors参数搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7dcc9c-ff9a-48f0-b3ac-c213cd007466",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# def KNeighborsClassifier_model(X,Y):   \n",
    "    \n",
    "#     # 首先实例化各个回归方法\n",
    "#     KNeighborsClassifier_auto = KNeighborsClassifier(n_jobs=1)\n",
    "#     param_dict = {\"n_neighbors\":[2,3,4,5,6,7,8,9,10,11,12,13,14,15],\n",
    "#                  \"algorithm\":['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "#                   \"weights\":['uniform', 'distance'],\n",
    "#                   \"p\":[1, 2],\n",
    "#                  }\n",
    "#     estimator = GridSearchCV(estimator = KNeighborsClassifier_auto, param_grid=param_dict, cv=cv,n_jobs=-1,scoring = \"roc_auc\")\n",
    "#     estimator.fit(X,Y)\n",
    "#     return estimator.best_params_,estimator.best_score_,estimator.best_estimator_\n",
    "\n",
    "# tmp_1,tmp_2,KNeighborsClassifier_auto = KNeighborsClassifier_model(X,Y)\n",
    "# print(tmp_1,tmp_2,KNeighborsClassifier_auto)\n",
    "# # tmp = pd.DataFrame(tmp_1)\n",
    "# # df_fig = tmp[[\"params\"]]\n",
    "# # df_fig.to_csv(\"KNN-FCFP-网格搜索.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d39f4-ac19-483d-b6ae-012b45a567e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from time import time\n",
    "begin_time = time()\n",
    "# Search optimal hyperparameter\n",
    "KNeighborsClassifier_auto = KNeighborsClassifier(n_jobs=1)\n",
    "\n",
    "random_forest_hp_range={\"n_neighbors\":[2,3,4,5,6,7,8,9,10,11,12,13,14,15],\n",
    "                 \"algorithm\":['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                  \"weights\":['uniform', 'distance'],\n",
    "                  \"p\":[1, 2],\n",
    "                       }\n",
    "print(random_forest_hp_range)\n",
    "\n",
    "estimator_all_roc = GridSearchCV(estimator=KNeighborsClassifier_auto,\n",
    "                                 param_grid=random_forest_hp_range,\n",
    "                                 cv=cv,\n",
    "                                 n_jobs=-1,\n",
    "                                 scoring=\"roc_auc\",verbose=1)\n",
    "# %%time\n",
    "estimator_all_roc.fit(X, Y)\n",
    "end_time = time()\n",
    "print({end_time - begin_time})\n",
    "print(estimator_all_roc.best_params_)\n",
    "print(estimator_all_roc.best_score_)\n",
    "tmp = pd.DataFrame(estimator_all_roc.cv_results_)\n",
    "df_fig = tmp[[\"mean_test_score\",\"params\"]]\n",
    "df_fig.to_csv(\"./KNN/tmp2-knn.csv\",index=False)\n",
    "df_fig[\"n_neighbors\"] = 1\n",
    "df_fig['algorithm'] = 1\n",
    "df_fig[\"weights\"] = 1\n",
    "df_fig['p']=1\n",
    "for i in range(0,df_fig.shape[0]):\n",
    "    dict_tmp = df_fig[\"params\"].iloc[i]\n",
    "    df_fig[\"n_neighbors\"].iloc[i] = dict_tmp[\"n_neighbors\"]\n",
    "    df_fig[\"algorithm\"].iloc[i] = dict_tmp[\"algorithm\"]\n",
    "    df_fig[\"weights\"].iloc[i] = dict_tmp[\"weights\"]\n",
    "    df_fig['p'].iloc[i]=dict_tmp['p']\n",
    "    \n",
    "df_fig.head(50)\n",
    "df_fig.to_csv(\"./KNN/网格搜索结果KNN.csv\",index=False)\n",
    "df_fig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca4a4de-9dca-4fbd-8167-35e289f83bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimator_all_roc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d857e672-42d1-4d7f-aa51-49b00f5df765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X = x_mor_train\n",
    "train_Y = y_mor_train\n",
    "test_X = x_mor_test\n",
    "test_Y = y_mor_test\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier(n_jobs=-1,\n",
    "                            algorithm = 'auto',\n",
    "                            n_neighbors = 4,\n",
    "                            p = 1,\n",
    "                            weights = 'uniform'\n",
    "                         )\n",
    "\n",
    "estimator = KNN\n",
    "estimator.fit(train_X, train_Y)\n",
    "clf_train = estimator.predict(train_X)\n",
    "clf_test = estimator.predict(test_X)\n",
    "print(f\"训练集准确度是{accuracy_score(train_Y,clf_train)}\")\n",
    "print(f\"测试集准确度是{accuracy_score(test_Y,clf_test)}\")\n",
    "\n",
    "train_matrix = confusion_matrix(train_Y, clf_train)\n",
    "test_matrix = confusion_matrix(test_Y, clf_test)\n",
    "plt.rc('axes', linewidth=1.5)\n",
    "# 绘制混淆矩阵\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(train_matrix, annot=True, cmap=\"Blues\", cbar=None,fmt=\"d\")  \n",
    "#cbar=None 就会不显示色条,fmt=\"d\"确保中间现实数字\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title(\"Confusion Matrix of Train\")\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(test_matrix, annot=True, cmap=\"Blues\", cbar=None,fmt=\"d\")  \n",
    "#cbar=None 就会不显示色条,fmt=\"d\"确保中间现实数字\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title(\"Confusion Matrix of Test\")\n",
    "plt.savefig(\"./KNN/混淆矩阵_KNN.svg\", dpi = 600)\n",
    "plt.show()\n",
    "\n",
    "#########  ROC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "# 训练集 ROC 图\n",
    "plt.subplot(1, 2, 1)\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]  # 获取训练集的预测概率\n",
    "fpr_train, tpr_train, _ = roc_curve(train_Y, y_pro_train)  # 计算 ROC 曲线的参数\n",
    "roc_auc_train = auc(fpr_train, tpr_train)  # 计算 AUC\n",
    "plt.plot(fpr_train, tpr_train, label='KNN-Train (AUC = %0.3f)' % roc_auc_train)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 绘制测试集 ROC 图\n",
    "plt.subplot(1, 2, 2)\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]  # 获取测试集的预测概率\n",
    "fpr_test, tpr_test, _ = roc_curve(test_Y, y_pro_test)  # 计算 ROC 曲线的参数\n",
    "roc_auc_test = auc(fpr_test, tpr_test)  # 计算 AUC\n",
    "plt.plot(fpr_test, tpr_test, label='KNN-Test (AUC = %0.3f)' % roc_auc_test)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.savefig(\"./KNN/ROC_KNN.svg\", dpi=600)  # 保存图形为 SVG 格式文件\n",
    "plt.show()  # 显示图形\n",
    "\n",
    "##绘制组合图\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制 ROC 曲线\n",
    "plt.plot(fpr_train, tpr_train,color='#5D9C59', label='KNN-Train (AUC = %0.3f)' % roc_auc_train)\n",
    "plt.plot(fpr_test, tpr_test,color='#5463FF', label='KNN-Test (AUC = %0.3f)' % roc_auc_test)\n",
    "# 绘制对角线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 设置标题和标签\n",
    "plt.title('KNN-ECFPs', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('False Positive Rate', fontweight='bold', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontweight='bold', fontsize=15)\n",
    "plt.legend(loc='lower right')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./KNN/ROC_KNN_组合.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "# 训练集PR_AUC图\n",
    "plt.figure(figsize=(12, 5))\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]\n",
    "precision_train, recall_train, _ = precision_recall_curve(train_Y, y_pro_train, pos_label=1)\n",
    "pr_auc_train = auc(recall_train, precision_train)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(recall_train, precision_train, label='KNN-Train (PR_AUC = {:.3f})'.format(pr_auc_train))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "# 测试集PR_AUC图\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]\n",
    "precision_test, recall_test, _ = precision_recall_curve(test_Y, y_pro_test, pos_label=1)\n",
    "pr_auc_test = auc(recall_test, precision_test)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall_test, precision_test, label='KNN-Test (PR_AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./KNN/PR_KNN.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制训练集PR_AUC图\n",
    "plt.plot(recall_train, precision_train,color='#5D9C59', label='KNN-Train (PR-AUC = {:.3f})'.format(pr_auc_train))\n",
    "# 绘制测试集PR_AUC图\n",
    "plt.plot(recall_test, precision_test,color='#5463FF', label='KNN-Test (PR-AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('KNN-ECFPs', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Recall', fontweight='bold', fontsize=15)\n",
    "plt.ylabel('Precision', fontweight='bold', fontsize=15)\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./KNN/PR_KNN_组合.svg\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3663794-c0cc-47cd-be8e-552c6686f61e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a09b906-9a50-4c4f-babe-87fc56fdd11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef, make_scorer\n",
    "\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    return data\n",
    "\n",
    "def process_all_scores(score_dict, algorithm_name, folder):\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/5-CV-{metric.upper()}.csv\"\n",
    "        columns = [str(i) for i in range(len(values))]\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)\n",
    "    return results\n",
    "\n",
    "# 实际的数据和模型定义\n",
    "train_X = x_mor_train  \n",
    "train_Y = y_mor_train  \n",
    "model = KNN   \n",
    "\n",
    "# 定义5折交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# 评分函数\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'roc_auc': 'roc_auc_ovr',\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# 执行交叉验证\n",
    "scores = cross_validate(model, train_X, train_Y, scoring=scoring, cv=cv_strategy, return_estimator=False)\n",
    "\n",
    "# 格式化分数字典以使用在处理函数中\n",
    "formatted_scores = {key[5:]: scores[key] for key in scores.keys() if key.startswith('test_')}\n",
    "\n",
    "# 处理并保存分数\n",
    "results = process_all_scores(formatted_scores, \"KNN\", \"./KNN/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b145a93f-a94f-4f66-a007-c2f95d0e1ba2",
   "metadata": {},
   "source": [
    "### 10折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b648fd29-df21-4e66-a598-4e2489b8f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef, make_scorer\n",
    "\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    return data\n",
    "\n",
    "def process_all_scores(score_dict, algorithm_name, folder):\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/10-CV-{metric.upper()}.csv\"\n",
    "        columns = [str(i) for i in range(len(values))]\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)\n",
    "    return results\n",
    "\n",
    "# 实际的数据和模型定义\n",
    "train_X = x_mor_train  \n",
    "train_Y = y_mor_train  \n",
    "model = KNN   ####修改模型\n",
    "\n",
    "# 定义10折交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# 评分函数\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'roc_auc': 'roc_auc_ovr',\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# 执行交叉验证\n",
    "scores = cross_validate(model, train_X, train_Y, scoring=scoring, cv=cv_strategy, return_estimator=False)\n",
    "\n",
    "# 格式化分数字典以使用在处理函数中\n",
    "formatted_scores = {key[5:]: scores[key] for key in scores.keys() if key.startswith('test_')}\n",
    "\n",
    "# 处理并保存分数\n",
    "results = process_all_scores(formatted_scores, \"KNN\", \"./KNN/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fbbadc-0c97-4f95-8726-e7ea64e485c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 忽略特定类型的警告\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "\n",
    "# 导入机器学习库scikit-learn中的KNN分类器和其他必要的工具包\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    roc_auc_score, f1_score, matthews_corrcoef, \n",
    "    make_scorer, confusion_matrix\n",
    ")\n",
    "import pandas as pd  # 导入数据处理库pandas\n",
    "import numpy as np  # 导入数值计算库numpy\n",
    "\n",
    "# 定义特异性评分函数\n",
    "def specificity_score(y_true, y_pred):\n",
    "    \"\"\"计算特异性（Specificity）.\"\"\"\n",
    "    tn, fp, _, _ = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "\n",
    "# 定义一个函数用于保存训练集交叉验证的分数到CSV文件，并且打印/保存平均值。\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    \"\"\"将交叉验证的成绩保存到CSV文件中。\"\"\"\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)  # 计算平均分并添加为新列\n",
    "    data.to_csv(file_path, index=False)  # 将DataFrame保存为CSV文件\n",
    "    print(f\"Data saved to {file_path}\")  # 打印保存信息\n",
    "    return data\n",
    "\n",
    "# 定义一个函数来处理所有成绩指标并使用`save_cv_scores`函数保存它们。\n",
    "# 修改process_all_scores函数，添加n_splits参数以反映正确的折数。\n",
    "def process_all_scores(score_dict, algorithm_name, folder, n_splits):\n",
    "    \"\"\"处理所有成绩指标并将其保存到CSV文件中。\"\"\"\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/{n_splits}-CV-{metric.upper()}.csv\"  # 使用传入的n_splits来构造文件名\n",
    "        columns = [str(i+1) for i in range(len(values))]  # 创建列名列表\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)  # 保存成绩并添加到结果字典\n",
    "    return results\n",
    "\n",
    "# 实例化KNN分类器，配置超参数\n",
    "KNN = KNeighborsClassifier(n_jobs=-1,\n",
    "                            algorithm = 'auto',\n",
    "                            n_neighbors = 9,\n",
    "                            p = 1,\n",
    "                            weights = 'uniform'\n",
    "                         )\n",
    "# 使用KNN分类器进行训练和预测。\n",
    "def train_and_evaluate(model, train_features, train_labels, test_features, test_labels):\n",
    "    \"\"\"训练模型并评估其在训练集和测试集上的性能。\"\"\"\n",
    "    model.fit(train_features, train_labels)  # 训练模型\n",
    "    clf_train_preds = model.predict(train_features)  # 在训练集上进行预测\n",
    "    clf_test_preds = model.predict(test_features)  # 在测试集上进行预测\n",
    "    # 打印训练集和测试集的准确率\n",
    "    print(f\"Training Set Accuracy: {accuracy_score(train_labels, clf_train_preds)}\")\n",
    "    print(f\"Test Set Accuracy: {accuracy_score(test_labels, clf_test_preds)}\")\n",
    "\n",
    "# 初始化用于训练和测试的特征和标签变量。\n",
    "train_X, train_Y = x_mor_train, y_mor_train  # 训练集特征和标签\n",
    "test_X, test_Y = x_mor_test, y_mor_test  # 测试集特征和标签\n",
    "\n",
    "# 执行训练和评估。\n",
    "train_and_evaluate(KNN, train_X, train_Y, test_X, test_Y)\n",
    "\n",
    "# 定义一个函数进行交叉验证和成绩的保存。\n",
    "# 修改perform_cross_validation函数的调用，传入n_splits参数。\n",
    "def perform_cross_validation(model, train_features, train_labels, n_splits, folder):\n",
    "    \"\"\"执行交叉验证和成绩处理。\"\"\"\n",
    "    cv_strategy = StratifiedKFold(n_splits=n_splits)  # 使用分层k折交叉验证\n",
    "    # 定义评分方法\n",
    "    scoring_methods = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': make_scorer(precision_score, average='macro'),\n",
    "        'recall': make_scorer(recall_score, average='macro'),\n",
    "        'roc_auc': 'roc_auc_ovr',\n",
    "        'f1': make_scorer(f1_score, average='macro'),\n",
    "        'matthews_corrcoef': make_scorer(matthews_corrcoef),\n",
    "        'specificity': make_scorer(specificity_score)  # 添加特异性评分\n",
    "    }\n",
    "    # 执行交叉验证\n",
    "    scores = cross_validate(model, train_features, train_labels, scoring=scoring_methods, cv=cv_strategy)\n",
    "    # 格式化分数并返回结果\n",
    "    formatted_scores = {key.split('_')[-1]: scores[key] for key in scores if key.startswith('test_')}\n",
    "    # 注意这里传入n_splits\n",
    "    return process_all_scores(formatted_scores, model.__class__.__name__, folder, n_splits)\n",
    "\n",
    "# 执行5折交叉验证然后是10折交叉验证。\n",
    "# 注意这里传入n_splits参数到process_all_scores函数。\n",
    "results_5_fold = perform_cross_validation(KNN, train_X, train_Y, 5, \"./KNN\")  # 5折交叉验证结果\n",
    "results_10_fold = perform_cross_validation(KNN, train_X, train_Y, 10, \"./KNN\")  # 10折交叉验证结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457e3df-b221-480e-8abc-0e58b3ab67bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def train_and_evaluate(model, train_features, train_labels, test_features, test_labels, output_file):\n",
    "    \"\"\"训练模型并评估其在训练集和测试集上的性能，包括多种评估指标，并将结果保存到CSV文件。\"\"\"\n",
    "    model.fit(train_features, train_labels)  # 训练模型\n",
    "    clf_train_preds = model.predict(train_features)  # 在训练集上进行预测\n",
    "    clf_test_preds = model.predict(test_features)  # 在测试集上进行预测\n",
    "    \n",
    "    # 计算训练集上的性能指标\n",
    "    metrics = {\n",
    "        'Train_Accuracy': accuracy_score(train_labels, clf_train_preds),\n",
    "        'Train_Precision': precision_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_Recall': recall_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_F1': f1_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_MCC': matthews_corrcoef(train_labels, clf_train_preds),\n",
    "        'Train_Specificity': specificity_score(train_labels, clf_train_preds),\n",
    "        'Train_ROC_AUC': roc_auc_score(train_labels, model.predict_proba(train_features)[:, 1], multi_class='ovr'),\n",
    "        \n",
    "        'Test_Accuracy': accuracy_score(test_labels, clf_test_preds),\n",
    "        'Test_Precision': precision_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_Recall': recall_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_F1': f1_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_MCC': matthews_corrcoef(test_labels, clf_test_preds),\n",
    "        'Test_Specificity': specificity_score(test_labels, clf_test_preds),\n",
    "        'Test_ROC_AUC': roc_auc_score(test_labels, model.predict_proba(test_features)[:, 1], multi_class='ovr')\n",
    "    }\n",
    "    \n",
    "    # 将字典转换为DataFrame并保存到CSV文件\n",
    "    df = pd.DataFrame([metrics])\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Metrics saved to {output_file}\")\n",
    "\n",
    "# 执行训练和评估，输出结果\n",
    "train_and_evaluate(KNN, train_X, train_Y, test_X, test_Y,\"./KNN/训练和评估.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e368c3-03cf-4a0d-a4ec-735dbbfdf29b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "estimator = KNN\n",
    "estimator.fit(train_X, train_Y)\n",
    "clf_test = estimator.predict(test_X)\n",
    "acc_test = accuracy_score(test_Y,clf_test)\n",
    "roc_test = roc_auc_score(test_Y,clf_test)\n",
    "pre_test = precision_score(test_Y,clf_test)\n",
    "rec_test = recall_score(test_Y,clf_test)\n",
    "f1_test = f1_score(test_Y,clf_test)\n",
    "mcc_test = matthews_corrcoef(test_Y,clf_test)\n",
    "matrix_test = confusion_matrix(test_Y,clf_test)\n",
    "ap_test = average_precision_score(test_Y,clf_test)\n",
    "\n",
    "algorithm_model = [KNN]\n",
    "algorithm_name = [\"KNN\"]\n",
    "tmp_1 = np.zeros((1,2))\n",
    "Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(2))\n",
    "tmp_2 = np.zeros((1,2))\n",
    "Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(2))\n",
    "tmp_3 = np.zeros((1,2))\n",
    "Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(2))  \n",
    "tmp_4 = np.zeros((1,2))\n",
    "Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(2)) \n",
    "tmp_5 = np.zeros((1,2))\n",
    "F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(2))\n",
    "tmp_6 = np.zeros((1,2))\n",
    "MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(2))\n",
    "tmp_7 = np.zeros((1,2))\n",
    "Ap_data = pd.DataFrame(tmp_7,index=algorithm_name,columns=range(2))\n",
    "\n",
    "Auc_data.loc[algorithm_name]  = roc_test\n",
    "Acc_data.loc[algorithm_name]  = acc_test\n",
    "Recall_data.loc[algorithm_name] = rec_test\n",
    "Precision_data.loc[algorithm_name] = pre_test\n",
    "F1_data.loc[algorithm_name]  = f1_test\n",
    "MCC_data.loc[algorithm_name]  = mcc_test\n",
    "Ap_data.loc[algorithm_name]  = ap_test\n",
    "\n",
    "Auc_data.to_csv(\"./KNN/test_ROC.csv\")\n",
    "Acc_data.to_csv(\"./KNN/test_ACC.csv\")\n",
    "Recall_data.to_csv(\"./KNN/test_REC.csv\")\n",
    "Precision_data.to_csv(\"./KNN/test_PRE.csv\")\n",
    "F1_data.to_csv(\"./KNN/test_F1.csv\")\n",
    "MCC_data.to_csv(\"./KNN/test_MCC.csv\")\n",
    "Ap_data.to_csv(\"./KNN/test_AP.csv\")\n",
    "\n",
    "clf_train = estimator.predict(train_X)\n",
    "acc_train = accuracy_score(train_Y,clf_train)\n",
    "roc_train = roc_auc_score(train_Y,clf_train)\n",
    "pre_train = precision_score(train_Y,clf_train)\n",
    "rec_train = recall_score(train_Y,clf_train)\n",
    "f1_train = f1_score(train_Y,clf_train)\n",
    "mcc_train = matthews_corrcoef(train_Y,clf_train)\n",
    "matrix_train = confusion_matrix(train_Y,clf_train)\n",
    "ap_train = average_precision_score(train_Y,clf_train)\n",
    "\n",
    "tmp_1 = np.zeros((1,2))\n",
    "Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(2))\n",
    "tmp_2 = np.zeros((1,2))\n",
    "Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(2))\n",
    "tmp_3 = np.zeros((1,2))\n",
    "Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(2))  \n",
    "tmp_4 = np.zeros((1,2))\n",
    "Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(2)) \n",
    "tmp_5 = np.zeros((1,2))\n",
    "F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(2))\n",
    "tmp_6 = np.zeros((1,2))\n",
    "MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(2))\n",
    "tmp_7 = np.zeros((1,2))\n",
    "Ap_data = pd.DataFrame(tmp_7,index=algorithm_name,columns=range(2))\n",
    "\n",
    "Auc_data.loc[algorithm_name]  = roc_train\n",
    "Acc_data.loc[algorithm_name]  = acc_train\n",
    "Recall_data.loc[algorithm_name] = rec_train\n",
    "Precision_data.loc[algorithm_name] = pre_train\n",
    "F1_data.loc[algorithm_name]  = f1_train\n",
    "MCC_data.loc[algorithm_name]  = mcc_train\n",
    "Ap_data.loc[algorithm_name]  = ap_train\n",
    "\n",
    "Auc_data.to_csv(\"./KNN/train_ROC.csv\")\n",
    "Acc_data.to_csv(\"./KNN/train_ACC.csv\")\n",
    "Recall_data.to_csv(\"./KNN/train_REC.csv\")\n",
    "Precision_data.to_csv(\"./KNN/train_PRE.csv\")\n",
    "F1_data.to_csv(\"./KNN/train_F1.csv\")\n",
    "MCC_data.to_csv(\"./KNN/train_MCC.csv\")\n",
    "Ap_data.to_csv(\"./KNN/train_AP.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb1a5f2-e2e5-439b-b269-15fa80eb5ed4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SVM参数搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97787f3-5ad2-4e5d-aa81-c0bdff877bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# def SVC_model(X,Y):  \n",
    "    \n",
    "#     # 首先实例化各个回归方法\n",
    "#     SVC_auto = SVC(random_state=0,probability=True)\n",
    "#     param_dict = {\n",
    "#                 \"gamma\":['scale','auto'],\n",
    "#                 \"kernel\":[ 'linear', 'poly','rbf', 'sigmoid'],      #, 'precomputed' 这个参数对于X有额外的要求\n",
    "#                 \"shrinking\":[True, False],\n",
    "#                 \"class_weight\":['none','balanced'],\n",
    "#                  }\n",
    "#     estimator = GridSearchCV(estimator = SVC_auto, param_grid=param_dict, cv=cv,n_jobs=-1,scoring = \"roc_auc\")\n",
    "#     estimator.fit(X,Y)\n",
    "#     return estimator.best_params_,estimator.best_score_,estimator.best_estimator_\n",
    "\n",
    "# tmp_1,tmp_2,SVC_auto = SVC_model(X,Y)\n",
    "# print(tmp_1,tmp_2,SVC_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02177292-f2a7-4d53-8127-81c6bc0cb404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from time import time\n",
    "begin_time = time()\n",
    "# Search optimal hyperparameter\n",
    "SVC_auto = SVC(random_state=0,probability=True)\n",
    "\n",
    "random_forest_hp_range={ \"gamma\":['scale','auto'],\n",
    "                 'C': [0.1, 1, 10, 50,100],  \n",
    "                \"kernel\":[ 'linear', 'rbf', 'sigmoid'],      #, 'precomputed' 这个参数对于X有额外的要求\n",
    "                \"shrinking\":[True, False],\n",
    "                \"class_weight\":['none','balanced'],\n",
    "                       }\n",
    "print(random_forest_hp_range)\n",
    "\n",
    "estimator_all_roc = GridSearchCV(estimator=SVC_auto,\n",
    "                                 param_grid=random_forest_hp_range,\n",
    "                                 cv=cv,\n",
    "                                 n_jobs=-1,\n",
    "                                 scoring=\"roc_auc\",verbose=1)\n",
    "# %%time\n",
    "estimator_all_roc.fit(X, Y)\n",
    "end_time = time()\n",
    "print({end_time - begin_time})\n",
    "print(estimator_all_roc.best_params_)\n",
    "print(estimator_all_roc.best_score_)\n",
    "tmp = pd.DataFrame(estimator_all_roc.cv_results_)\n",
    "df_fig = tmp[[\"mean_test_score\",\"params\"]]\n",
    "df_fig.to_csv(\"./SVM/tmp2-svm.csv\",index=False)\n",
    "df_fig[\"gamma\"] = 1\n",
    "#df_fig[\"C\"] = 1\n",
    "df_fig['kernel'] = 1\n",
    "df_fig[\"shrinking\"] = 1\n",
    "df_fig['class_weight']=1\n",
    "for i in range(0,df_fig.shape[0]):\n",
    "    dict_tmp = df_fig[\"params\"].iloc[i]\n",
    "    df_fig[\"gamma\"].iloc[i] = dict_tmp[\"gamma\"]\n",
    "    #df_fig[\"C\"].iloc[i] = dict_tmp[\"C\"]\n",
    "    df_fig[\"kernel\"].iloc[i] = dict_tmp[\"kernel\"]\n",
    "    df_fig[\"shrinking\"].iloc[i] = dict_tmp[\"shrinking\"]\n",
    "    df_fig['class_weight'].iloc[i]=dict_tmp['class_weight']\n",
    "df_fig.head(50)\n",
    "df_fig.to_csv(\"./SVM/网格搜索结果SVM.csv\",index=False)\n",
    "df_fig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad23596-7133-4a75-98bb-6d4169ce032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimator_all_roc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63c1f22-0f2f-4823-95a2-d2b4ad482084",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X = x_mor_train\n",
    "train_Y = y_mor_train\n",
    "test_X = x_mor_test\n",
    "test_Y = y_mor_test\n",
    "from sklearn.svm import SVC\n",
    "SVM = SVC(random_state = 0,\n",
    "                            class_weight = 'balanced',\n",
    "                            gamma = 'scale',\n",
    "                            C = 10 ,\n",
    "                            kernel = 'rbf',\n",
    "                            shrinking = True,\n",
    "                            probability=True\n",
    "                         )\n",
    "estimator = SVM\n",
    "estimator.fit(train_X, train_Y)\n",
    "clf_train = estimator.predict(train_X)\n",
    "clf_test = estimator.predict(test_X)\n",
    "print(f\"训练集准确度是{accuracy_score(train_Y,clf_train)}\")\n",
    "print(f\"测试集准确度是{accuracy_score(test_Y,clf_test)}\")\n",
    "train_matrix = confusion_matrix(train_Y, clf_train)\n",
    "test_matrix = confusion_matrix(test_Y, clf_test)\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(train_matrix, annot=True, cmap=\"Blues\", cbar=None,fmt=\"d\")  \n",
    "#cbar=None 就会不显示色条,fmt=\"d\"确保中间现实数字\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title(\"Confusion Matrix of Train\")\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(test_matrix, annot=True, cmap=\"Blues\", cbar=None,fmt=\"d\")  \n",
    "#cbar=None 就会不显示色条,fmt=\"d\"确保中间现实数字\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title(\"Confusion Matrix of Test\")\n",
    "plt.savefig(\"./SVM/混淆矩阵_SVM.svg\", dpi = 600)\n",
    "plt.show()\n",
    "\n",
    "#########  ROC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "# 训练集 ROC 图\n",
    "plt.subplot(1, 2, 1)\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]  # 获取训练集的预测概率\n",
    "fpr_train, tpr_train, _ = roc_curve(train_Y, y_pro_train)  # 计算 ROC 曲线的参数\n",
    "roc_auc_train = auc(fpr_train, tpr_train)  # 计算 AUC\n",
    "plt.plot(fpr_train, tpr_train, label='SVM-Train (AUC = %0.3f)' % roc_auc_train)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 绘制测试集 ROC 图\n",
    "plt.subplot(1, 2, 2)\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]  # 获取测试集的预测概率\n",
    "fpr_test, tpr_test, _ = roc_curve(test_Y, y_pro_test)  # 计算 ROC 曲线的参数\n",
    "roc_auc_test = auc(fpr_test, tpr_test)  # 计算 AUC\n",
    "plt.plot(fpr_test, tpr_test, label='SVM-Test (AUC = %0.3f)' % roc_auc_test)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.savefig(\"./SVM/ROC_SVM.svg\", dpi=600)  # 保存图形为 SVG 格式文件\n",
    "plt.show()  # 显示图形\n",
    "\n",
    "##绘制组合图\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制 ROC 曲线\n",
    "plt.plot(fpr_train, tpr_train,color='#5D9C59', label='SVM-Train (AUC = %0.3f)' % roc_auc_train)\n",
    "plt.plot(fpr_test, tpr_test,color='#5463FF', label='SVM-Test (AUC = %0.3f)' % roc_auc_test)\n",
    "# 绘制对角线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 设置标题和标签\n",
    "plt.title('SVM-ECFPs', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('False Positive Rate', fontweight='bold', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontweight='bold', fontsize=15)\n",
    "plt.legend(loc='lower right')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./SVM/ROC_SVM_组合.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "# 训练集PR_AUC图\n",
    "plt.figure(figsize=(12, 5))\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]\n",
    "precision_train, recall_train, _ = precision_recall_curve(train_Y, y_pro_train, pos_label=1)\n",
    "pr_auc_train = auc(recall_train, precision_train)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(recall_train, precision_train, label='SVM-Train (PR_AUC = {:.3f})'.format(pr_auc_train))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "# 测试集PR_AUC图\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]\n",
    "precision_test, recall_test, _ = precision_recall_curve(test_Y, y_pro_test, pos_label=1)\n",
    "pr_auc_test = auc(recall_test, precision_test)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall_test, precision_test, label='SVM-Test (PR_AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./SVM/PR_SVM.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制训练集PR_AUC图\n",
    "plt.plot(recall_train, precision_train,color='#5D9C59', label='SVM-Train (PR-AUC = {:.3f})'.format(pr_auc_train))\n",
    "# 绘制测试集PR_AUC图\n",
    "plt.plot(recall_test, precision_test,color='#5463FF', label='SVM-Test (PR-AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('SVM-ECFPs', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Recall', fontweight='bold', fontsize=15)\n",
    "plt.ylabel('Precision', fontweight='bold', fontsize=15)\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./SVM/PR_SVM_组合.svg\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6033bb86-6ed8-4802-a9f1-6db5954afbf0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0bbf1d-2d5c-4d90-bd14-7f0d37f64042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef, make_scorer\n",
    "\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    return data\n",
    "\n",
    "def process_all_scores(score_dict, algorithm_name, folder):\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/5-CV-{metric.upper()}.csv\"\n",
    "        columns = [str(i) for i in range(len(values))]\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)\n",
    "    return results\n",
    "\n",
    "# 实际的数据和模型定义\n",
    "train_X = x_mor_train  \n",
    "train_Y = y_mor_train  \n",
    "model = SVM   \n",
    "\n",
    "# 定义5折交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# 评分函数\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'roc_auc': 'roc_auc_ovr',\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# 执行交叉验证\n",
    "scores = cross_validate(model, train_X, train_Y, scoring=scoring, cv=cv_strategy, return_estimator=False)\n",
    "\n",
    "# 格式化分数字典以使用在处理函数中\n",
    "formatted_scores = {key[5:]: scores[key] for key in scores.keys() if key.startswith('test_')}\n",
    "\n",
    "# 处理并保存分数\n",
    "results = process_all_scores(formatted_scores, \"SVM\", \"./SVM/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf0b8d8-3059-47e6-b6d4-91e59c88e145",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 10折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e0cae8-8479-4481-8c31-89ebb029aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef, make_scorer\n",
    "\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    return data\n",
    "\n",
    "def process_all_scores(score_dict, algorithm_name, folder):\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/10-CV-{metric.upper()}.csv\"\n",
    "        columns = [str(i) for i in range(len(values))]\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)\n",
    "    return results\n",
    "\n",
    "# 实际的数据和模型定义\n",
    "train_X = x_mor_train  \n",
    "train_Y = y_mor_train  \n",
    "model = SVM   ####修改模型\n",
    "\n",
    "# 定义10折交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# 评分函数\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'roc_auc': 'roc_auc_ovr',\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# 执行交叉验证\n",
    "scores = cross_validate(model, train_X, train_Y, scoring=scoring, cv=cv_strategy, return_estimator=False)\n",
    "\n",
    "# 格式化分数字典以使用在处理函数中\n",
    "formatted_scores = {key[5:]: scores[key] for key in scores.keys() if key.startswith('test_')}\n",
    "\n",
    "# 处理并保存分数\n",
    "results = process_all_scores(formatted_scores, \"SVM\", \"./SVM/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea29290-77ae-46f4-9f00-9e5e49562111",
   "metadata": {},
   "source": [
    "### 在外部测试集上的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e950d3-8d15-4415-9801-15571cecdb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 忽略特定类型的警告\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "\n",
    "# 导入机器学习库scikit-learn中的SVM分类器和其他必要的工具包\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    roc_auc_score, f1_score, matthews_corrcoef, \n",
    "    make_scorer, confusion_matrix\n",
    ")\n",
    "import pandas as pd  # 导入数据处理库pandas\n",
    "import numpy as np  # 导入数值计算库numpy\n",
    "\n",
    "# 定义特异性评分函数\n",
    "def specificity_score(y_true, y_pred):\n",
    "    \"\"\"计算特异性（Specificity）.\"\"\"\n",
    "    tn, fp, _, _ = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "\n",
    "# 定义一个函数用于保存训练集交叉验证的分数到CSV文件，并且打印/保存平均值。\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    \"\"\"将交叉验证的成绩保存到CSV文件中。\"\"\"\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)  # 计算平均分并添加为新列\n",
    "    data.to_csv(file_path, index=False)  # 将DataFrame保存为CSV文件\n",
    "    print(f\"Data saved to {file_path}\")  # 打印保存信息\n",
    "    return data\n",
    "\n",
    "# 定义一个函数来处理所有成绩指标并使用`save_cv_scores`函数保存它们。\n",
    "# 修改process_all_scores函数，添加n_splits参数以反映正确的折数。\n",
    "def process_all_scores(score_dict, algorithm_name, folder, n_splits):\n",
    "    \"\"\"处理所有成绩指标并将其保存到CSV文件中。\"\"\"\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/{n_splits}-CV-{metric.upper()}.csv\"  # 使用传入的n_splits来构造文件名\n",
    "        columns = [str(i+1) for i in range(len(values))]  # 创建列名列表\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)  # 保存成绩并添加到结果字典\n",
    "    return results\n",
    "\n",
    "# # 实例化一个AdaBoost分类器，使用最优参数。\n",
    "# ada_classifier = AdaBoostClassifier(\n",
    "#     random_state=0,  # 确保结果可复现\n",
    "#     algorithm='SAMME',  # 使用的算法类型\n",
    "#     learning_rate=1.5,  # 学习率\n",
    "#     n_estimators=403  # 迭代次数，即使用的弱学习器的数量\n",
    "# )\n",
    "\n",
    "# 初始化SVM模型并设置参数\n",
    "SVM = SVC(random_state = 0,\n",
    "                            class_weight = 'balanced',\n",
    "                            gamma = 'scale',\n",
    "                            C = 10 ,\n",
    "                            kernel = 'rbf',\n",
    "                            shrinking = True,\n",
    "                            probability=True\n",
    "                         )\n",
    "\n",
    "# 使用SVM分类器进行训练和预测。\n",
    "def train_and_evaluate(model, train_features, train_labels, test_features, test_labels):\n",
    "    \"\"\"训练模型并评估其在训练集和测试集上的性能。\"\"\"\n",
    "    model.fit(train_features, train_labels)  # 训练模型\n",
    "    clf_train_preds = model.predict(train_features)  # 在训练集上进行预测\n",
    "    clf_test_preds = model.predict(test_features)  # 在测试集上进行预测\n",
    "    # 打印训练集和测试集的准确率\n",
    "    print(f\"Training Set Accuracy: {accuracy_score(train_labels, clf_train_preds)}\")\n",
    "    print(f\"Test Set Accuracy: {accuracy_score(test_labels, clf_test_preds)}\")\n",
    "\n",
    "# 初始化用于训练和测试的特征和标签变量。\n",
    "train_X, train_Y = x_mor_train, y_mor_train  # 训练集特征和标签\n",
    "test_X, test_Y = x_mor_test, y_mor_test  # 测试集特征和标签\n",
    "\n",
    "# 执行训练和评估。\n",
    "train_and_evaluate(SVM, train_X, train_Y, test_X, test_Y)\n",
    "\n",
    "# 定义一个函数进行交叉验证和成绩的保存。\n",
    "# 修改perform_cross_validation函数的调用，传入n_splits参数。\n",
    "def perform_cross_validation(model, train_features, train_labels, n_splits, folder):\n",
    "    \"\"\"执行交叉验证和成绩处理。\"\"\"\n",
    "    cv_strategy = StratifiedKFold(n_splits=n_splits)  # 使用分层k折交叉验证\n",
    "    # 定义评分方法\n",
    "    scoring_methods = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': make_scorer(precision_score, average='macro'),\n",
    "        'recall': make_scorer(recall_score, average='macro'),\n",
    "        'roc_auc': 'roc_auc_ovr',\n",
    "        'f1': make_scorer(f1_score, average='macro'),\n",
    "        'matthews_corrcoef': make_scorer(matthews_corrcoef),\n",
    "        'specificity': make_scorer(specificity_score)  # 添加特异性评分\n",
    "    }\n",
    "    # 执行交叉验证\n",
    "    scores = cross_validate(model, train_features, train_labels, scoring=scoring_methods, cv=cv_strategy)\n",
    "    # 格式化分数并返回结果\n",
    "    formatted_scores = {key.split('_')[-1]: scores[key] for key in scores if key.startswith('test_')}\n",
    "    # 注意这里传入n_splits\n",
    "    return process_all_scores(formatted_scores, model.__class__.__name__, folder, n_splits)\n",
    "\n",
    "# 执行5折交叉验证然后是10折交叉验证。\n",
    "# 注意这里传入n_splits参数到process_all_scores函数。\n",
    "results_5_fold = perform_cross_validation(SVM, train_X, train_Y, 5, \"./SVM\")  # 5折交叉验证结果\n",
    "results_10_fold = perform_cross_validation(SVM, train_X, train_Y, 10, \"./SVM\")  # 10折交叉验证结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b891dd43-d904-4b23-88b2-1a98d64dfae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def train_and_evaluate(model, train_features, train_labels, test_features, test_labels, output_file):\n",
    "    \"\"\"训练模型并评估其在训练集和测试集上的性能，包括多种评估指标，并将结果保存到CSV文件。\"\"\"\n",
    "    model.fit(train_features, train_labels)  # 训练模型\n",
    "    clf_train_preds = model.predict(train_features)  # 在训练集上进行预测\n",
    "    clf_test_preds = model.predict(test_features)  # 在测试集上进行预测\n",
    "    \n",
    "    # 计算训练集上的性能指标\n",
    "    metrics = {\n",
    "        'Train_Accuracy': accuracy_score(train_labels, clf_train_preds),\n",
    "        'Train_Precision': precision_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_Recall': recall_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_F1': f1_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_MCC': matthews_corrcoef(train_labels, clf_train_preds),\n",
    "        'Train_Specificity': specificity_score(train_labels, clf_train_preds),\n",
    "        'Train_ROC_AUC': roc_auc_score(train_labels, model.predict_proba(train_features)[:, 1], multi_class='ovr'),\n",
    "        \n",
    "        'Test_Accuracy': accuracy_score(test_labels, clf_test_preds),\n",
    "        'Test_Precision': precision_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_Recall': recall_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_F1': f1_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_MCC': matthews_corrcoef(test_labels, clf_test_preds),\n",
    "        'Test_Specificity': specificity_score(test_labels, clf_test_preds),\n",
    "        'Test_ROC_AUC': roc_auc_score(test_labels, model.predict_proba(test_features)[:, 1], multi_class='ovr')\n",
    "    }\n",
    "    \n",
    "    # 将字典转换为DataFrame并保存到CSV文件\n",
    "    df = pd.DataFrame([metrics])\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Metrics saved to {output_file}\")\n",
    "\n",
    "# 执行训练和评估，输出结果\n",
    "train_and_evaluate(SVM, train_X, train_Y, test_X, test_Y,\"./SVM/训练和评估.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a839521c-2587-4a64-bcae-69181387dae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "estimator = SVM\n",
    "estimator.fit(train_X, train_Y)\n",
    "clf_test = estimator.predict(test_X)\n",
    "acc_test = accuracy_score(test_Y,clf_test)\n",
    "roc_test = roc_auc_score(test_Y,clf_test)\n",
    "pre_test = precision_score(test_Y,clf_test)\n",
    "rec_test = recall_score(test_Y,clf_test)\n",
    "f1_test = f1_score(test_Y,clf_test)\n",
    "mcc_test = matthews_corrcoef(test_Y,clf_test)\n",
    "matrix_test = confusion_matrix(test_Y,clf_test)\n",
    "ap_test = average_precision_score(test_Y,clf_test)\n",
    "\n",
    "algorithm_model = [SVM]\n",
    "algorithm_name = [\"SVM\"]\n",
    "tmp_1 = np.zeros((1,2))\n",
    "Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(2))\n",
    "tmp_2 = np.zeros((1,2))\n",
    "Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(2))\n",
    "tmp_3 = np.zeros((1,2))\n",
    "Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(2))  \n",
    "tmp_4 = np.zeros((1,2))\n",
    "Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(2)) \n",
    "tmp_5 = np.zeros((1,2))\n",
    "F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(2))\n",
    "tmp_6 = np.zeros((1,2))\n",
    "MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(2))\n",
    "tmp_7 = np.zeros((1,2))\n",
    "Ap_data = pd.DataFrame(tmp_7,index=algorithm_name,columns=range(2))\n",
    "\n",
    "Auc_data.loc[algorithm_name]  = roc_test\n",
    "Acc_data.loc[algorithm_name]  = acc_test\n",
    "Recall_data.loc[algorithm_name] = rec_test\n",
    "Precision_data.loc[algorithm_name] = pre_test\n",
    "F1_data.loc[algorithm_name]  = f1_test\n",
    "MCC_data.loc[algorithm_name]  = mcc_test\n",
    "Ap_data.loc[algorithm_name]  = ap_test\n",
    "\n",
    "Auc_data.to_csv(\"./SVM/test_ROC.csv\")\n",
    "Acc_data.to_csv(\"./SVM/test_ACC.csv\")\n",
    "Recall_data.to_csv(\"./SVM/test_REC.csv\")\n",
    "Precision_data.to_csv(\"./SVM/test_PRE.csv\")\n",
    "F1_data.to_csv(\"./SVM/test_F1.csv\")\n",
    "MCC_data.to_csv(\"./SVM/test_MCC.csv\")\n",
    "Ap_data.to_csv(\"./SVM/test_AP.csv\")\n",
    "\n",
    "clf_train = estimator.predict(train_X)\n",
    "acc_train = accuracy_score(train_Y,clf_train)\n",
    "roc_train = roc_auc_score(train_Y,clf_train)\n",
    "pre_train = precision_score(train_Y,clf_train)\n",
    "rec_train = recall_score(train_Y,clf_train)\n",
    "f1_train = f1_score(train_Y,clf_train)\n",
    "mcc_train = matthews_corrcoef(train_Y,clf_train)\n",
    "matrix_train = confusion_matrix(train_Y,clf_train)\n",
    "ap_train = average_precision_score(train_Y,clf_train)\n",
    "\n",
    "tmp_1 = np.zeros((1,2))\n",
    "Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(2))\n",
    "tmp_2 = np.zeros((1,2))\n",
    "Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(2))\n",
    "tmp_3 = np.zeros((1,2))\n",
    "Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(2))  \n",
    "tmp_4 = np.zeros((1,2))\n",
    "Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(2)) \n",
    "tmp_5 = np.zeros((1,2))\n",
    "F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(2))\n",
    "tmp_6 = np.zeros((1,2))\n",
    "MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(2))\n",
    "tmp_7 = np.zeros((1,2))\n",
    "Ap_data = pd.DataFrame(tmp_7,index=algorithm_name,columns=range(2))\n",
    "\n",
    "Auc_data.loc[algorithm_name]  = roc_train\n",
    "Acc_data.loc[algorithm_name]  = acc_train\n",
    "Recall_data.loc[algorithm_name] = rec_train\n",
    "Precision_data.loc[algorithm_name] = pre_train\n",
    "F1_data.loc[algorithm_name]  = f1_train\n",
    "MCC_data.loc[algorithm_name]  = mcc_train\n",
    "Ap_data.loc[algorithm_name]  = ap_train\n",
    "\n",
    "Auc_data.to_csv(\"./SVM/train_ROC.csv\")\n",
    "Acc_data.to_csv(\"./SVM/train_ACC.csv\")\n",
    "Recall_data.to_csv(\"./SVM/train_REC.csv\")\n",
    "Precision_data.to_csv(\"./SVM/train_PRE.csv\")\n",
    "F1_data.to_csv(\"./SVM/train_F1.csv\")\n",
    "MCC_data.to_csv(\"./SVM/train_MCC.csv\")\n",
    "Ap_data.to_csv(\"./SVM/train_AP.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2a40da-c5a5-4db0-a7a5-50715ec228bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# RF参数搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6155d242-a413-467c-8ae5-63f7d4049c10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RandomForestClassifier_auto = RandomForestClassifier(random_state=0,n_jobs=-1)\n",
    "def RandomForestClassifier_model(X,Y):\n",
    "\n",
    "    # 首先实例化各个回归方法\n",
    "    param_dict = {\"criterion\":['gini','entropy'],\n",
    "                        \"max_features\":[\"log2\",'sqrt'],\n",
    "                        \"class_weight\":['balance','balanced_subsample'],\n",
    "                        \"bootstrap\":[True,False],\n",
    "                        \"oob_score\":[True,False]}\n",
    "    estimator = GridSearchCV(estimator = RandomForestClassifier_auto, param_grid=param_dict, cv=cv,n_jobs=-1,scoring = \"roc_auc\")\n",
    "    estimator.fit(X,Y)\n",
    "    return estimator.best_params_,estimator.best_score_,estimator.best_estimator_\n",
    "\n",
    "tmp_1,tmp_2,RandomforestClassifier_auto = RandomForestClassifier_model(X,Y)\n",
    "print(tmp_1,tmp_2,RandomForestClassifier_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808dc7a7-0dd3-431f-8f97-fdec8969c794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RandomForestClassifier_auto = RandomForestClassifier(random_state=0,n_jobs=-1)\n",
    "from time import time\n",
    "begin_time = time()\n",
    "# Search optimal hyperparameter\n",
    "n_estimators_range=[int(x) for x in np.linspace(start=10,stop=210,num=10)]\n",
    "max_depth_range=[int(x) for x in np.linspace(5,25,num=10)]\n",
    "min_samples_split_range=[int(x) for x in np.linspace(5,25,num=10)]\n",
    "min_samples_leaf_range=[3,4,5,6,7]\n",
    "# max_features=['sqrt','log2']\n",
    "# min_samples_leaf=\n",
    "RandomForestClassifier_auto = RandomForestClassifier(random_state=0,n_jobs=-1)\n",
    "\n",
    "random_forest_hp_range={'n_estimators':n_estimators_range,\n",
    "                        'max_depth':max_depth_range,\n",
    "                        'min_samples_split':min_samples_split_range,\n",
    "                        'min_samples_leaf':min_samples_leaf_range,\n",
    "                        \"criterion\":['entropy'],\n",
    "                        \"max_features\":['log2'],\n",
    "                        \"class_weight\":['balanced_subsample'],\n",
    "                        \"bootstrap\":[True],\n",
    "                        \"oob_score\":[True]\n",
    "                       }\n",
    "print(random_forest_hp_range)\n",
    "\n",
    "estimator_all_roc = GridSearchCV(estimator=RandomForestClassifier_auto,\n",
    "                                 param_grid=random_forest_hp_range,\n",
    "                                 cv=cv,\n",
    "                                 n_jobs=-1,\n",
    "                                 scoring=\"roc_auc\",verbose=1)\n",
    "# %%time\n",
    "estimator_all_roc.fit(X, Y)\n",
    "end_time = time()\n",
    "print({end_time - begin_time})\n",
    "print(estimator_all_roc.best_params_)\n",
    "print(estimator_all_roc.best_score_)\n",
    "tmp = pd.DataFrame(estimator_all_roc.cv_results_)\n",
    "df_fig = tmp[[\"mean_test_score\",\"params\"]]\n",
    "df_fig.to_csv(\"./RF/tmp2.csv\",index=False)\n",
    "df_fig[\"n_estimators\"] = 1\n",
    "df_fig['max_depth'] = 1\n",
    "df_fig[\"min_samples_split\"] = 1\n",
    "df_fig['min_samples_leaf']=1\n",
    "for i in range(0,df_fig.shape[0]):\n",
    "    dict_tmp = df_fig[\"params\"].iloc[i]\n",
    "    df_fig[\"n_estimators\"].iloc[i] = dict_tmp[\"n_estimators\"]\n",
    "    df_fig[\"max_depth\"].iloc[i] = dict_tmp[\"max_depth\"]\n",
    "    df_fig[\"min_samples_split\"].iloc[i] = dict_tmp[\"min_samples_split\"]\n",
    "    df_fig['min_samples_leaf'].iloc[i]=dict_tmp['min_samples_leaf']\n",
    "    \n",
    "df_fig.head(50)\n",
    "df_fig.to_csv(\"./RF/网格搜索结果RF.csv\",index=False)\n",
    "df_fig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb946473-85ef-4ac9-8b41-dad3bf4d7ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimator_all_roc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b368382f-e9f6-43aa-9a06-fc28f134d43b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X = x_mor_train\n",
    "train_Y = y_mor_train\n",
    "test_X = x_mor_test\n",
    "test_Y = y_mor_test\n",
    "\n",
    "RF = RandomForestClassifier(random_state = 0,\n",
    "                            class_weight = 'balanced_subsample',\n",
    "                            criterion = 'entropy',\n",
    "                            max_features = 'log2',\n",
    "                            bootstrap = True,\n",
    "                            max_depth = 20,\n",
    "                            min_samples_leaf = 3,\n",
    "                            min_samples_split = 5,\n",
    "                            n_estimators = 76,\n",
    "                            oob_score = True)\n",
    "\n",
    "estimator = RF\n",
    "estimator.fit(train_X, train_Y)\n",
    "clf_train = estimator.predict(train_X)\n",
    "clf_test = estimator.predict(test_X)\n",
    "print(f\"训练集准确度是{accuracy_score(train_Y,clf_train)}\")\n",
    "print(f\"测试集准确度是{accuracy_score(test_Y,clf_test)}\")\n",
    "train_matrix = confusion_matrix(train_Y, clf_train)\n",
    "test_matrix = confusion_matrix(test_Y, clf_test)\n",
    "\n",
    "plt.rc('axes', linewidth=1.5)\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(train_matrix, annot=True, cmap=\"Blues\", cbar=None,fmt=\"d\")\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title(\"Confusion Matrix of Train\")\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(test_matrix, annot=True, cmap=\"Blues\", cbar=None,fmt=\"d\")\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title(\"Confusion Matrix of Test\")\n",
    "plt.savefig(\"./RF/混淆矩阵_RF.svg\", dpi = 300)\n",
    "plt.show()\n",
    "\n",
    "#########  ROC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "# 训练集 ROC 图\n",
    "plt.subplot(1, 2, 1)\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]  # 获取训练集的预测概率\n",
    "fpr_train, tpr_train, _ = roc_curve(train_Y, y_pro_train)  # 计算 ROC 曲线的参数\n",
    "roc_auc_train = auc(fpr_train, tpr_train)  # 计算 AUC\n",
    "plt.plot(fpr_train, tpr_train, label='RF-Train (AUC = %0.3f)' % roc_auc_train)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 绘制测试集 ROC 图\n",
    "plt.subplot(1, 2, 2)\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]  # 获取测试集的预测概率\n",
    "fpr_test, tpr_test, _ = roc_curve(test_Y, y_pro_test)  # 计算 ROC 曲线的参数\n",
    "roc_auc_test = auc(fpr_test, tpr_test)  # 计算 AUC\n",
    "plt.plot(fpr_test, tpr_test, label='RF-Test (AUC = %0.3f)' % roc_auc_test)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('RF-PubchemFPs')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.savefig(\"./RF/ROC_RF.svg\", dpi=600)  # 保存图形为 SVG 格式文件\n",
    "plt.show()  # 显示图形\n",
    "\n",
    "##绘制组合图\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制 ROC 曲线\n",
    "plt.plot(fpr_train, tpr_train,color='#5D9C59', label='RF-Train (AUC = %0.3f)' % roc_auc_train)\n",
    "plt.plot(fpr_test, tpr_test,color='#5463FF', label='RF-Test (AUC = %0.3f)' % roc_auc_test)\n",
    "# 绘制对角线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 设置标题和标签\n",
    "plt.title('RF-ECFPs', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('False Positive Rate', fontweight='bold', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontweight='bold', fontsize=15)\n",
    "plt.legend(loc='lower right')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./RF/ROC_RF_组合.svg\", dpi=600)\n",
    "plt.show()\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "# 训练集PR_AUC图\n",
    "plt.figure(figsize=(12, 5))\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]\n",
    "precision_train, recall_train, _ = precision_recall_curve(train_Y, y_pro_train, pos_label=1)\n",
    "pr_auc_train = auc(recall_train, precision_train)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(recall_train, precision_train, label='RF-Train (PR_AUC = {:.3f})'.format(pr_auc_train))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "# 测试集PR_AUC图\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]\n",
    "precision_test, recall_test, _ = precision_recall_curve(test_Y, y_pro_test, pos_label=1)\n",
    "pr_auc_test = auc(recall_test, precision_test)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall_test, precision_test, label='RF-Test (PR_AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./RF/PR_RF.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制训练集PR_AUC图\n",
    "plt.plot(recall_train, precision_train,color='#5D9C59', label='RF-Train (PR-AUC = {:.3f})'.format(pr_auc_train))\n",
    "# 绘制测试集PR_AUC图\n",
    "plt.plot(recall_test, precision_test,color='#5463FF', label='RF-Test (PR-AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('RF-ECFPs', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Recall', fontweight='bold', fontsize=15)\n",
    "plt.ylabel('Precision', fontweight='bold', fontsize=15)\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./RF/PR_RF_组合.svg\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ffd821-8ccc-427a-b3e0-6754c9cd176a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e824f77-59dd-464a-922c-2954fb613293",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef, make_scorer\n",
    "\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    return data\n",
    "\n",
    "def process_all_scores(score_dict, algorithm_name, folder):\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/5-CV-{metric.upper()}.csv\"\n",
    "        columns = [str(i) for i in range(len(values))]\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)\n",
    "    return results\n",
    "\n",
    "# 实际的数据和模型定义\n",
    "train_X = x_mor_train  \n",
    "train_Y = y_mor_train  \n",
    "model = RF   \n",
    "\n",
    "# 定义5折交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# 评分函数\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'roc_auc': 'roc_auc_ovr',\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# 执行交叉验证\n",
    "scores = cross_validate(model, train_X, train_Y, scoring=scoring, cv=cv_strategy, return_estimator=False)\n",
    "\n",
    "# 格式化分数字典以使用在处理函数中\n",
    "formatted_scores = {key[5:]: scores[key] for key in scores.keys() if key.startswith('test_')}\n",
    "\n",
    "# 处理并保存分数\n",
    "results = process_all_scores(formatted_scores, \"RF\", \"./RF/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b15913-54eb-49e8-bd02-33b30045f36b",
   "metadata": {},
   "source": [
    "### 10折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8310f37c-fbe1-4dc6-bfca-863720bb9fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef, make_scorer\n",
    "\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    return data\n",
    "\n",
    "def process_all_scores(score_dict, algorithm_name, folder):\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/10-CV-{metric.upper()}.csv\"\n",
    "        columns = [str(i) for i in range(len(values))]\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)\n",
    "    return results\n",
    "\n",
    "# 实际的数据和模型定义\n",
    "train_X = x_mor_train  \n",
    "train_Y = y_mor_train  \n",
    "model = RF   ####修改模型\n",
    "\n",
    "# 定义10折交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# 评分函数\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'roc_auc': 'roc_auc_ovr',\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# 执行交叉验证\n",
    "scores = cross_validate(model, train_X, train_Y, scoring=scoring, cv=cv_strategy, return_estimator=False)\n",
    "\n",
    "# 格式化分数字典以使用在处理函数中\n",
    "formatted_scores = {key[5:]: scores[key] for key in scores.keys() if key.startswith('test_')}\n",
    "\n",
    "# 处理并保存分数\n",
    "results = process_all_scores(formatted_scores, \"RF\", \"./RF/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd0dd3b-e4ad-422c-b0f5-38515e3caab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 忽略特定类型的警告\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "\n",
    "# 导入机器学习库scikit-learn中的RF分类器和其他必要的工具包\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    roc_auc_score, f1_score, matthews_corrcoef, \n",
    "    make_scorer, confusion_matrix\n",
    ")\n",
    "import pandas as pd  # 导入数据处理库pandas\n",
    "import numpy as np  # 导入数值计算库numpy\n",
    "\n",
    "# 定义特异性评分函数\n",
    "def specificity_score(y_true, y_pred):\n",
    "    \"\"\"计算特异性（Specificity）.\"\"\"\n",
    "    tn, fp, _, _ = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "\n",
    "# 定义一个函数用于保存训练集交叉验证的分数到CSV文件，并且打印/保存平均值。\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    \"\"\"将交叉验证的成绩保存到CSV文件中。\"\"\"\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)  # 计算平均分并添加为新列\n",
    "    data.to_csv(file_path, index=False)  # 将DataFrame保存为CSV文件\n",
    "    print(f\"Data saved to {file_path}\")  # 打印保存信息\n",
    "    return data\n",
    "\n",
    "# 定义一个函数来处理所有成绩指标并使用`save_cv_scores`函数保存它们。\n",
    "# 修改process_all_scores函数，添加n_splits参数以反映正确的折数。\n",
    "def process_all_scores(score_dict, algorithm_name, folder, n_splits):\n",
    "    \"\"\"处理所有成绩指标并将其保存到CSV文件中。\"\"\"\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/{n_splits}-CV-{metric.upper()}.csv\"  # 使用传入的n_splits来构造文件名\n",
    "        columns = [str(i+1) for i in range(len(values))]  # 创建列名列表\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)  # 保存成绩并添加到结果字典\n",
    "    return results\n",
    "\n",
    "RF = RandomForestClassifier(random_state = 0,\n",
    "                            class_weight = 'balanced_subsample',\n",
    "                            criterion = 'entropy',\n",
    "                            max_features = 'log2',\n",
    "                            bootstrap = True,\n",
    "                            max_depth = 20,\n",
    "                            min_samples_leaf = 3,\n",
    "                            min_samples_split = 5,\n",
    "                            n_estimators = 76,\n",
    "                            oob_score = True)\n",
    "\n",
    "# 使用RF分类器进行训练和预测。\n",
    "def train_and_evaluate(model, train_features, train_labels, test_features, test_labels):\n",
    "    \"\"\"训练模型并评估其在训练集和测试集上的性能。\"\"\"\n",
    "    model.fit(train_features, train_labels)  # 训练模型\n",
    "    clf_train_preds = model.predict(train_features)  # 在训练集上进行预测\n",
    "    clf_test_preds = model.predict(test_features)  # 在测试集上进行预测\n",
    "    # 打印训练集和测试集的准确率\n",
    "    print(f\"Training Set Accuracy: {accuracy_score(train_labels, clf_train_preds)}\")\n",
    "    print(f\"Test Set Accuracy: {accuracy_score(test_labels, clf_test_preds)}\")\n",
    "\n",
    "# 初始化用于训练和测试的特征和标签变量。\n",
    "train_X, train_Y = x_mor_train, y_mor_train  # 训练集特征和标签\n",
    "test_X, test_Y = x_mor_test, y_mor_test  # 测试集特征和标签\n",
    "\n",
    "# 执行训练和评估。\n",
    "train_and_evaluate(RF, train_X, train_Y, test_X, test_Y)\n",
    "\n",
    "# 定义一个函数进行交叉验证和成绩的保存。\n",
    "# 修改perform_cross_validation函数的调用，传入n_splits参数。\n",
    "def perform_cross_validation(model, train_features, train_labels, n_splits, folder):\n",
    "    \"\"\"执行交叉验证和成绩处理。\"\"\"\n",
    "    cv_strategy = StratifiedKFold(n_splits=n_splits)  # 使用分层k折交叉验证\n",
    "    # 定义评分方法\n",
    "    scoring_methods = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': make_scorer(precision_score, average='macro'),\n",
    "        'recall': make_scorer(recall_score, average='macro'),\n",
    "        'roc_auc': 'roc_auc_ovr',\n",
    "        'f1': make_scorer(f1_score, average='macro'),\n",
    "        'matthews_corrcoef': make_scorer(matthews_corrcoef),\n",
    "        'specificity': make_scorer(specificity_score)  # 添加特异性评分\n",
    "    }\n",
    "    # 执行交叉验证\n",
    "    scores = cross_validate(model, train_features, train_labels, scoring=scoring_methods, cv=cv_strategy)\n",
    "    # 格式化分数并返回结果\n",
    "    formatted_scores = {key.split('_')[-1]: scores[key] for key in scores if key.startswith('test_')}\n",
    "    # 注意这里传入n_splits\n",
    "    return process_all_scores(formatted_scores, model.__class__.__name__, folder, n_splits)\n",
    "\n",
    "# 执行5折交叉验证然后是10折交叉验证。\n",
    "# 注意这里传入n_splits参数到process_all_scores函数。\n",
    "results_5_fold = perform_cross_validation(RF, train_X, train_Y, 5, \"./RF\")  # 5折交叉验证结果\n",
    "results_10_fold = perform_cross_validation(RF, train_X, train_Y, 10, \"./RF\")  # 10折交叉验证结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e6818-00d7-4227-ad2c-5363d8fceea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def train_and_evaluate(model, train_features, train_labels, test_features, test_labels, output_file):\n",
    "    \"\"\"训练模型并评估其在训练集和测试集上的性能，包括多种评估指标，并将结果保存到CSV文件。\"\"\"\n",
    "    model.fit(train_features, train_labels)  # 训练模型\n",
    "    clf_train_preds = model.predict(train_features)  # 在训练集上进行预测\n",
    "    clf_test_preds = model.predict(test_features)  # 在测试集上进行预测\n",
    "    \n",
    "    # 计算训练集上的性能指标\n",
    "    metrics = {\n",
    "        'Train_Accuracy': accuracy_score(train_labels, clf_train_preds),\n",
    "        'Train_Precision': precision_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_Recall': recall_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_F1': f1_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_MCC': matthews_corrcoef(train_labels, clf_train_preds),\n",
    "        'Train_Specificity': specificity_score(train_labels, clf_train_preds),\n",
    "        'Train_ROC_AUC': roc_auc_score(train_labels, model.predict_proba(train_features)[:, 1], multi_class='ovr'),\n",
    "        \n",
    "        'Test_Accuracy': accuracy_score(test_labels, clf_test_preds),\n",
    "        'Test_Precision': precision_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_Recall': recall_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_F1': f1_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_MCC': matthews_corrcoef(test_labels, clf_test_preds),\n",
    "        'Test_Specificity': specificity_score(test_labels, clf_test_preds),\n",
    "        'Test_ROC_AUC': roc_auc_score(test_labels, model.predict_proba(test_features)[:, 1], multi_class='ovr')\n",
    "    }\n",
    "    \n",
    "    # 将字典转换为DataFrame并保存到CSV文件\n",
    "    df = pd.DataFrame([metrics])\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Metrics saved to {output_file}\")\n",
    "\n",
    "# 执行训练和评估，输出结果\n",
    "train_and_evaluate(RF, train_X, train_Y, test_X, test_Y,\"./RF/训练和评估.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294cd342-20f1-42c3-a3fa-8060f9415e71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "estimator = RF\n",
    "estimator.fit(train_X, train_Y)\n",
    "clf_test = estimator.predict(test_X)\n",
    "acc_test = accuracy_score(test_Y,clf_test)\n",
    "roc_test = roc_auc_score(test_Y,clf_test)\n",
    "pre_test = precision_score(test_Y,clf_test)\n",
    "rec_test = recall_score(test_Y,clf_test)\n",
    "f1_test = f1_score(test_Y,clf_test)\n",
    "mcc_test = matthews_corrcoef(test_Y,clf_test)\n",
    "matrix_test = confusion_matrix(test_Y,clf_test)\n",
    "ap_test = average_precision_score(test_Y,clf_test)\n",
    "\n",
    "algorithm_model = [RF]\n",
    "algorithm_name = [\"RF\"]\n",
    "tmp_1 = np.zeros((1,2))\n",
    "Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(2))\n",
    "tmp_2 = np.zeros((1,2))\n",
    "Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(2))\n",
    "tmp_3 = np.zeros((1,2))\n",
    "Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(2))  \n",
    "tmp_4 = np.zeros((1,2))\n",
    "Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(2)) \n",
    "tmp_5 = np.zeros((1,2))\n",
    "F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(2))\n",
    "tmp_6 = np.zeros((1,2))\n",
    "MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(2))\n",
    "tmp_7 = np.zeros((1,2))\n",
    "Ap_data = pd.DataFrame(tmp_7,index=algorithm_name,columns=range(2))\n",
    "\n",
    "Auc_data.loc[algorithm_name]  = roc_test\n",
    "Acc_data.loc[algorithm_name]  = acc_test\n",
    "Recall_data.loc[algorithm_name] = rec_test\n",
    "Precision_data.loc[algorithm_name] = pre_test\n",
    "F1_data.loc[algorithm_name]  = f1_test\n",
    "MCC_data.loc[algorithm_name]  = mcc_test\n",
    "Ap_data.loc[algorithm_name]  = ap_test\n",
    "\n",
    "Auc_data.to_csv(\"./RF/test_ROC.csv\")\n",
    "Acc_data.to_csv(\"./RF/test_ACC.csv\")\n",
    "Recall_data.to_csv(\"./RF/test_REC.csv\")\n",
    "Precision_data.to_csv(\"./RF/test_PRE.csv\")\n",
    "F1_data.to_csv(\"./RF/test_F1.csv\")\n",
    "MCC_data.to_csv(\"./RF/test_MCC.csv\")\n",
    "Ap_data.to_csv(\"./RF/test_AP.csv\")\n",
    "\n",
    "clf_train = estimator.predict(train_X)\n",
    "acc_train = accuracy_score(train_Y,clf_train)\n",
    "roc_train = roc_auc_score(train_Y,clf_train)\n",
    "pre_train = precision_score(train_Y,clf_train)\n",
    "rec_train = recall_score(train_Y,clf_train)\n",
    "f1_train = f1_score(train_Y,clf_train)\n",
    "mcc_train = matthews_corrcoef(train_Y,clf_train)\n",
    "matrix_train = confusion_matrix(train_Y,clf_train)\n",
    "ap_train = average_precision_score(train_Y,clf_train)\n",
    "\n",
    "tmp_1 = np.zeros((1,2))\n",
    "Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(2))\n",
    "tmp_2 = np.zeros((1,2))\n",
    "Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(2))\n",
    "tmp_3 = np.zeros((1,2))\n",
    "Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(2))  \n",
    "tmp_4 = np.zeros((1,2))\n",
    "Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(2)) \n",
    "tmp_5 = np.zeros((1,2))\n",
    "F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(2))\n",
    "tmp_6 = np.zeros((1,2))\n",
    "MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(2))\n",
    "tmp_7 = np.zeros((1,2))\n",
    "Ap_data = pd.DataFrame(tmp_7,index=algorithm_name,columns=range(2))\n",
    "\n",
    "Auc_data.loc[algorithm_name]  = roc_train\n",
    "Acc_data.loc[algorithm_name]  = acc_train\n",
    "Recall_data.loc[algorithm_name] = rec_train\n",
    "Precision_data.loc[algorithm_name] = pre_train\n",
    "F1_data.loc[algorithm_name]  = f1_train\n",
    "MCC_data.loc[algorithm_name]  = mcc_train\n",
    "Ap_data.loc[algorithm_name]  = ap_train\n",
    "\n",
    "Auc_data.to_csv(\"./RF/train_ROC.csv\")\n",
    "Acc_data.to_csv(\"./RF/train_ACC.csv\")\n",
    "Recall_data.to_csv(\"./RF/train_REC.csv\")\n",
    "Precision_data.to_csv(\"./RF/train_PRE.csv\")\n",
    "F1_data.to_csv(\"./RF/train_F1.csv\")\n",
    "MCC_data.to_csv(\"./RF/train_MCC.csv\")\n",
    "Ap_data.to_csv(\"./RF/train_AP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "285e3b0c-048b-4287-afd1-f341f5d04d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RandomForest-ECFPs.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier(random_state = 0,\n",
    "                            class_weight = 'balanced_subsample',\n",
    "                            criterion = 'entropy',\n",
    "                            max_features = 'log2',\n",
    "                            bootstrap = True,\n",
    "                            max_depth = 20,\n",
    "                            min_samples_leaf = 3,\n",
    "                            min_samples_split = 5,\n",
    "                            n_estimators = 76,\n",
    "                            oob_score = True)\n",
    "RF.fit(x_mor_train, y_mor_train.values.ravel())  \n",
    "joblib.dump(RF, \"RandomForest-ECFPs.pkl\") # 保存模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afff39c-65ad-4933-8e55-9f0eb3f3ea2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# XGBoost参数搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1f5e13-eff8-433e-a182-c89088007677",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "xgb = XGBClassifier(\n",
    "    random_state=0,\n",
    "    objective='binary:logistic'\n",
    ")\n",
    "from time import time\n",
    "begin_time = time()\n",
    "\n",
    "learning_rate_range=[0.1]\n",
    "n_estimators_range=[int(x) for x in np.linspace(start=10,stop=210,num=10)]\n",
    "max_depth_range=[int(x) for x in np.linspace(3,23,num=10)]\n",
    "min_child_weight_range=[i for i in range(1,3,5)]\n",
    "gamma_range=[i/10.0 for i in range(0,10)]\n",
    "subsample_range=[i/10.0 for i in range(6,10)]\n",
    "colsample_bytree_range=[i/10.0 for i in range(6,10)]\n",
    "reg_alpha_range=[0.1]    \n",
    "reg_lambda_range=[0.1]    \n",
    "random_forest_hp_range={'n_estimators':n_estimators_range,\n",
    "                        'max_depth':max_depth_range,\n",
    "                        'min_child_weight':min_child_weight_range,\n",
    "                        'gamma':gamma_range,\n",
    "                        'subsample':subsample_range,\n",
    "                        'colsample_bytree':colsample_bytree_range,\n",
    "                        'reg_alpha':reg_alpha_range,\n",
    "                        'reg_lambda':reg_lambda_range\n",
    "                       }\n",
    "print(random_forest_hp_range)\n",
    "\n",
    "estimator_all_roc = GridSearchCV(estimator=xgb,\n",
    "                                 param_grid=random_forest_hp_range,\n",
    "                                 cv=cv,\n",
    "                                 n_jobs=-1,\n",
    "                                 scoring=\"roc_auc\",verbose=1)\n",
    "# %%time\n",
    "estimator_all_roc.fit(X, Y)\n",
    "end_time = time()\n",
    "print({end_time - begin_time})\n",
    "print(estimator_all_roc.best_params_)\n",
    "print(estimator_all_roc.best_score_)\n",
    "tmp = pd.DataFrame(estimator_all_roc.cv_results_)\n",
    "df_fig = tmp[[\"mean_test_score\",\"params\"]]\n",
    "df_fig.to_csv(\"./XGBoost/xgbtmp.csv\",index=False)\n",
    "df_fig = pd.read_csv(\"./XGBoost/xgbtmp.csv\")\n",
    "df_fig[\"colsample_bytree\"] = 1\n",
    "df_fig[\"gamma\"] = 1\n",
    "df_fig[\"max_depth\"] = 1\n",
    "df_fig[\"min_child_weight\"]=1\n",
    "df_fig[\"n_estimators\"]=1\n",
    "df_fig[\"reg_alpha\"]=1\n",
    "df_fig[\"reg_lambda\"]=1\n",
    "df_fig[\"subsample\"]=1\n",
    "for i in range(0,df_fig.shape[0]):\n",
    "    dict_tmp = df_fig['params'].iloc[i]\n",
    "    dict_tmp = eval(dict_tmp)\n",
    "    df_fig[\"colsample_bytree\"].iloc[i] = dict_tmp[\"colsample_bytree\"]\n",
    "    df_fig[\"gamma\"].iloc[i] = dict_tmp[\"gamma\"]\n",
    "    df_fig[\"max_depth\"].iloc[i] = dict_tmp[\"max_depth\"]\n",
    "    df_fig[\"min_child_weight\"].iloc[i] = dict_tmp[\"min_child_weight\"]\n",
    "    df_fig[\"n_estimators\"].iloc[i] = dict_tmp[\"n_estimators\"]\n",
    "    df_fig[\"reg_alpha\"].iloc[i] = dict_tmp[\"reg_alpha\"]\n",
    "    df_fig[\"reg_lambda\"].iloc[i] = dict_tmp[\"reg_lambda\"]\n",
    "    df_fig[\"subsample\"].iloc[i] = dict_tmp[\"subsample\"]\n",
    "        \n",
    "df_fig.head(50)\n",
    "df_fig.to_csv(\"./XGBoost/xgb网格搜索结果.csv\",index=False)\n",
    "df_fig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c2fe0a-eff0-4956-9677-a6aa8737b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimator_all_roc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17452db-5553-45fb-aa65-2bc889e2d7cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "train_X = x_mor_train  # 训练集特征数据\n",
    "train_Y = y_mor_train  # 训练集目标数据（标签）\n",
    "test_X = x_mor_test    # 测试集特征数据\n",
    "test_Y = y_mor_test    # 测试集目标数据（标签）\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    random_state=0,\n",
    "    objective='binary:logistic',\n",
    "    colsample_bytree = 0.7,\n",
    "    gamma = 0.4,\n",
    "    max_depth = 11,\n",
    "    min_child_weight = 1,\n",
    "    n_estimators = 10,\n",
    "    reg_alpha = 0.1,\n",
    "    reg_lambda = 0.1,\n",
    "    subsample = 0.7\n",
    ")\n",
    "# 训练模型\n",
    "estimator = xgb\n",
    "estimator.fit(train_X, train_Y)\n",
    "# 在训练集和测试集上进行预测\n",
    "clf_train = estimator.predict(train_X)\n",
    "clf_test = estimator.predict(test_X)\n",
    "print(f\"训练集准确度是{accuracy_score(train_Y,clf_train)}\")\n",
    "print(f\"测试集准确度是{accuracy_score(test_Y,clf_test)}\")\n",
    "\n",
    "# 生成训练集和测试集的混淆矩阵\n",
    "train_matrix = confusion_matrix(train_Y, clf_train)\n",
    "test_matrix = confusion_matrix(test_Y, clf_test)\n",
    "# 绘制混淆矩阵\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(train_matrix, annot=True, cmap=\"Blues\", cbar=None,fmt=\"d\") \n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title(\"Confusion Matrix of Train\")\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(test_matrix, annot=True, cmap=\"Blues\", cbar=None,fmt=\"d\")\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title(\"Confusion Matrix of Test\")\n",
    "plt.savefig(\"./XGBoost/混淆矩阵_XGB.svg\", dpi = 600)\n",
    "plt.show()\n",
    "\n",
    "#########  ROC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "# 训练集 ROC 图\n",
    "plt.subplot(1, 2, 1)\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]  # 获取训练集的预测概率\n",
    "fpr_train, tpr_train, _ = roc_curve(train_Y, y_pro_train)  # 计算 ROC 曲线的参数\n",
    "roc_auc_train = auc(fpr_train, tpr_train)  # 计算 AUC\n",
    "plt.plot(fpr_train, tpr_train, label='XGBoost-Train (AUC = %0.3f)' % roc_auc_train)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "\n",
    "# 绘制测试集 ROC 图\n",
    "plt.subplot(1, 2, 2)\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]  # 获取测试集的预测概率\n",
    "fpr_test, tpr_test, _ = roc_curve(test_Y, y_pro_test)  # 计算 ROC 曲线的参数\n",
    "roc_auc_test = auc(fpr_test, tpr_test)  # 计算 AUC\n",
    "plt.plot(fpr_test, tpr_test, label='XGBoost-Test (AUC = %0.3f)' % roc_auc_test)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.savefig(\"./XGBoost/ROC_XGBoost.svg\", dpi=600)  # 保存图形为 SVG 格式文件\n",
    "plt.show()  # 显示图形\n",
    "\n",
    "##绘制组合图\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制 ROC 曲线\n",
    "plt.plot(fpr_train, tpr_train,color='#5D9C59', label='XGBoost-Train (AUC = %0.3f)' % roc_auc_train)\n",
    "plt.plot(fpr_test, tpr_test,color='#5463FF', label='XGBoost-Test (AUC = %0.3f)' % roc_auc_test)\n",
    "# 绘制对角线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 设置标题和标签\n",
    "plt.title('XGBoost-ECFPs', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('False Positive Rate', fontweight='bold', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontweight='bold', fontsize=15)\n",
    "plt.legend(loc='lower right')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./XGBoost/ROC_XGBoost_组合.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "# 训练集PR_AUC图\n",
    "plt.figure(figsize=(12, 5))\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]\n",
    "precision_train, recall_train, _ = precision_recall_curve(train_Y, y_pro_train, pos_label=1)\n",
    "pr_auc_train = auc(recall_train, precision_train)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(recall_train, precision_train, label='XGBoost-Train (PR_AUC = {:.3f})'.format(pr_auc_train))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "\n",
    "# 测试集PR_AUC图\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]\n",
    "precision_test, recall_test, _ = precision_recall_curve(test_Y, y_pro_test, pos_label=1)\n",
    "pr_auc_test = auc(recall_test, precision_test)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall_test, precision_test, label='XGBoost-Test (PR_AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./XGBoost/PR_XGBoost.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制训练集PR_AUC图\n",
    "plt.plot(recall_train, precision_train,color='#5D9C59', label='XGBoost-Train (PR-AUC = {:.3f})'.format(pr_auc_train))\n",
    "# 绘制测试集PR_AUC图\n",
    "plt.plot(recall_test, precision_test,color='#5463FF', label='XGBoost-Test (PR-AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('XGBoost-ECFPs', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Recall', fontweight='bold', fontsize=15)\n",
    "plt.ylabel('Precision', fontweight='bold', fontsize=15)\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./XGBoost/PR_XGBoost_组合.svg\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ecd422-734b-4f53-86d7-c4ac909e1840",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 5折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999762c-8e2b-448b-a0c8-310bd12512b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_funcs = ['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'matthews_corrcoef']\n",
    "# scores = cross_validate(xgb,    #上一步定义的模型参数\n",
    "#                             train_X,\n",
    "#                             train_Y,\n",
    "#                             scoring=score_funcs,\n",
    "#                             cv=cv,             # 直接嫁接上面定义的 cv\n",
    "#                             return_estimator=True)\n",
    "    \n",
    "# model_acc =  scores['test_accuracy']\n",
    "# model_auc = scores['test_roc_auc']\n",
    "# model_recall =  scores['test_recall']\n",
    "# model_precision = scores['test_precision']\n",
    "# model_f1 = scores['test_f1']\n",
    "# model_mcc = scores['test_matthews_corrcoef']\n",
    "\n",
    "# algorithm_model = [xgb]\n",
    "# algorithm_name = [\"XGB\"]\n",
    "# tmp_1 = np.zeros((1,5))\n",
    "# Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(5))\n",
    "# tmp_2 = np.zeros((1,5))\n",
    "# Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(5))\n",
    "# tmp_3 = np.zeros((1,5))\n",
    "# Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(5))  \n",
    "# tmp_4 = np.zeros((1,5))\n",
    "# Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(5)) \n",
    "# tmp_5 = np.zeros((1,5))\n",
    "# F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(5))\n",
    "# tmp_6 = np.zeros((1,5))\n",
    "# MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(5))\n",
    "\n",
    "# for i in range(5):\n",
    "#     Acc_data[i].loc[algorithm_name]  = model_acc[i]\n",
    "#     Auc_data[i].loc[algorithm_name]  = model_auc[i]\n",
    "#     Recall_data[i].loc[algorithm_name] = model_recall[i]\n",
    "#     Precision_data[i].loc[algorithm_name] = model_precision[i]\n",
    "#     F1_data[i].loc[algorithm_name]  = model_f1[i]\n",
    "#     MCC_data[i].loc[algorithm_name]  = model_mcc[i]\n",
    "# df_acc = Acc_data\n",
    "# df_acc.to_csv(\"./XGBoost/5-CV-Acc.csv\")\n",
    "# df_acc = pd.read_csv('./XGBoost/5-CV-Acc.csv')\n",
    "# label = []\n",
    "# label = algorithm_name\n",
    "# average = []\n",
    "# average = (df_acc['0']+df_acc['1']+df_acc['2']+df_acc['3']+df_acc['4'])/5\n",
    "# data_tuples = list(zip(label,df_acc['0'],df_acc['1'],df_acc['2'],df_acc['3'],df_acc['4'],average))\n",
    "# df_acc = pd.DataFrame(data_tuples,  columns=['label','0','1','2','3','4', 'average'])\n",
    "# df_acc.to_csv('./XGBoost/5-CV-Acc.csv',index=False)\n",
    "\n",
    "# df_auc = Auc_data\n",
    "# df_auc.to_csv(\"./XGBoost/5-CV-AUC_ROC.csv\")\n",
    "# df_auc = pd.read_csv('./XGBoost/5-CV-AUC_ROC.csv')\n",
    "# label = []\n",
    "# label = algorithm_name\n",
    "# average = []\n",
    "# average = (df_auc['0']+df_auc['1']+df_auc['2']+df_auc['3']+df_auc['4'])/5\n",
    "# data_tuples = list(zip(label,df_auc['0'],df_auc['1'],df_auc['2'],df_auc['3'],df_auc['4'],average))\n",
    "# df_auc = pd.DataFrame(data_tuples,  columns=['label','0','1','2','3','4', 'average'])\n",
    "# df_auc.to_csv('./XGBoost/5-CV-AUC_ROC.csv',index=False)\n",
    "\n",
    "# df_rec = Recall_data\n",
    "# df_rec.to_csv(\"./XGBoost/5-CV-REC.csv\")\n",
    "# df_rec = pd.read_csv('./XGBoost/5-CV-REC.csv')\n",
    "# label = []\n",
    "# label = algorithm_name\n",
    "# average = []\n",
    "# average = (df_rec['0']+df_rec['1']+df_rec['2']+df_rec['3']+df_rec['4'])/5\n",
    "# data_tuples = list(zip(label,df_rec['0'],df_rec['1'],df_rec['2'],df_rec['3'],df_rec['4'],average))\n",
    "# df_rec = pd.DataFrame(data_tuples,  columns=['label','0','1','2','3','4', 'average'])\n",
    "# df_rec.to_csv('./XGBoost/5-CV-REC.csv',index=False)\n",
    "\n",
    "# df_pre = Precision_data\n",
    "# df_pre.to_csv(\"./XGBoost/5-CV-PRE.csv\")\n",
    "# df_pre = pd.read_csv('./XGBoost/5-CV-PRE.csv')\n",
    "# label = []\n",
    "# label = algorithm_name\n",
    "# average = []\n",
    "# average = (df_pre['0']+df_pre['1']+df_pre['2']+df_pre['3']+df_pre['4'])/5\n",
    "# data_tuples = list(zip(label,df_pre['0'],df_pre['1'],df_pre['2'],df_pre['3'],df_pre['4'],average))\n",
    "# df_pre = pd.DataFrame(data_tuples,  columns=['label','0','1','2','3','4', 'average'])\n",
    "# df_pre.to_csv('./XGBoost/5-CV-PRE.csv',index=False)\n",
    "\n",
    "# df_f1 = F1_data\n",
    "# df_f1.to_csv(\"./XGBoost/5-CV-F1.csv\")\n",
    "# df_f1 = pd.read_csv('./XGBoost/5-CV-F1.csv')\n",
    "# label = []\n",
    "# label = algorithm_name\n",
    "# average = []\n",
    "# average = (df_f1['0']+df_f1['1']+df_f1['2']+df_f1['3']+df_f1['4'])/5\n",
    "# data_tuples = list(zip(label,df_f1['0'],df_f1['1'],df_f1['2'],df_f1['3'],df_f1['4'],average))\n",
    "# df_f1 = pd.DataFrame(data_tuples,  columns=['label','0','1','2','3','4', 'average'])\n",
    "# df_f1.to_csv('./XGBoost/5-CV-F1.csv',index=False)\n",
    "\n",
    "# df_mcc = MCC_data\n",
    "# df_mcc.to_csv(\"./XGBoost/5-CV-MCC.csv\")\n",
    "# df_mcc = pd.read_csv('./XGBoost/5-CV-MCC.csv')\n",
    "# label = []\n",
    "# label = algorithm_name\n",
    "# average = []\n",
    "# average = (df_mcc['0']+df_mcc['1']+df_mcc['2']+df_mcc['3']+df_mcc['4'])/5\n",
    "# data_tuples = list(zip(label,df_mcc['0'],df_mcc['1'],df_mcc['2'],df_mcc['3'],df_mcc['4'],average))\n",
    "# df_mcc = pd.DataFrame(data_tuples,  columns=['label','0','1','2','3','4', 'average'])\n",
    "# df_mcc.to_csv('./XGBoost/5-CV-MCC.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d428a481-a3dd-4a4c-ba24-c1ed861217e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 5折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891e6d8-1ce9-497e-bfa1-595ee7470227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef, make_scorer\n",
    "\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    return data\n",
    "\n",
    "def process_all_scores(score_dict, algorithm_name, folder):\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/5-CV-{metric.upper()}.csv\"\n",
    "        columns = [str(i) for i in range(len(values))]\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)\n",
    "    return results\n",
    "\n",
    "# 实际的数据和模型定义\n",
    "train_X = x_mor_train  \n",
    "train_Y = y_mor_train  \n",
    "model = xgb\n",
    "\n",
    "# 定义5折交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# 评分函数\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'roc_auc': 'roc_auc_ovr',\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# 执行交叉验证\n",
    "scores = cross_validate(model, train_X, train_Y, scoring=scoring, cv=cv_strategy, return_estimator=False)\n",
    "\n",
    "# 格式化分数字典以使用在处理函数中\n",
    "formatted_scores = {key[5:]: scores[key] for key in scores.keys() if key.startswith('test_')}\n",
    "\n",
    "# 处理并保存分数\n",
    "results = process_all_scores(formatted_scores, \"xgb\", \"./XGBoost/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a9ab28-21e3-4119-86d9-3342bd1f3b44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 10折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a51c95-99c5-478e-8bab-2482b36625e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef, make_scorer\n",
    "\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    return data\n",
    "\n",
    "def process_all_scores(score_dict, algorithm_name, folder):\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/10-CV-{metric.upper()}.csv\"\n",
    "        columns = [str(i) for i in range(len(values))]\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)\n",
    "    return results\n",
    "\n",
    "# 实际的数据和模型定义\n",
    "train_X = x_mor_train  \n",
    "train_Y = y_mor_train  \n",
    "xgb_model = xgb\n",
    "\n",
    "# 定义10折交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# 评分函数\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'roc_auc': 'roc_auc_ovr',\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# 执行交叉验证\n",
    "scores = cross_validate(xgb_model, train_X, train_Y, scoring=scoring, cv=cv_strategy, return_estimator=False)\n",
    "\n",
    "# 格式化分数字典以使用在处理函数中\n",
    "formatted_scores = {key[5:]: scores[key] for key in scores.keys() if key.startswith('test_')}\n",
    "\n",
    "# 处理并保存分数\n",
    "results = process_all_scores(formatted_scores, \"xgb\", \"./XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65e2c7-4a32-4bff-8fb4-c205f4b8e92f",
   "metadata": {},
   "source": [
    "#### 在测试集上的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b071ae6-23e0-41cc-8706-6d4469fa8244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 忽略特定类型的警告\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "\n",
    "# 导入机器学习库scikit-learn中的XGB分类器和其他必要的工具包\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    roc_auc_score, f1_score, matthews_corrcoef, \n",
    "    make_scorer, confusion_matrix\n",
    ")\n",
    "import pandas as pd  # 导入数据处理库pandas\n",
    "import numpy as np  # 导入数值计算库numpy\n",
    "\n",
    "# 定义特异性评分函数\n",
    "def specificity_score(y_true, y_pred):\n",
    "    \"\"\"计算特异性（Specificity）.\"\"\"\n",
    "    tn, fp, _, _ = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "\n",
    "# 定义一个函数用于保存训练集交叉验证的分数到CSV文件，并且打印/保存平均值。\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    \"\"\"将交叉验证的成绩保存到CSV文件中。\"\"\"\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)  # 计算平均分并添加为新列\n",
    "    data.to_csv(file_path, index=False)  # 将DataFrame保存为CSV文件\n",
    "    print(f\"Data saved to {file_path}\")  # 打印保存信息\n",
    "    return data\n",
    "\n",
    "# 定义一个函数来处理所有成绩指标并使用`save_cv_scores`函数保存它们。\n",
    "# 修改process_all_scores函数，添加n_splits参数以反映正确的折数。\n",
    "def process_all_scores(score_dict, algorithm_name, folder, n_splits):\n",
    "    \"\"\"处理所有成绩指标并将其保存到CSV文件中。\"\"\"\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/{n_splits}-CV-{metric.upper()}.csv\"  # 使用传入的n_splits来构造文件名\n",
    "        columns = [str(i+1) for i in range(len(values))]  # 创建列名列表\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)  # 保存成绩并添加到结果字典\n",
    "    return results\n",
    "\n",
    "# 初始化XGBClassifier分类器，并设置超参数\n",
    "\n",
    "XGB = XGBClassifier(\n",
    "    random_state=0,\n",
    "    objective='binary:logistic',\n",
    "    colsample_bytree = 0.7,\n",
    "    gamma = 0.4,\n",
    "    max_depth = 11,\n",
    "    min_child_weight = 1,\n",
    "    n_estimators = 10,\n",
    "    reg_alpha = 0.1,\n",
    "    reg_lambda = 0.1,\n",
    "    subsample = 0.7\n",
    ")\n",
    "\n",
    "# 使用XGB分类器进行训练和预测。\n",
    "def train_and_evaluate(model, train_features, train_labels, test_features, test_labels):\n",
    "    \"\"\"训练模型并评估其在训练集和测试集上的性能。\"\"\"\n",
    "    model.fit(train_features, train_labels)  # 训练模型\n",
    "    clf_train_preds = model.predict(train_features)  # 在训练集上进行预测\n",
    "    clf_test_preds = model.predict(test_features)  # 在测试集上进行预测\n",
    "    # 打印训练集和测试集的准确率\n",
    "    print(f\"Training Set Accuracy: {accuracy_score(train_labels, clf_train_preds)}\")\n",
    "    print(f\"Test Set Accuracy: {accuracy_score(test_labels, clf_test_preds)}\")\n",
    "\n",
    "# 初始化用于训练和测试的特征和标签变量。\n",
    "train_X, train_Y = x_mor_train, y_mor_train  # 训练集特征和标签\n",
    "test_X, test_Y = x_mor_test, y_mor_test  # 测试集特征和标签\n",
    "\n",
    "# 执行训练和评估。\n",
    "train_and_evaluate(XGB, train_X, train_Y, test_X, test_Y)\n",
    "\n",
    "# 定义一个函数进行交叉验证和成绩的保存。\n",
    "# 修改perform_cross_validation函数的调用，传入n_splits参数。\n",
    "def perform_cross_validation(model, train_features, train_labels, n_splits, folder):\n",
    "    \"\"\"执行交叉验证和成绩处理。\"\"\"\n",
    "    cv_strategy = StratifiedKFold(n_splits=n_splits)  # 使用分层k折交叉验证\n",
    "    # 定义评分方法\n",
    "    scoring_methods = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': make_scorer(precision_score, average='macro'),\n",
    "        'recall': make_scorer(recall_score, average='macro'),\n",
    "        'roc_auc': 'roc_auc_ovr',\n",
    "        'f1': make_scorer(f1_score, average='macro'),\n",
    "        'matthews_corrcoef': make_scorer(matthews_corrcoef),\n",
    "        'specificity': make_scorer(specificity_score)  # 添加特异性评分\n",
    "    }\n",
    "    # 执行交叉验证\n",
    "    scores = cross_validate(model, train_features, train_labels, scoring=scoring_methods, cv=cv_strategy)\n",
    "    # 格式化分数并返回结果\n",
    "    formatted_scores = {key.split('_')[-1]: scores[key] for key in scores if key.startswith('test_')}\n",
    "    # 注意这里传入n_splits\n",
    "    return process_all_scores(formatted_scores, model.__class__.__name__, folder, n_splits)\n",
    "\n",
    "# 执行5折交叉验证然后是10折交叉验证。\n",
    "# 注意这里传入n_splits参数到process_all_scores函数。\n",
    "results_5_fold = perform_cross_validation(XGB, train_X, train_Y, 5, \"./XGBoost\")  # 5折交叉验证结果\n",
    "results_10_fold = perform_cross_validation(XGB, train_X, train_Y, 10, \"./XGBoost\")  # 10折交叉验证结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27857da1-c963-4cf0-af05-d43d6a101f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def train_and_evaluate(model, train_features, train_labels, test_features, test_labels, output_file):\n",
    "    \"\"\"训练模型并评估其在训练集和测试集上的性能，包括多种评估指标，并将结果保存到CSV文件。\"\"\"\n",
    "    model.fit(train_features, train_labels)  # 训练模型\n",
    "    clf_train_preds = model.predict(train_features)  # 在训练集上进行预测\n",
    "    clf_test_preds = model.predict(test_features)  # 在测试集上进行预测\n",
    "    \n",
    "    # 计算训练集上的性能指标\n",
    "    metrics = {\n",
    "        'Train_Accuracy': accuracy_score(train_labels, clf_train_preds),\n",
    "        'Train_Precision': precision_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_Recall': recall_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_F1': f1_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_MCC': matthews_corrcoef(train_labels, clf_train_preds),\n",
    "        'Train_Specificity': specificity_score(train_labels, clf_train_preds),\n",
    "        'Train_ROC_AUC': roc_auc_score(train_labels, model.predict_proba(train_features)[:, 1], multi_class='ovr'),\n",
    "        \n",
    "        'Test_Accuracy': accuracy_score(test_labels, clf_test_preds),\n",
    "        'Test_Precision': precision_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_Recall': recall_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_F1': f1_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_MCC': matthews_corrcoef(test_labels, clf_test_preds),\n",
    "        'Test_Specificity': specificity_score(test_labels, clf_test_preds),\n",
    "        'Test_ROC_AUC': roc_auc_score(test_labels, model.predict_proba(test_features)[:, 1], multi_class='ovr')\n",
    "    }\n",
    "    \n",
    "    # 将字典转换为DataFrame并保存到CSV文件\n",
    "    df = pd.DataFrame([metrics])\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Metrics saved to {output_file}\")\n",
    "\n",
    "# 执行训练和评估，输出结果\n",
    "train_and_evaluate(XGB, train_X, train_Y, test_X, test_Y,\"./XGBoost/训练和评估.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45e34f5-a74e-48de-8e85-d2ea9aadd349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "estimator = xgb\n",
    "estimator.fit(train_X, train_Y)\n",
    "clf_test = estimator.predict(test_X)\n",
    "acc_test = accuracy_score(test_Y,clf_test)\n",
    "roc_test = roc_auc_score(test_Y,clf_test)\n",
    "pre_test = precision_score(test_Y,clf_test)\n",
    "rec_test = recall_score(test_Y,clf_test)\n",
    "f1_test = f1_score(test_Y,clf_test)\n",
    "mcc_test = matthews_corrcoef(test_Y,clf_test)\n",
    "matrix_test = confusion_matrix(test_Y,clf_test)\n",
    "ap_test = average_precision_score(test_Y,clf_test)\n",
    "\n",
    "algorithm_model = [xgb]\n",
    "algorithm_name = [\"XGB\"]\n",
    "tmp_1 = np.zeros((1,2))\n",
    "Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(2))\n",
    "tmp_2 = np.zeros((1,2))\n",
    "Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(2))\n",
    "tmp_3 = np.zeros((1,2))\n",
    "Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(2))  \n",
    "tmp_4 = np.zeros((1,2))\n",
    "Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(2)) \n",
    "tmp_5 = np.zeros((1,2))\n",
    "F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(2))\n",
    "tmp_6 = np.zeros((1,2))\n",
    "MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(2))\n",
    "tmp_7 = np.zeros((1,2))\n",
    "Ap_data = pd.DataFrame(tmp_7,index=algorithm_name,columns=range(2))\n",
    "\n",
    "Auc_data.loc[algorithm_name]  = roc_test\n",
    "Acc_data.loc[algorithm_name]  = acc_test\n",
    "Recall_data.loc[algorithm_name] = rec_test\n",
    "Precision_data.loc[algorithm_name] = pre_test\n",
    "F1_data.loc[algorithm_name]  = f1_test\n",
    "MCC_data.loc[algorithm_name]  = mcc_test\n",
    "Ap_data.loc[algorithm_name]  = ap_test\n",
    "\n",
    "Auc_data.to_csv(\"./XGBoost/test_ROC.csv\")\n",
    "Acc_data.to_csv(\"./XGBoost/test_ACC.csv\")\n",
    "Recall_data.to_csv(\"./XGBoost/test_REC.csv\")\n",
    "Precision_data.to_csv(\"./XGBoost/test_PRE.csv\")\n",
    "F1_data.to_csv(\"./XGBoost/test_F1.csv\")\n",
    "MCC_data.to_csv(\"./XGBoost/test_MCC.csv\")\n",
    "Ap_data.to_csv(\"./XGBoost/test_AP.csv\")\n",
    "\n",
    "clf_train = estimator.predict(train_X)\n",
    "acc_train = accuracy_score(train_Y,clf_train)\n",
    "roc_train = roc_auc_score(train_Y,clf_train)\n",
    "pre_train = precision_score(train_Y,clf_train)\n",
    "rec_train = recall_score(train_Y,clf_train)\n",
    "f1_train = f1_score(train_Y,clf_train)\n",
    "mcc_train = matthews_corrcoef(train_Y,clf_train)\n",
    "matrix_train = confusion_matrix(train_Y,clf_train)\n",
    "ap_train = average_precision_score(train_Y,clf_train)\n",
    "\n",
    "tmp_1 = np.zeros((1,2))\n",
    "Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(2))\n",
    "tmp_2 = np.zeros((1,2))\n",
    "Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(2))\n",
    "tmp_3 = np.zeros((1,2))\n",
    "Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(2))  \n",
    "tmp_4 = np.zeros((1,2))\n",
    "Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(2)) \n",
    "tmp_5 = np.zeros((1,2))\n",
    "F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(2))\n",
    "tmp_6 = np.zeros((1,2))\n",
    "MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(2))\n",
    "tmp_7 = np.zeros((1,2))\n",
    "Ap_data = pd.DataFrame(tmp_7,index=algorithm_name,columns=range(2))\n",
    "\n",
    "Auc_data.loc[algorithm_name]  = roc_train\n",
    "Acc_data.loc[algorithm_name]  = acc_train\n",
    "Recall_data.loc[algorithm_name] = rec_train\n",
    "Precision_data.loc[algorithm_name] = pre_train\n",
    "F1_data.loc[algorithm_name]  = f1_train\n",
    "MCC_data.loc[algorithm_name]  = mcc_train\n",
    "Ap_data.loc[algorithm_name]  = ap_train\n",
    "\n",
    "Auc_data.to_csv(\"./XGBoost/train_ROC.csv\")\n",
    "Acc_data.to_csv(\"./XGBoost/train_ACC.csv\")\n",
    "Recall_data.to_csv(\"./XGBoost/train_REC.csv\")\n",
    "Precision_data.to_csv(\"./XGBoost/train_PRE.csv\")\n",
    "F1_data.to_csv(\"./XGBoost/train_F1.csv\")\n",
    "MCC_data.to_csv(\"./XGBoost/train_MCC.csv\")\n",
    "Ap_data.to_csv(\"./XGBoost/train_AP.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bda798-45e1-408d-9157-fb40380eb7a1",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d613f95b-70d7-43cd-b1d7-4e1f554fa0c5",
   "metadata": {},
   "source": [
    "### 参数搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e684662-45f1-4afa-aa70-bff3e1a9d8bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from time import time\n",
    "begin_time = time()\n",
    "# Search optimal hyperparameter\n",
    "mlp_auto = MLPClassifier(random_state = 0)\n",
    "\n",
    "#hidden_layer_sizes_range = [int(x) for x in np.linspace(start=25,stop=200,num=10)]\n",
    "\n",
    "hidden_layer_sizes_range = [  \n",
    "    (x, y, z)   \n",
    "    for x in np.linspace(start=20, stop=200, num=5, dtype=int)   \n",
    "    for y in np.linspace(start=20, stop=200, num=5, dtype=int)   \n",
    "    for z in np.linspace(start=20, stop=200, num=5, dtype=int)  \n",
    "] \n",
    "\n",
    "mlp_range = {\"solver\":['sgd','lbfgs','adam'],   # 优化算法的选择\n",
    "                    \"activation\":['relu','identity','logistic','tanh'],   # 激活函数的选择\n",
    "                    #\"alpha\": [1e-4],  #默认，正则化项参数\n",
    "                    \"hidden_layer_sizes\" : hidden_layer_sizes_range,   # 隐藏层大小的选择\n",
    "                    #\"learning_rate_init\" : [0.001], \n",
    "                    #默认0.001，初始学习率，控制更新权重的补偿，只有当solver=’sgd’ 或’adam’时使用\n",
    "                    \"learning_rate\": ['constant','invscaling','adaptive'],   # 学习率的选择\n",
    "                    }      \n",
    "print(mlp_range)  \n",
    "\n",
    "estimator_all_roc = GridSearchCV(estimator=mlp_auto,\n",
    "                                 param_grid=mlp_range,\n",
    "                                 cv=cv,\n",
    "                                 n_jobs=-1,\n",
    "                                 scoring=\"roc_auc\",verbose=1)\n",
    "\n",
    "# %%time\n",
    "estimator_all_roc.fit(X, Y)\n",
    "end_time = time()\n",
    "print({end_time - begin_time})\n",
    "print(estimator_all_roc.best_params_)\n",
    "print(estimator_all_roc.best_score_)\n",
    "tmp = pd.DataFrame(estimator_all_roc.cv_results_)\n",
    "df_fig = tmp[[\"mean_test_score\",\"params\"]]\n",
    "# 将最佳参数提取到新的列中  \n",
    "for param in [\"solver\", \"activation\", \"learning_rate\"]:  \n",
    "    df_fig[param] = df_fig[\"params\"].apply(lambda x: x[param])  \n",
    "# 由于hidden_layer_sizes是一个元组，我们需要将它转换为字符串以便保存  \n",
    "df_fig[\"hidden_layer_sizes\"] = df_fig[\"params\"].apply(lambda x: str(x[\"hidden_layer_sizes\"]))  \n",
    "df_fig.to_csv(\"./DNN/tmp2-dnn.csv\", index=False)  \n",
    "df_fig.head(50)  \n",
    "df_fig.to_csv(\"./DNN/网格搜索结果DNN.csv\", index=False)  \n",
    "df_fig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceeeb49-d620-43b7-8ff9-9afb5fa8b6be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(estimator_all_roc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5960a3e5-a41d-4372-ba4f-2a178666aad9",
   "metadata": {},
   "source": [
    "### 混淆矩阵  AUC-ROC PR-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456983ff-51a9-4069-a750-29292fa8157d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "train_X = x_mor_train  # 训练集特征数据\n",
    "train_Y = y_mor_train  # 训练集目标数据（标签）\n",
    "test_X = x_mor_test    # 测试集特征数据\n",
    "test_Y = y_mor_test    # 测试集目标数据（标签）\n",
    "\n",
    "plt.rc('axes', linewidth=1.5)\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    random_state=0,\n",
    "    activation='tanh',\n",
    "    hidden_layer_sizes = (110,200,110),\n",
    "    learning_rate = 'constant',\n",
    "    solver = 'sgd'\n",
    ")\n",
    "# 训练模型\n",
    "estimator = mlp\n",
    "estimator.fit(train_X, train_Y)\n",
    "# 在训练集和测试集上进行预测\n",
    "clf_train = estimator.predict(train_X)\n",
    "clf_test = estimator.predict(test_X)\n",
    "print(f\"训练集准确度是{accuracy_score(train_Y,clf_train)}\")\n",
    "print(f\"测试集准确度是{accuracy_score(test_Y,clf_test)}\")\n",
    "\n",
    "# 生成训练集和测试集的混淆矩阵\n",
    "train_matrix = confusion_matrix(train_Y, clf_train)\n",
    "test_matrix = confusion_matrix(test_Y, clf_test)\n",
    "# 绘制混淆矩阵\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(train_matrix, annot=True, cmap=\"Blues\", cbar=None,fmt=\"d\") \n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title(\"Confusion Matrix of Train\")\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(test_matrix, annot=True, cmap=\"Blues\", cbar=None,fmt=\"d\")\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title(\"Confusion Matrix of Test\")\n",
    "plt.savefig(\"./DNN/混淆矩阵_DNN.svg\", dpi = 600)\n",
    "plt.show()\n",
    "\n",
    "#########  ROC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "# 训练集 ROC 图\n",
    "plt.subplot(1, 2, 1)\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]  # 获取训练集的预测概率\n",
    "fpr_train, tpr_train, _ = roc_curve(train_Y, y_pro_train)  # 计算 ROC 曲线的参数\n",
    "roc_auc_train = auc(fpr_train, tpr_train)  # 计算 AUC\n",
    "plt.plot(fpr_train, tpr_train, label='DNN-Train (AUC = %0.3f)' % roc_auc_train)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 绘制测试集 ROC 图\n",
    "plt.subplot(1, 2, 2)\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]  # 获取测试集的预测概率\n",
    "fpr_test, tpr_test, _ = roc_curve(test_Y, y_pro_test)  # 计算 ROC 曲线的参数\n",
    "roc_auc_test = auc(fpr_test, tpr_test)  # 计算 AUC\n",
    "plt.plot(fpr_test, tpr_test, label='DNN-Test (AUC = %0.3f)' % roc_auc_test)  # 绘制 ROC 曲线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色  # 绘制对角线\n",
    "plt.title('Receiver Operating Characteristic')  # 设置标题\n",
    "plt.xlabel('False Positive Rate')  # 设置横坐标标签\n",
    "plt.ylabel('True Positive Rate')  # 设置纵坐标标签\n",
    "plt.legend(loc='lower right')  # 设置图例位置\n",
    "plt.gca().spines['top'].set_visible(True)  # 显示顶部边框\n",
    "plt.gca().spines['right'].set_visible(True)  # 显示右侧边框\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.savefig(\"./DNN/AUC_ROC.svg\", dpi=600)  # 保存图形为 SVG 格式文件\n",
    "plt.show()  # 显示图形\n",
    "\n",
    "##绘制组合图\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制 ROC 曲线\n",
    "plt.plot(fpr_train, tpr_train,color='#5D9C59', label='DNN-Train (AUC = %0.3f)' % roc_auc_train)\n",
    "plt.plot(fpr_test, tpr_test,color='#5463FF', label='DNN-Test (AUC = %0.3f)' % roc_auc_test)\n",
    "# 绘制对角线\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')  #颜色\n",
    "# 添加背景网格\n",
    "plt.grid(True, linestyle='--')\n",
    "# 设置标题和标签\n",
    "plt.title('DNN-ECFPs', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('False Positive Rate', fontweight='bold', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontweight='bold', fontsize=15)\n",
    "plt.legend(loc='lower right')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./DNN/AUC_ROC_组合.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "# 训练集PR_AUC图\n",
    "plt.figure(figsize=(12, 5))\n",
    "y_pro_train = estimator.predict_proba(train_X)[:, 1]\n",
    "precision_train, recall_train, _ = precision_recall_curve(train_Y, y_pro_train, pos_label=1)\n",
    "pr_auc_train = auc(recall_train, precision_train)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(recall_train, precision_train, label='DNN-Train (PR_AUC = {:.3f})'.format(pr_auc_train))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "\n",
    "# 测试集PR_AUC图\n",
    "y_pro_test = estimator.predict_proba(test_X)[:, 1]\n",
    "precision_test, recall_test, _ = precision_recall_curve(test_Y, y_pro_test, pos_label=1)\n",
    "pr_auc_test = auc(recall_test, precision_test)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall_test, precision_test, label='DNN-Test (PR_AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('PR_AUC')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./DNN/PR_AUC.svg\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "# 绘制训练集PR_AUC图\n",
    "plt.plot(recall_train, precision_train,color='#5D9C59', label='DNN-Train (PR-AUC = {:.3f})'.format(pr_auc_train))\n",
    "# 绘制测试集PR_AUC图\n",
    "plt.plot(recall_test, precision_test,color='#5463FF', label='DNN-Test (PR-AUC = {:.3f})'.format(pr_auc_test))\n",
    "plt.title('DNN-ECFPs', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Recall', fontweight='bold', fontsize=15)\n",
    "plt.ylabel('Precision', fontweight='bold', fontsize=15)\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.savefig(\"./DNN/PR_AUC_组合.svg\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b49b8d1f-1f12-400f-8bcb-a8574f343cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/md06/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['DNN-ECFPs.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(\n",
    "    random_state=0,\n",
    "    activation='tanh',\n",
    "    hidden_layer_sizes = (110,200,110),\n",
    "    learning_rate = 'constant',\n",
    "    solver = 'sgd'\n",
    ")\n",
    "mlp.fit(x_mor_train, y_mor_train.values.ravel())  \n",
    "joblib.dump(mlp, \"DNN-ECFPs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552670a2-a189-42d6-9c10-b77aad9c8eed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 官网例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca9d62c-c76e-48d6-835a-91e02ec64fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 官网例子\n",
    "# Code source: Gaël Varoquaux\n",
    "#              Andreas Müller\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "    SVC(gamma=2, C=1, random_state=42),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42),\n",
    "    DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    RandomForestClassifier(\n",
    "        max_depth=5, n_estimators=10, max_features=1, random_state=42\n",
    "    ),\n",
    "    MLPClassifier(alpha=1, max_iter=1000, random_state=42),\n",
    "    AdaBoostClassifier(algorithm=\"SAMME\", random_state=42),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1\n",
    ")\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [\n",
    "    make_moons(noise=0.3, random_state=0),\n",
    "    make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "    linearly_separable,\n",
    "]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.4, random_state=42\n",
    "    )\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\")\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "    # Plot the testing points\n",
    "    ax.scatter(\n",
    "        X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors=\"k\"\n",
    "    )\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "\n",
    "        clf = make_pipeline(StandardScaler(), clf)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        DecisionBoundaryDisplay.from_estimator(\n",
    "            clf, X, cmap=cm, alpha=0.8, ax=ax, eps=0.5\n",
    "        )\n",
    "\n",
    "        # Plot the training points\n",
    "        ax.scatter(\n",
    "            X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\"\n",
    "        )\n",
    "        # Plot the testing points\n",
    "        ax.scatter(\n",
    "            X_test[:, 0],\n",
    "            X_test[:, 1],\n",
    "            c=y_test,\n",
    "            cmap=cm_bright,\n",
    "            edgecolors=\"k\",\n",
    "            alpha=0.6,\n",
    "        )\n",
    "\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name)\n",
    "        ax.text(\n",
    "            x_max - 0.3,\n",
    "            y_min + 0.3,\n",
    "            (\"%.2f\" % score).lstrip(\"0\"),\n",
    "            size=15,\n",
    "            horizontalalignment=\"right\",\n",
    "        )\n",
    "        i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f9a7f1-0a8d-4ee1-a157-51af9f61da8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 十折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa5dc60-6d7a-4ac8-b8d5-fe5b9a94fbaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef, make_scorer\n",
    "\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    return data\n",
    "\n",
    "def process_all_scores(score_dict, algorithm_name, folder):\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/10-CV-{metric.upper()}.csv\"\n",
    "        columns = [str(i) for i in range(len(values))]\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)\n",
    "    return results\n",
    "\n",
    "# 实际的数据和模型定义\n",
    "train_X = x_mor_train  \n",
    "train_Y = y_mor_train  \n",
    "model = mlp\n",
    "\n",
    "# 定义10折交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# 评分函数\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'roc_auc': 'roc_auc_ovr',\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# 执行交叉验证\n",
    "scores = cross_validate(model, train_X, train_Y, scoring=scoring, cv=cv_strategy, return_estimator=False)\n",
    "\n",
    "# 格式化分数字典以使用在处理函数中\n",
    "formatted_scores = {key[5:]: scores[key] for key in scores.keys() if key.startswith('test_')}\n",
    "\n",
    "# 处理并保存分数\n",
    "results = process_all_scores(formatted_scores, \"mlp\", \"./DNN/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d18fa0-ec28-4c5b-bd4d-636a73bda1d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 五折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ad0c0-991f-4717-ab1a-0cf4a1c23a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, matthews_corrcoef, make_scorer\n",
    "\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "    return data\n",
    "\n",
    "def process_all_scores(score_dict, algorithm_name, folder):\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/5-CV-{metric.upper()}.csv\"\n",
    "        columns = [str(i) for i in range(len(values))]\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)\n",
    "    return results\n",
    "\n",
    "# 实际的数据和模型定义\n",
    "train_X = x_mor_train  \n",
    "train_Y = y_mor_train  \n",
    "model = mlp\n",
    "\n",
    "# 定义5折交叉验证\n",
    "cv_strategy = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# 评分函数\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'roc_auc': 'roc_auc_ovr',\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# 执行交叉验证\n",
    "scores = cross_validate(model, train_X, train_Y, scoring=scoring, cv=cv_strategy, return_estimator=False)\n",
    "\n",
    "# 格式化分数字典以使用在处理函数中\n",
    "formatted_scores = {key[5:]: scores[key] for key in scores.keys() if key.startswith('test_')}\n",
    "\n",
    "# 处理并保存分数\n",
    "results = process_all_scores(formatted_scores, \"mlp\", \"./DNN/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17db58a0-2618-404b-8bd9-8a19c83f7fa7",
   "metadata": {},
   "source": [
    "### 在外部测试集的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f2e1c2-5033-491c-bdf5-82415b561e04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 忽略特定类型的警告\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "\n",
    "# 导入机器学习库scikit-learn中的XGB分类器和其他必要的工具包\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    roc_auc_score, f1_score, matthews_corrcoef, \n",
    "    make_scorer, confusion_matrix\n",
    ")\n",
    "import pandas as pd  # 导入数据处理库pandas\n",
    "import numpy as np  # 导入数值计算库numpy\n",
    "\n",
    "# 定义特异性评分函数\n",
    "def specificity_score(y_true, y_pred):\n",
    "    \"\"\"计算特异性（Specificity）.\"\"\"\n",
    "    tn, fp, _, _ = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "\n",
    "# 定义一个函数用于保存训练集交叉验证的分数到CSV文件，并且打印/保存平均值。\n",
    "def save_cv_scores(scores, column_names, file_path, label):\n",
    "    \"\"\"将交叉验证的成绩保存到CSV文件中。\"\"\"\n",
    "    data = pd.DataFrame(np.array(scores).reshape(1, -1), index=[label], columns=column_names)\n",
    "    data['average'] = data.mean(axis=1)  # 计算平均分并添加为新列\n",
    "    data.to_csv(file_path, index=False)  # 将DataFrame保存为CSV文件\n",
    "    print(f\"Data saved to {file_path}\")  # 打印保存信息\n",
    "    return data\n",
    "\n",
    "# 定义一个函数来处理所有成绩指标并使用`save_cv_scores`函数保存它们。\n",
    "# 修改process_all_scores函数，添加n_splits参数以反映正确的折数。\n",
    "def process_all_scores(score_dict, algorithm_name, folder, n_splits):\n",
    "    \"\"\"处理所有成绩指标并将其保存到CSV文件中。\"\"\"\n",
    "    results = {}\n",
    "    for metric, values in score_dict.items():\n",
    "        file_path = f\"{folder}/{n_splits}-CV-{metric.upper()}.csv\"  # 使用传入的n_splits来构造文件名\n",
    "        columns = [str(i+1) for i in range(len(values))]  # 创建列名列表\n",
    "        results[metric] = save_cv_scores(values, columns, file_path, algorithm_name)  # 保存成绩并添加到结果字典\n",
    "    return results\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    random_state=0,\n",
    "    activation='tanh',\n",
    "    hidden_layer_sizes = (110,200,110),\n",
    "    learning_rate = 'constant',\n",
    "    solver = 'sgd'\n",
    ")\n",
    "\n",
    "# 使用XGB分类器进行训练和预测。\n",
    "def train_and_evaluate(model, train_features, train_labels, test_features, test_labels):\n",
    "    \"\"\"训练模型并评估其在训练集和测试集上的性能。\"\"\"\n",
    "    model.fit(train_features, train_labels)  # 训练模型\n",
    "    clf_train_preds = model.predict(train_features)  # 在训练集上进行预测\n",
    "    clf_test_preds = model.predict(test_features)  # 在测试集上进行预测\n",
    "    # 打印训练集和测试集的准确率\n",
    "    print(f\"Training Set Accuracy: {accuracy_score(train_labels, clf_train_preds)}\")\n",
    "    print(f\"Test Set Accuracy: {accuracy_score(test_labels, clf_test_preds)}\")\n",
    "\n",
    "# 初始化用于训练和测试的特征和标签变量。\n",
    "train_X, train_Y = x_mor_train, y_mor_train  # 训练集特征和标签\n",
    "test_X, test_Y = x_mor_test, y_mor_test  # 测试集特征和标签\n",
    "\n",
    "# 执行训练和评估。\n",
    "train_and_evaluate(mlp, train_X, train_Y, test_X, test_Y)\n",
    "\n",
    "# 定义一个函数进行交叉验证和成绩的保存。\n",
    "# 修改perform_cross_validation函数的调用，传入n_splits参数。\n",
    "def perform_cross_validation(model, train_features, train_labels, n_splits, folder):\n",
    "    \"\"\"执行交叉验证和成绩处理。\"\"\"\n",
    "    cv_strategy = StratifiedKFold(n_splits=n_splits)  # 使用分层k折交叉验证\n",
    "    # 定义评分方法\n",
    "    scoring_methods = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': make_scorer(precision_score, average='macro'),\n",
    "        'recall': make_scorer(recall_score, average='macro'),\n",
    "        'roc_auc': 'roc_auc_ovr',\n",
    "        'f1': make_scorer(f1_score, average='macro'),\n",
    "        'matthews_corrcoef': make_scorer(matthews_corrcoef),\n",
    "        'specificity': make_scorer(specificity_score)  # 添加特异性评分\n",
    "    }\n",
    "    # 执行交叉验证\n",
    "    scores = cross_validate(model, train_features, train_labels, scoring=scoring_methods, cv=cv_strategy)\n",
    "    # 格式化分数并返回结果\n",
    "    formatted_scores = {key.split('_')[-1]: scores[key] for key in scores if key.startswith('test_')}\n",
    "    # 注意这里传入n_splits\n",
    "    return process_all_scores(formatted_scores, model.__class__.__name__, folder, n_splits)\n",
    "\n",
    "# 执行5折交叉验证然后是10折交叉验证。\n",
    "# 注意这里传入n_splits参数到process_all_scores函数。\n",
    "results_5_fold = perform_cross_validation(mlp, train_X, train_Y, 5, \"./DNN\")  # 5折交叉验证结果\n",
    "results_10_fold = perform_cross_validation(mlp, train_X, train_Y, 10, \"./DNN\")  # 10折交叉验证结果 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd2594d-3be3-4d75-a189-30ecf53bc432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def train_and_evaluate(model, train_features, train_labels, test_features, test_labels, output_file):\n",
    "    \"\"\"训练模型并评估其在训练集和测试集上的性能，包括多种评估指标，并将结果保存到CSV文件。\"\"\"\n",
    "    model.fit(train_features, train_labels)  # 训练模型\n",
    "    clf_train_preds = model.predict(train_features)  # 在训练集上进行预测\n",
    "    clf_test_preds = model.predict(test_features)  # 在测试集上进行预测\n",
    "    \n",
    "    # 计算训练集上的性能指标\n",
    "    metrics = {\n",
    "        'Train_Accuracy': accuracy_score(train_labels, clf_train_preds),\n",
    "        'Train_Precision': precision_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_Recall': recall_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_F1': f1_score(train_labels, clf_train_preds, average='macro'),\n",
    "        'Train_MCC': matthews_corrcoef(train_labels, clf_train_preds),\n",
    "        'Train_Specificity': specificity_score(train_labels, clf_train_preds),\n",
    "        'Train_ROC_AUC': roc_auc_score(train_labels, model.predict_proba(train_features)[:, 1], multi_class='ovr'),\n",
    "        \n",
    "        'Test_Accuracy': accuracy_score(test_labels, clf_test_preds),\n",
    "        'Test_Precision': precision_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_Recall': recall_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_F1': f1_score(test_labels, clf_test_preds, average='macro'),\n",
    "        'Test_MCC': matthews_corrcoef(test_labels, clf_test_preds),\n",
    "        'Test_Specificity': specificity_score(test_labels, clf_test_preds),\n",
    "        'Test_ROC_AUC': roc_auc_score(test_labels, model.predict_proba(test_features)[:, 1], multi_class='ovr')\n",
    "    }\n",
    "    \n",
    "    # 将字典转换为DataFrame并保存到CSV文件\n",
    "    df = pd.DataFrame([metrics])\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Metrics saved to {output_file}\")\n",
    "\n",
    "# 执行训练和评估，输出结果\n",
    "train_and_evaluate(mlp, train_X, train_Y, test_X, test_Y,\"./DNN/训练和评估.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5038ca-9ab0-4b6f-8a1f-c0d0181931d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "estimator = mlp\n",
    "estimator.fit(train_X, train_Y)\n",
    "clf_test = estimator.predict(test_X)\n",
    "acc_test = accuracy_score(test_Y,clf_test)\n",
    "roc_test = roc_auc_score(test_Y,clf_test)\n",
    "pre_test = precision_score(test_Y,clf_test)\n",
    "rec_test = recall_score(test_Y,clf_test)\n",
    "f1_test = f1_score(test_Y,clf_test)\n",
    "mcc_test = matthews_corrcoef(test_Y,clf_test)\n",
    "matrix_test = confusion_matrix(test_Y,clf_test)\n",
    "ap_test = average_precision_score(test_Y,clf_test)\n",
    "\n",
    "algorithm_model = [mlp]\n",
    "algorithm_name = [\"MLP\"]   # 在csv文件里的第一列\n",
    "tmp_1 = np.zeros((1,2))\n",
    "Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(2))\n",
    "tmp_2 = np.zeros((1,2))\n",
    "Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(2))\n",
    "tmp_3 = np.zeros((1,2))\n",
    "Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(2))  \n",
    "tmp_4 = np.zeros((1,2))\n",
    "Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(2)) \n",
    "tmp_5 = np.zeros((1,2))\n",
    "F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(2))\n",
    "tmp_6 = np.zeros((1,2))\n",
    "MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(2))\n",
    "tmp_7 = np.zeros((1,2))\n",
    "Ap_data = pd.DataFrame(tmp_7,index=algorithm_name,columns=range(2))\n",
    "\n",
    "Auc_data.loc[algorithm_name]  = roc_test\n",
    "Acc_data.loc[algorithm_name]  = acc_test\n",
    "Recall_data.loc[algorithm_name] = rec_test\n",
    "Precision_data.loc[algorithm_name] = pre_test\n",
    "F1_data.loc[algorithm_name]  = f1_test\n",
    "MCC_data.loc[algorithm_name]  = mcc_test\n",
    "Ap_data.loc[algorithm_name]  = ap_test\n",
    "\n",
    "Auc_data.to_csv(\"./DNN/test_ROC.csv\")\n",
    "Acc_data.to_csv(\"./DNN/test_ACC.csv\")\n",
    "Recall_data.to_csv(\"./DNN/test_REC.csv\")\n",
    "Precision_data.to_csv(\"./DNN/test_PRE.csv\")\n",
    "F1_data.to_csv(\"./DNN/test_F1.csv\")\n",
    "MCC_data.to_csv(\"./DNN/test_MCC.csv\")\n",
    "Ap_data.to_csv(\"./DNN/test_AP.csv\")\n",
    "\n",
    "clf_train = estimator.predict(train_X)\n",
    "acc_train = accuracy_score(train_Y,clf_train)\n",
    "roc_train = roc_auc_score(train_Y,clf_train)\n",
    "pre_train = precision_score(train_Y,clf_train)\n",
    "rec_train = recall_score(train_Y,clf_train)\n",
    "f1_train = f1_score(train_Y,clf_train)\n",
    "mcc_train = matthews_corrcoef(train_Y,clf_train)\n",
    "matrix_train = confusion_matrix(train_Y,clf_train)\n",
    "ap_train = average_precision_score(train_Y,clf_train)\n",
    "\n",
    "tmp_1 = np.zeros((1,2))\n",
    "Auc_data = pd.DataFrame(tmp_1,index=algorithm_name,columns=range(2))\n",
    "tmp_2 = np.zeros((1,2))\n",
    "Acc_data = pd.DataFrame(tmp_2,index=algorithm_name,columns=range(2))\n",
    "tmp_3 = np.zeros((1,2))\n",
    "Recall_data = pd.DataFrame(tmp_3,index=algorithm_name,columns=range(2))  \n",
    "tmp_4 = np.zeros((1,2))\n",
    "Precision_data = pd.DataFrame(tmp_4,index=algorithm_name,columns=range(2)) \n",
    "tmp_5 = np.zeros((1,2))\n",
    "F1_data = pd.DataFrame(tmp_5,index=algorithm_name,columns=range(2))\n",
    "tmp_6 = np.zeros((1,2))\n",
    "MCC_data = pd.DataFrame(tmp_6,index=algorithm_name,columns=range(2))\n",
    "tmp_7 = np.zeros((1,2))\n",
    "Ap_data = pd.DataFrame(tmp_7,index=algorithm_name,columns=range(2))\n",
    "\n",
    "Auc_data.loc[algorithm_name]  = roc_train\n",
    "Acc_data.loc[algorithm_name]  = acc_train\n",
    "Recall_data.loc[algorithm_name] = rec_train\n",
    "Precision_data.loc[algorithm_name] = pre_train\n",
    "F1_data.loc[algorithm_name]  = f1_train\n",
    "MCC_data.loc[algorithm_name]  = mcc_train\n",
    "Ap_data.loc[algorithm_name]  = ap_train\n",
    "\n",
    "Auc_data.to_csv(\"./DNN/train_ROC.csv\")\n",
    "Acc_data.to_csv(\"./DNN/train_ACC.csv\")\n",
    "Recall_data.to_csv(\"./DNN/train_REC.csv\")\n",
    "Precision_data.to_csv(\"./DNN/train_PRE.csv\")\n",
    "F1_data.to_csv(\"./DNN/train_F1.csv\")\n",
    "MCC_data.to_csv(\"./DNN/train_MCC.csv\")\n",
    "Ap_data.to_csv(\"./DNN/train_AP.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a166085-32cd-42e3-9183-68dbb6f1e566",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#  绘图"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc002bb-468c-45ad-a05f-32871a045e59",
   "metadata": {},
   "source": [
    "#### 5-fold交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c9253-b5f4-4812-9b75-e14013d2bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 从CSV文件加载数据\n",
    "data = pd.read_csv('./绘图/5-CV.csv')\n",
    "\n",
    "# 假设CSV文件中的列名为'model'和'AUC-ROC'\n",
    "x = data['model']\n",
    "values = data['AUC-ROC']\n",
    "\n",
    "# 设置绘图\n",
    "plt.figure(figsize=(6, 5))  # 可选：指定图形大小\n",
    "plt.title('5-fold Cross-Validation', fontsize=15)  # 设置图表标题和标题字体大小\n",
    "plt.ylim(0, 1.0)  # 设置y轴的范围\n",
    "plt.xlabel('Model', fontsize=14, fontweight='bold')  # 设置x轴标签，字体大小和字体粗细\n",
    "plt.ylabel('AUC-ROC', fontsize=14, fontweight='bold')  # 设置y轴标签，字体大小和字体粗细\n",
    "\n",
    "# 使用colormap生成颜色渐变，但限制色彩变化\n",
    "cmap = plt.get_cmap('Blues')\n",
    "color_start = 0.3  # 开始颜色的强度\n",
    "color_end = 0.5   # 结束颜色的强度\n",
    "colors = [cmap(color_start + (color_end - color_start) * i / len(x)) for i in range(len(x))]\n",
    "\n",
    "# 绘制柱状图，并为每根柱子指定颜色和宽度\n",
    "bar_width = 0.6  # 设置柱子的宽度\n",
    "bars = plt.bar(x, values, color=colors, width=bar_width)  # 增加width参数来设置宽度\n",
    "\n",
    "plt.gca().xaxis.grid(True, linestyle='--', which='major', color='grey', alpha=0.2)\n",
    "plt.gca().yaxis.grid(True, linestyle='--', which='major', color='grey', alpha=0.2)\n",
    "# 在每根柱子上添加文本\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 3), ha='center', va='bottom', rotation=90)  # 添加文本并设置垂直对齐\n",
    "    #round(yval, 2)：这是要显示的文本内容，将 yval 四舍五入到小数点后两位\n",
    "\n",
    "# 设置边框加粗\n",
    "ax = plt.gca()  # 获取当前的Axes对象\n",
    "[ax.spines[spine].set_linewidth(1.5) for spine in ax.spines]  # 加粗所有边框\n",
    "\n",
    "plt.savefig(\"./绘图/5-CV.svg\",bbox_inches=\"tight\")\n",
    "plt.show()  # 显示图表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411d99a1-affb-4b99-8618-75809a07023d",
   "metadata": {},
   "source": [
    "#### 10-fold交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa4bb93-9dce-4043-8e0e-0ae3f8fc3c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 从CSV文件加载数据\n",
    "data = pd.read_csv('./绘图/10-CV.csv')\n",
    "\n",
    "# 假设CSV文件中的列名为'model'和'AUC-ROC'\n",
    "x = data['model']\n",
    "values = data['AUC-ROC']\n",
    "\n",
    "# 设置绘图\n",
    "plt.figure(figsize=(6, 5))  # 可选：指定图形大小\n",
    "plt.title('10-fold Cross-Validation', fontsize=15)  # 设置图表标题和标题字体大小\n",
    "plt.ylim(0, 1.0)  # 设置y轴的范围\n",
    "plt.xlabel('Model', fontsize=14, fontweight='bold')  # 设置x轴标签，字体大小和字体粗细\n",
    "plt.ylabel('AUC-ROC', fontsize=14, fontweight='bold')  # 设置y轴标签，字体大小和字体粗细\n",
    "\n",
    "# 使用colormap生成颜色渐变，但限制色彩变化\n",
    "cmap = plt.get_cmap('Blues')\n",
    "color_start = 0.3  # 开始颜色的强度\n",
    "color_end = 0.5   # 结束颜色的强度\n",
    "colors = [cmap(color_start + (color_end - color_start) * i / len(x)) for i in range(len(x))]\n",
    "\n",
    "# 绘制柱状图，并为每根柱子指定颜色和宽度\n",
    "bar_width = 0.6  # 设置柱子的宽度\n",
    "bars = plt.bar(x, values, color=colors, width=bar_width)  # 增加width参数来设置宽度\n",
    "plt.gca().xaxis.grid(True, linestyle='--', which='major', color='grey', alpha=0.2)\n",
    "plt.gca().yaxis.grid(True, linestyle='--', which='major', color='grey', alpha=0.2)\n",
    "\n",
    "# 在每根柱子上添加文本\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 3), ha='center', va='bottom', rotation=90)  # 添加文本并设置垂直对齐\n",
    "    #round(yval, 2)：这是要显示的文本内容，将 yval 四舍五入到小数点后两位\n",
    "\n",
    "# 设置边框加粗\n",
    "ax = plt.gca()  # 获取当前的Axes对象\n",
    "[ax.spines[spine].set_linewidth(1.5) for spine in ax.spines]  # 加粗所有边框\n",
    "\n",
    "plt.savefig(\"./绘图/10-CV.svg\",bbox_inches=\"tight\")\n",
    "plt.show()  # 显示图表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981365bc-419e-4d2d-b779-815b4cd6e647",
   "metadata": {},
   "source": [
    "#### 箱型图"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929601aa-ccbb-4da9-bc12-eace0ae666a7",
   "metadata": {},
   "source": [
    "##### 作者：lne的科研记录本\n",
    "##### 链接：https://www.zhihu.com/question/486921343/answer/2785783712\n",
    "##### 来源：知乎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f791f0-ab1e-4d6a-8781-47136543c5ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 数据导入\n",
    "data = pd.read_csv('./绘图/箱型图.csv')\n",
    "\n",
    "# 设置画布\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.title('5-fold Cross-Validation', fontsize=15)  # 设置图表标题和标题字体大小\n",
    "plt.ylim(0.7, 1.0)  # 设置y轴的范围\n",
    "plt.xlabel('Model', fontsize=14, fontweight='bold')  # 设置x轴标签，字体大小和字体粗细\n",
    "plt.ylabel('AUC-ROC', fontsize=14, fontweight='bold')  # 设置y轴标签，字体大小和字体粗细\n",
    "\n",
    "# 箱线图绘制\n",
    "sns.boxplot(x=data['model'],  # 指定x轴的数据\n",
    "            y=data['AUC-ROC'],  # 指定y轴的数据\n",
    "            data=data,  # 指定绘图的数据集\n",
    "            whiskerprops={'color': 'black', 'linewidth': '0.9'},  # 设置须的大小\n",
    "            capprops={'color': 'black', 'linewidth': '1.0'},  # 设置顶端线条的大小\n",
    "            color=\"black\",\n",
    "            boxprops={\"edgecolor\": \"black\", \"linewidth\": 0.5},  # 设置箱体边缘属性\n",
    "            orient='v',  # 竖直方向\n",
    "            linewidth=0.5,\n",
    "            width=0.4,  # 指定箱子宽度\n",
    "            showfliers=False,  # 不显示异常值\n",
    "            flierprops={'markerfacecolor': 'g', 'marker': 'D', 'markersize': 6.0, 'markeredgecolor': 'black'},\n",
    "            medianprops={'linestyle': '--', 'color': 'black', 'linewidth': '0.7'},  # 中位数线属性\n",
    "            meanprops={'marker': '+', 'markersize': '6', 'markeredgecolor': 'red', 'markerfacecolor': 'none', 'markeredgewidth': '0.5'})  # 均值属性\n",
    "\n",
    "# 设置背景颜色和网格\n",
    "plt.gca().set_facecolor('white')  # 设置背景颜色为白色\n",
    "plt.gca().yaxis.grid(True, linestyle='--', which='major', color='grey', alpha=0.5)  # 设置y轴网格线为虚线，灰色，半透明\n",
    "plt.gca().xaxis.grid(True, linestyle='--', which='major', color='grey', alpha=0.5) \n",
    "plt.grid(True)\n",
    "\n",
    "# 设置边框\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['top'].set_color('black')\n",
    "ax.spines['right'].set_color('black')\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "# 设置边框加粗\n",
    "ax = plt.gca()  # 获取当前的Axes对象\n",
    "[ax.spines[spine].set_linewidth(1.5) for spine in ax.spines]  # 加粗所有边框\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./绘图/5-CV-箱型图.svg\", bbox_inches=\"tight\", dpi=600)  # 保存图像，设置DPI为600\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995222d3-275d-40d5-a4ca-85890412e4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fbw",
   "language": "python",
   "name": "fbw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
